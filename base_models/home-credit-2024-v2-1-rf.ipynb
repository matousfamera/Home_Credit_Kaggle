{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":50160,"databundleVersionId":7921029},{"sourceType":"datasetVersion","sourceId":8011205,"datasetId":4680819,"databundleVersionId":8123154}],"dockerImageVersionId":30665,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **CONTENT**\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"markdown","source":"# **LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom contextlib import contextmanager\nimport multiprocessing as mp\nfrom functools import partial\nfrom scipy.stats import kurtosis, iqr, skew\nimport lightgbm as lgb\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom glob import glob\nfrom pathlib import Path\nfrom datetime import datetime\nimport polars as pl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.base import BaseEstimator, RegressorMixin\nfrom sklearn.metrics import roc_auc_score \nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom tqdm.notebook import tqdm\nimport joblib\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport gc\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:41.424879Z","iopub.execute_input":"2024-04-02T19:07:41.425430Z","iopub.status.idle":"2024-04-02T19:07:44.597862Z","shell.execute_reply.started":"2024-04-02T19:07:41.425392Z","shell.execute_reply":"2024-04-02T19:07:44.596669Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **CONFIGURATION**\n<a id='configuration'></a>\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"code","source":"# GENERAL CONFIGURATIONS\nNUM_THREADS = 4\nDATA_DIRECTORY = \"/kaggle/input/home-credit-credit-risk-model-stability/parquet_files/\"\nSUBMISSION_SUFIX = \"_model_2.1_31\"\n#MODE CONFIGURATION\nSHOW_REPORT = False\nSELECTKBEST = False\nEXPORT_DATAFRAME = False\nIMPORT_DATAFRAME = False\n# LIGHTGBM CONFIGURATION AND HYPER-PARAMETERS\nGENERATE_SUBMISSION_FILES = True\nEVALUATE_VALIDATION_SET = True\nSTRATIFIED_KFOLD = True\nBALANCE_COLUMNS = False\nRANDOM_SEED = 324\nNUM_FOLDS = 5\nEARLY_STOPPING = 100\nROOT            = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n\n\nRF_PARAMS = {\n    \"n_estimators\": 101,\n    \"max_depth\": 9,\n    \"min_samples_split\": 4,\n    \"min_samples_leaf\": 3,\n    \"max_features\": 0.676,\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.600434Z","iopub.execute_input":"2024-04-02T19:07:44.601000Z","iopub.status.idle":"2024-04-02T19:07:44.608824Z","shell.execute_reply.started":"2024-04-02T19:07:44.600967Z","shell.execute_reply":"2024-04-02T19:07:44.607662Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Set aggregations","metadata":{}},{"cell_type":"code","source":"# AGGREGATIONS\n\n# D: max, min, mean\n# M: \n# A : max, min, mean, sum\n# L : max, min, mean, sum\n\n\nAPPLPREV1_AGG = {\n\n    'num_group1':['count'],\n    'actualdpd_943P': ['min','max','mean','sum'],\n    'annuity_853A': ['min','max','mean','sum'],\n    'approvaldate_319D':['max','min','mean'],\n    'byoccupationinc_3656910L': ['min','max','mean','sum'],\n    'cancelreason_3545846M':['max'],\n    'childnum_21L': ['min','max','mean','sum'],\n    'creationdate_885D':['min','max','mean'],\n    'credacc_actualbalance_314A': ['min','max','mean','sum'],\n    'credacc_credlmt_575A': ['min','max','mean','sum'],\n    'credacc_maxhisbal_375A': ['min','max','mean','sum'],\n    'credacc_minhisbal_90A': ['min','max','mean','sum'],\n    'credacc_status_367L': ['max'],\n    'credacc_transactions_402L': ['min','max','mean','sum'],\n    'credamount_590A': ['min','max','mean','sum'],\n    'credtype_587L': ['max'],\n    'currdebt_94A': ['min','max','mean','sum'],\n    'dateactivated_425D':['min','max','mean'],\n    'district_544M':['max'],\n    'downpmt_134A': ['min','max','mean','sum'],\n    'dtlastpmt_581D':['min','max','mean'],\n    'dtlastpmtallstes_3545839D':['min','max','mean'],\n    'education_1138M':['max'],\n    'employedfrom_700D':['min','max','mean'],\n    'familystate_726L': ['max'],\n    'firstnonzeroinstldate_307D': ['min','max','mean'],\n    'inittransactioncode_279L': ['max'],\n    'isbidproduct_390L': ['min','max','mean','sum'],\n    'isdebitcard_527L': ['min','max','mean','sum'],\n    'mainoccupationinc_437A': ['min','max','mean','sum','median'],\n    'maxdpdtolerance_577P': ['min','max','mean','sum'],\n    'outstandingdebt_522A': ['min','max','mean','sum'],\n    'pmtnum_8L': ['min','max','mean','sum'],\n    'postype_4733339M':['max'],\n    #'profession_152M':['max'],\n    'rejectreason_755M':['max'],\n    'rejectreasonclient_4145042M':['max'],\n    'revolvingaccount_394A': ['min','max','mean','sum'],\n    'status_219L': ['max'],\n    'tenor_203L': ['min','max','mean','sum'],\n    \n}\nAPPLPREV2_AGG = {\n    'num_group1':['count'],\n    'num_group2':['count'],\n    'conts_type_509L':['max'],\n    #'cacccardblochreas_147M'\n    'credacc_cards_status_52L':['max']\n    \n}\nPERSON1_AGG={\n    'num_group1':['count'],\n    'birth_259D': ['max'],\n    #'childnum_185L':['max','mean','min'],\n    'contaddr_district_15M':['max'],\n    'contaddr_matchlist_1032L':['max'],\n    'contaddr_smempladdr_334L':['max'],\n    'contaddr_zipcode_807M':['max'],\n    'education_927M':['max'],\n    'empl_employedfrom_271D':['max','mean','min'],\n    'empl_employedtotal_800L':['max'],\n    'empl_industry_691L':['max'],\n    #'empladdr_district_926M'\n    #'empladdr_zipcode_114M'\n    'familystate_447L':['max','count'],\n    #'gender_992L'\n    'housetype_905L':['max'],\n    #'housingtype_772L'\n    'incometype_1044T':['max'],\n    #'isreference_387L'\n    'language1_981M':['max'],\n    'mainoccupationinc_384A':['max','mean','min', 'count'],\n    #'maritalst_703L'\n    'personindex_1023L':['max','mean','min', 'count','sum'],\n    'persontype_1072L':['max','mean','min', 'count','sum'],\n    'persontype_792L':['max','mean','min', 'count','sum'],\n    #'registaddr_district_1083M'\n    #'registaddr_zipcode_184M'\n    'relationshiptoclient_415T':['max','count'],\n    'relationshiptoclient_642T':['max','count'],\n    'remitter_829L':['max'],\n    'role_1084L':['max','count'],\n    #'role_993L'\n    'safeguarantyflag_411L':['max'],\n    'sex_738L':['max'],\n    'type_25L':['max']\n    \n\n    \n    \n    \n}\nPERSON2_AGG={\n    'num_group1':['count'],\n    'num_group2':['count'],\n    #'addres_district_368M'\n    #'addres_role_871L'\n    #'addres_zip_823M'\n    #'conts_role_79M'\n    'empls_economicalst_849M':['max'],\n    #'empls_employedfrom_796D'\n    #'empls_employer_name_740M'\n    #'relatedpersons_role_762T'\n}\nOTHER_AGG={\n    'num_group1':['count'],\n    'amtdebitincoming_4809443A':['max','mean','min', 'count','sum'],\n    'amtdebitoutgoing_4809440A':['max','mean','min', 'count','sum'],\n    #'amtdepositbalance_4809441A'\n    #'amtdepositincoming_4809444A'\n    #'amtdepositoutgoing_4809442A'\n}\nDEBITCARD_AGG={\n    'num_group1':['count'],\n    #'last180dayaveragebalance_704A'\n    #'last180dayturnover_1134A'\n    #'last30dayturnover_651A'\n    'openingdate_857D':['min','max','mean']\n}\nTAX_REGISTRY_A_AGG={\n    'num_group1':['count'],\n    'amount_4527230A': ['max','mean','min','sum'],\n    'name_4527232M':['max'],\n    'recorddate_4527225D':['max','mean','min']\n    \n}\nTAX_REGISTRY_B_AGG={\n    'num_group1':['count'],\n    'amount_4917619A':['min','mean','max','sum'],\n    'deductiondate_4917603D':['max','mean','min'],\n    'name_4917606M':['max'],\n    \n    \n}\nTAX_REGISTRY_C_AGG={\n    'num_group1':['count'],\n    'employername_160M':['max'],\n    'pmtamount_36A':['min','mean','max','sum'],\n    'processingdate_168D':['mean','min','max'],\n\n}\nCREDIT_BUREAU_A_1_AGG={\n    \n    'num_group1':['count'],\n    #'annualeffectiverate_199L'\n    #'annualeffectiverate_63L'\n    'classificationofcontr_13M':['max'],\n    'classificationofcontr_400M':['max'],\n    'contractst_545M':['max'],\n    'contractst_964M':['max'],\n    #'contractsum_5085717L'\n    #'credlmt_230A'\n    'credlmt_935A':['max'],\n    'dateofcredend_289D':['mean','min','max'],\n    'dateofcredend_353D':['mean','min','max'],\n    'dateofcredstart_181D':['mean','min','max'],\n    'dateofcredstart_739D':['mean','min','max'],\n    'dateofrealrepmt_138D':['mean','min','max'],\n    'debtoutstand_525A':['min','mean','max','sum'],\n    'debtoverdue_47A':['min','mean','max','sum'],\n    'description_351M':['max'],\n    'dpdmax_139P':['min','mean','max','sum'],\n    #'dpdmax_757P'\n    #'dpdmaxdatemonth_442T':['max'],\n    #'dpdmaxdatemonth_89T':['max'],\n    #'dpdmaxdateyear_596T'\n    #'dpdmaxdateyear_896T'\n    'financialinstitution_382M':['max'],\n    'financialinstitution_591M':['max'],\n    'instlamount_768A':['min','mean','max','sum'],\n    #'instlamount_852A'\n    #'interestrate_508L'\n    'lastupdate_1112D':['mean','min','max'],\n    'lastupdate_388D':['mean','min','max'],\n    'monthlyinstlamount_332A':['min','mean','max','sum'],\n    #'monthlyinstlamount_674A'\n    'nominalrate_281L':['mean','min','max'],\n    #'nominalrate_498L'\n    'numberofcontrsvalue_258L':['min','mean','max','sum'],\n    'numberofcontrsvalue_358L':['min','mean','max','sum'],\n    #'numberofinstls_229L':\n    'numberofinstls_320L':['min','mean','max','sum'],\n    #'numberofoutstandinstls_520L'\n    'numberofoutstandinstls_59L':['min','mean','max','sum'],\n    'numberofoverdueinstlmax_1039L':['min','mean','max','sum'],\n    #'numberofoverdueinstlmax_1151L'\n    #'numberofoverdueinstlmaxdat_148D'\n    'numberofoverdueinstlmaxdat_641D':['mean','min','max'],\n    \n    \n      \n    'overdueamountmaxdatemonth_284T': ['min', 'mean', 'max'],\n    'overdueamountmaxdatemonth_365T': ['min', 'mean', 'max'],\n    'overdueamountmaxdateyear_2T': ['min', 'mean', 'max'],\n    'overdueamountmaxdateyear_994T': ['min', 'mean', 'max'],\n    'periodicityofpmts_1102L': ['min', 'mean', 'max'],\n    'periodicityofpmts_837L': ['min', 'mean', 'max'],\n    'prolongationcount_1120L': ['min', 'mean', 'max'],\n    'prolongationcount_599L': ['min', 'mean', 'max'],\n    'purposeofcred_426M': ['min', 'mean', 'max'],\n    'purposeofcred_874M': ['min', 'mean', 'max'],\n    'refreshdate_3813885D': ['min', 'mean', 'max'],\n    'residualamount_488A': ['min', 'mean', 'max'],\n    'residualamount_856A': ['min', 'mean', 'max'],\n   \n    'totalamount_6A': ['min', 'mean', 'max'],\n    'totalamount_996A': ['min', 'mean', 'max'],\n    'totaldebtoverduevalue_178A': ['min', 'mean', 'max'],\n    'totaldebtoverduevalue_718A': ['min', 'mean', 'max'],\n    'totaloutstanddebtvalue_39A': ['min', 'mean', 'max'],\n    'totaloutstanddebtvalue_668A': ['min', 'mean', 'max']\n   \n}\nCREDIT_BUREAU_B_1_AGG={\n    'num_group1':['count'],\n    \n}\nCREDIT_BUREAU_A_2_AGG={\n \n   \n    'pmts_dpd_1073P': ['min', 'mean', 'max'],\n    'pmts_dpd_303P': ['min', 'mean', 'max'],\n    'pmts_month_158T': ['min', 'mean', 'max'],\n    'pmts_month_706T': ['min', 'mean', 'max'],\n    'pmts_overdue_1140A': ['min', 'mean', 'max'],\n    'pmts_overdue_1152A': ['min', 'mean', 'max'],\n    'pmts_year_1139T': ['min', 'mean', 'max'],\n    'pmts_year_507T': ['min', 'mean', 'max'],\n    'subjectroles_name_541M': ['min', 'mean', 'max'],\n    'subjectroles_name_838M': ['min', 'mean', 'max'],\n    \n    \n    'num_group1':['count'],\n    'num_group2':['count']\n}\nCREDIT_BUREAU_B_2_AGG={\n    'num_group1':['count'],\n    'num_group2':['count'],\n    'pmts_date_1107D':['min', 'mean', 'max'],\n    'pmts_dpdvalue_108P':['min','mean','max'],\n    'pmts_pmtsoverdue_635A':['min','mean','max'],\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.610388Z","iopub.execute_input":"2024-04-02T19:07:44.611002Z","iopub.status.idle":"2024-04-02T19:07:44.650658Z","shell.execute_reply.started":"2024-04-02T19:07:44.610973Z","shell.execute_reply":"2024-04-02T19:07:44.649682Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **MAIN FUNCTION**\n<a id='main_function'></a>\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"code","source":"def main(debug= False):\n    num_rows = 11111 if debug else None\n    print(\"Notebook started:\")\n    if not IMPORT_DATAFRAME:\n    \n        with timer(\"base\"):\n\n            df = get_base(DATA_DIRECTORY, num_rows=num_rows)\n\n            print(\"base dataframe shape:\", df.shape)\n\n\n\n        with timer(\"static\"):\n\n            df_static = get_static(DATA_DIRECTORY, num_rows=num_rows)\n            df_static = df_static.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_static, on='case_id', how='left', suffix='_static')\n            print(\"static dataframe shape:\", df_static.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n\n            del df_static\n            gc.collect()\n        \n        with timer(\"static_cb\"):\n\n            df_static_cb = get_static_cb(DATA_DIRECTORY, num_rows=num_rows)\n            df_static_cb = df_static_cb.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_static_cb, on='case_id', how='left', suffix='_static_cb')\n            print(\"static cb dataframe shape:\", df_static_cb.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_static_cb\n            gc.collect()\n\n        with timer(\"Previous applications depth 1 test\"):\n\n            df_applprev1 = get_applprev1(DATA_DIRECTORY, num_rows=num_rows)\n            df_applprev1 = df_applprev1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_applprev1, on='case_id', how='left', suffix='_applprev1')\n            print(\"Previous applications depth 1 test dataframe shape:\", df_applprev1.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_applprev1\n            gc.collect()\n\n        with timer(\"Previous applications depth 2 test\"):\n\n            df_applprev2 = get_applprev2(DATA_DIRECTORY, num_rows=num_rows)\n            df_applprev2 = df_applprev2.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_applprev2, on='case_id', how='left', suffix='_applprev2')\n            print(\"Previous applications depth 2 test dataframe shape:\", df_applprev2.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_applprev2\n            gc.collect()\n\n        with timer(\"Person depth 1 test\"):\n\n            df_person1 = get_person1(DATA_DIRECTORY, num_rows=num_rows)\n            df_person1 = df_person1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_person1, on='case_id', how='left', suffix='_person1')\n            print(\"Person depth 1 test dataframe shape:\", df_person1.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_person1\n            gc.collect()\n\n        with timer(\"Person depth 2 test\"):\n\n            df_person2 = get_person2(DATA_DIRECTORY, num_rows=num_rows)\n            df_person2 = df_person2.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_person2, on='case_id', how='left', suffix='_person2')\n            print(\"Person depth 2 test dataframe shape:\", df_person2.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_person2\n            gc.collect()\n\n        with timer(\"Other test\"):\n\n            df_other = get_other(DATA_DIRECTORY, num_rows=num_rows)\n            df_other = df_other.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_other, on='case_id', how='left', suffix='_other')\n            print(\"Other test dataframe shape:\", df_other.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_other\n            gc.collect()\n\n        with timer(\"Debit card test\"):\n\n            df_debitcard = get_debitcard(DATA_DIRECTORY, num_rows=num_rows)\n            df_debitcard = df_debitcard.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_debitcard, on='case_id', how='left', suffix='_debitcard')\n            print(\"Debit card test dataframe shape:\", df_debitcard.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_debitcard\n            gc.collect()\n\n        with timer(\"Tax registry a test\"):\n\n            df_tax_registry_a = get_tax_registry_a(DATA_DIRECTORY, num_rows=num_rows)\n            df_tax_registry_a = df_tax_registry_a.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_tax_registry_a, on='case_id', how='left', suffix='_tax_registry_a')\n            print(\"Tax registry a test dataframe shape:\", df_tax_registry_a.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_tax_registry_a\n            gc.collect()\n\n        with timer(\"Tax registry b test\"):\n\n            df_tax_registry_b = get_tax_registry_b(DATA_DIRECTORY, num_rows=num_rows)\n            df_tax_registry_b = df_tax_registry_b.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_tax_registry_b, on='case_id', how='left', suffix='_tax_registry_b')\n            print(\"Tax registry b test dataframe shape:\", df_tax_registry_b.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_tax_registry_b\n            gc.collect()\n\n        with timer(\"Tax registry c test\"):\n\n            df_tax_registry_c = get_tax_registry_c(DATA_DIRECTORY, num_rows=num_rows)\n            df_tax_registry_c = df_tax_registry_c.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_tax_registry_c, on='case_id', how='left', suffix='_tax_registry_c')\n            print(\"Tax registry c test dataframe shape:\", df_tax_registry_c.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_tax_registry_c\n            gc.collect()\n\n        with timer(\"Credit bureau a 1 test\"):\n\n            df_credit_bureau_a_1 = get_credit_bureau_a_1(DATA_DIRECTORY, num_rows=num_rows)\n            df_credit_bureau_a_1 = df_credit_bureau_a_1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_credit_bureau_a_1, on='case_id', how='left', suffix='_cb_a_1')\n            print(\"Credit bureau a 1 test dataframe shape:\", df_credit_bureau_a_1.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_credit_bureau_a_1\n            gc.collect()\n        with timer(\"Credit bureau b 1 test\"):\n\n            df_credit_bureau_b_1 = get_credit_bureau_b_1(DATA_DIRECTORY, num_rows=num_rows)\n            df_credit_bureau_b_1 = df_credit_bureau_b_1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_credit_bureau_b_1, on='case_id', how='left', suffix='_cb_b_1')\n            print(\"Credit bureau b 1 test dataframe shape:\", df_credit_bureau_b_1.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_credit_bureau_b_1\n            gc.collect()\n\n\n\n\n        with timer(\"Credit bureau a 2 test\"):\n\n            df_credit_bureau_a_2 = get_credit_bureau_a_2(DATA_DIRECTORY, num_rows=num_rows)\n            df_credit_bureau_a_2 = df_credit_bureau_a_2.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_credit_bureau_a_2, on='case_id', how='left', suffix='_cb_a_2')\n            print(\"Credit bureau a 2 test dataframe shape:\", df_credit_bureau_a_2.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_credit_bureau_a_2\n            gc.collect()\n\n        with timer(\"Credit bureau b 2 test\"):\n\n            df_credit_bureau_b_2 = get_credit_bureau_b_2(DATA_DIRECTORY, num_rows=num_rows)\n            df_credit_bureau_b_2 = df_credit_bureau_b_2.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_credit_bureau_b_2, on='case_id', how='left', suffix='_cb_b_2')\n            print(\"Credit bureau b 2 test dataframe shape:\", df_credit_bureau_b_2.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_credit_bureau_b_2\n            gc.collect()\n\n\n        with timer(\"Feature engineering / preprocessing\"): \n\n            df=feature_engineering(df)\n            get_info(df)\n            df_pandas, cat_cols = to_pandas(df)\n            del df;gc.collect()\n            df=df_pandas\n            #df=reduce_mem_usage(df)\n            print(\"DATAFRAME shape:\", df.shape)\n    else:\n        with timer(\"Importing processed dataframe\"):\n            \n\n            \n            df = pd.read_parquet(\"/kaggle/input/home-credit-2024-additional-dataset/processed_001_std.parquet\")\n\n            \n            for col in df.select_dtypes(exclude=['number']).columns:\n                df[col] = df[col].astype('category')\n            print(df.dtypes.value_counts())\n            #df=reduce_mem_usage(df)\n           \n            print(\"DATAFRAME shape:\", df.shape)\n    \n    if EXPORT_DATAFRAME:\n        with timer(\"Export dataframe\"):\n            df.to_parquet(\"/kaggle/working/processed_debug.parquet\", index=False)\n            \n            \n            print(\"NOTEBOOK HAS BEEN SUCCESSFULLY EXECUTED !!!\")\n            return\n    \n    if(SELECTKBEST):\n        with timer(\"SelectKBest feature research\"):\n            \n            selectkbestX(df)\n            print(\"NOTEBOOK HAS BEEN SUCCESSFULLY EXECUTED !!!\")\n            return\n\n    with timer(\"Model training\"):\n       \n        \n        del_features = ['target', 'case_id','WEEK_NUM']\n        predictors = list(filter(lambda v: v not in del_features, df.columns))\n        cat_cols = list(df.select_dtypes(\"object\").columns)\n        model = kfold_lightgbm_sklearn(df, cat_cols)\n       \n        \n\n    \n    \n    #with timer(\"Feature importance assesment\"):\n        \n     #   get_features_importances(predictors, model)\n        \n        \n    \n        \n    with timer(\"Submission\"):\n\n        if  GENERATE_SUBMISSION_FILES:\n            \n            if generate_submission_file(df, model):\n\n\n                print(\"Submission file has been created.\")\n            \n    \n    print(\"NOTEBOOK HAS BEEN SUCCESSFULLY EXECUTED !!!\")\n    \n    return df, model\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.653088Z","iopub.execute_input":"2024-04-02T19:07:44.653651Z","iopub.status.idle":"2024-04-02T19:07:44.700534Z","shell.execute_reply.started":"2024-04-02T19:07:44.653622Z","shell.execute_reply":"2024-04-02T19:07:44.698726Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# **UTILITY FUNCTIONS**","metadata":{}},{"cell_type":"markdown","source":"### Pipeline","metadata":{}},{"cell_type":"code","source":"class Pipeline:\n    @staticmethod\n    \n    \n    # Sets datatypes accordingly\n    def set_table_dtypes(df):\n        for col in df.columns:\n            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Int64))\n            elif col in [\"date_decision\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Date))\n            elif col[-1] in (\"P\", \"A\"):\n                df = df.with_columns(pl.col(col).cast(pl.Float64))\n            elif col[-1] in (\"M\",):\n                df = df.with_columns(pl.col(col).cast(pl.String))\n            elif col[-1] in (\"D\",):\n                df = df.with_columns(pl.col(col).cast(pl.Date))            \n\n        return df\n    \n    \n    # Changes the values of all date columns. The result will not be a date but number of days since date_decision.\n    @staticmethod\n    def handle_dates(df):\n        for col in df.columns:\n            if col[-1] in (\"D\",):\n                \n                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n                df = df.with_columns(pl.col(col).dt.total_days())\n                \n        df = df.drop(\"date_decision\", \"MONTH\")\n\n        return df\n    \n    # It drops columns with a lot of NaN values.\n    @staticmethod\n    def filter_cols(df):\n        for col in df.columns:\n            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n                isnull = df[col].is_null().mean()\n\n                if isnull > 0.95:\n                    df = df.drop(col)\n\n        for col in df.columns:\n            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n                freq = df[col].n_unique()\n\n                if (freq == 1) | (freq > 200):\n                    df = df.drop(col)\n\n        return df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.702402Z","iopub.execute_input":"2024-04-02T19:07:44.702753Z","iopub.status.idle":"2024-04-02T19:07:44.718883Z","shell.execute_reply.started":"2024-04-02T19:07:44.702718Z","shell.execute_reply":"2024-04-02T19:07:44.717340Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_info(dataframe):\n    \"\"\"\n    View data types, shape, and calculate the percentage of NaN (missing) values in each column\n    of a Polars DataFrame simultaneously.\n    \n    Parameters:\n    dataframe (polars.DataFrame): The DataFrame to analyze.\n    \n    Returns:\n    None\n    \"\"\"\n    # Print DataFrame shape\n    print(\"DataFrame Shape:\", dataframe.shape)\n    print(\"-\" * 60)\n    \n    # Print column information\n    print(\"{:<50} {:<30} {:<20}\".format(\"Column Name\", \"Data Type\", \"NaN Percentage\"))\n    print(\"-\" * 60)\n    \n    # Total number of rows in the DataFrame\n    total_rows = len(dataframe)\n    \n    # Iterate over each column\n    for column in dataframe.columns:\n        # Get the data type of the column\n        dtype = str(dataframe[column].dtype)\n        \n        # Count the number of NaN values in the column\n        nan_count = dataframe[column].null_count()\n        \n        # Calculate the percentage of NaN values\n        nan_percentage = (nan_count / total_rows) * 100\n        \n        # Print the information\n        print(\"{:<50} {:<30} {:.2f}%\".format(column, dtype, nan_percentage))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.720795Z","iopub.execute_input":"2024-04-02T19:07:44.722023Z","iopub.status.idle":"2024-04-02T19:07:44.737326Z","shell.execute_reply.started":"2024-04-02T19:07:44.721975Z","shell.execute_reply":"2024-04-02T19:07:44.736091Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def to_pandas(df_data, cat_cols=None):\n    df_data = df_data.to_pandas()\n    \n    if cat_cols is None:\n        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n    \n    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n    \n    return df_data, cat_cols","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.738968Z","iopub.execute_input":"2024-04-02T19:07:44.739483Z","iopub.status.idle":"2024-04-02T19:07:44.752201Z","shell.execute_reply.started":"2024-04-02T19:07:44.739443Z","shell.execute_reply":"2024-04-02T19:07:44.751135Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.753677Z","iopub.execute_input":"2024-04-02T19:07:44.754259Z","iopub.status.idle":"2024-04-02T19:07:44.769021Z","shell.execute_reply.started":"2024-04-02T19:07:44.754216Z","shell.execute_reply":"2024-04-02T19:07:44.768030Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.770528Z","iopub.execute_input":"2024-04-02T19:07:44.770911Z","iopub.status.idle":"2024-04-02T19:07:44.785806Z","shell.execute_reply.started":"2024-04-02T19:07:44.770882Z","shell.execute_reply":"2024-04-02T19:07:44.784412Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n    \n\n    temp=base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]] \\\n        .sort_values(\"WEEK_NUM\") \\\n        .groupby(\"WEEK_NUM\").mean()\n   \n    week_nums_to_drop = temp[(temp[\"target\"] == 0) | (temp[\"target\"] == 1)].index.tolist()\n\n    base_filtered = base[~base[\"WEEK_NUM\"].isin(week_nums_to_drop)]\n\n    # Apply the aggregator\n    gini_in_time = base_filtered.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]] \\\n        .sort_values(\"WEEK_NUM\") \\\n        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]] \\\n        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n\n    \n\n    x = np.arange(len(gini_in_time))\n    y = gini_in_time\n    a, b = np.polyfit(x, y, 1)\n    y_hat = a * x + b\n    residuals = y - y_hat\n    res_std = np.std(residuals)\n    avg_gini = np.nanmean(gini_in_time)  # Use np.nanmean to handle NaN values\n    \n    if SHOW_REPORT:\n        # Display the plot of x on y\n        plt.figure(figsize=(8, 6))\n        plt.plot(x, y, 'o', label='Gini in Time')\n        plt.plot(x, y_hat, '-', label='Fitted line (slope={:.2f}, intercept={:.2f})'.format(a, b))\n        plt.xlabel('Week')\n        plt.ylabel('Gini in Time')\n        plt.title('Gini Stability Over Time')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n    \n    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.792579Z","iopub.execute_input":"2024-04-02T19:07:44.793749Z","iopub.status.idle":"2024-04-02T19:07:44.808717Z","shell.execute_reply.started":"2024-04-02T19:07:44.793705Z","shell.execute_reply":"2024-04-02T19:07:44.807257Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Report function","metadata":{}},{"cell_type":"code","source":"'''\ndef make_report(num_rows, predictors, model):\n    # 1. time\n    current_time = datetime.now()\n    # Print the current time\n    print(\"Current Time:\", current_time)\n    \n    # 2. specification\n    if not num_rows:\n        print(\"The notebook was run in full mode.\")\n    else:\n        print(\"The notebook was run in debug mode. Number of rows: \" + str(num_rows))\n    \n    # 3. features\n    feat_importances_df = model.get_features_importances_df(predictors)\n    feat_importances_df['gain'] = feat_importances_df['gain'].round(0)\n    print(feat_importances_df.shape)\n    \n    predictions = pd.Series(model.get_predictions())\n   \n    numerical_columns = data.select_dtypes(include=['int', 'float']).columns\n\n    # Compute correlations of each numerical column with 'PREDICTIONS'\n    correlations = {}\n    \n    # Compute correlations of each numerical column with 'feat'\n    for column in numerical_columns:\n        correlations[column] = predictions.corr(data[column])\n\n    # Create a new DataFrame with 'features' and 'correlation' columns\n    correlation_df = pd.DataFrame(list(correlations.items()), columns=['features', 'correlation'])\n\n    # Round the correlation numbers to three decimal places\n    correlation_df['correlation'] = correlation_df['correlation'].round(3)\n\n    # Merge feat_importances_df and correlation_df on 'feature'\n    combined_df = pd.merge(feat_importances_df, correlation_df, left_on=\"feature\", right_on='features', how='left')\n\n    # Handle categorical features with no correlation\n    combined_df['correlation'] = combined_df['correlation'].fillna(value=np.nan)\n    \n\n    # Compute and add valid percentage for each feature\n    valid_percentage = (data[0:-10].count() / len(data[0:-10]))\n    valid_percentage = valid_percentage.round(3)\n    combined_df['valid_percentage'] = combined_df['feature'].map(valid_percentage)\n\n    # Print the combined_df DataFrame\n    print(combined_df.to_string(index=False))\n    print()\n    roc_score=roc_auc_score(data['target'][0:-10],predictions)\n    print(\"ROC score: \",roc_score)\n\n    # Compute false positive rate, true positive rate, and thresholds for ROC curve\n    fpr, tpr, thresholds = roc_curve(data['target'][0:-10], predictions)\n\n    # Plot ROC curve\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_score)\n    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    plt.show()\n'''","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.810699Z","iopub.execute_input":"2024-04-02T19:07:44.811649Z","iopub.status.idle":"2024-04-02T19:07:44.831159Z","shell.execute_reply.started":"2024-04-02T19:07:44.811603Z","shell.execute_reply":"2024-04-02T19:07:44.829488Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'\\ndef make_report(num_rows, predictors, model):\\n    # 1. time\\n    current_time = datetime.now()\\n    # Print the current time\\n    print(\"Current Time:\", current_time)\\n    \\n    # 2. specification\\n    if not num_rows:\\n        print(\"The notebook was run in full mode.\")\\n    else:\\n        print(\"The notebook was run in debug mode. Number of rows: \" + str(num_rows))\\n    \\n    # 3. features\\n    feat_importances_df = model.get_features_importances_df(predictors)\\n    feat_importances_df[\\'gain\\'] = feat_importances_df[\\'gain\\'].round(0)\\n    print(feat_importances_df.shape)\\n    \\n    predictions = pd.Series(model.get_predictions())\\n   \\n    numerical_columns = data.select_dtypes(include=[\\'int\\', \\'float\\']).columns\\n\\n    # Compute correlations of each numerical column with \\'PREDICTIONS\\'\\n    correlations = {}\\n    \\n    # Compute correlations of each numerical column with \\'feat\\'\\n    for column in numerical_columns:\\n        correlations[column] = predictions.corr(data[column])\\n\\n    # Create a new DataFrame with \\'features\\' and \\'correlation\\' columns\\n    correlation_df = pd.DataFrame(list(correlations.items()), columns=[\\'features\\', \\'correlation\\'])\\n\\n    # Round the correlation numbers to three decimal places\\n    correlation_df[\\'correlation\\'] = correlation_df[\\'correlation\\'].round(3)\\n\\n    # Merge feat_importances_df and correlation_df on \\'feature\\'\\n    combined_df = pd.merge(feat_importances_df, correlation_df, left_on=\"feature\", right_on=\\'features\\', how=\\'left\\')\\n\\n    # Handle categorical features with no correlation\\n    combined_df[\\'correlation\\'] = combined_df[\\'correlation\\'].fillna(value=np.nan)\\n    \\n\\n    # Compute and add valid percentage for each feature\\n    valid_percentage = (data[0:-10].count() / len(data[0:-10]))\\n    valid_percentage = valid_percentage.round(3)\\n    combined_df[\\'valid_percentage\\'] = combined_df[\\'feature\\'].map(valid_percentage)\\n\\n    # Print the combined_df DataFrame\\n    print(combined_df.to_string(index=False))\\n    print()\\n    roc_score=roc_auc_score(data[\\'target\\'][0:-10],predictions)\\n    print(\"ROC score: \",roc_score)\\n\\n    # Compute false positive rate, true positive rate, and thresholds for ROC curve\\n    fpr, tpr, thresholds = roc_curve(data[\\'target\\'][0:-10], predictions)\\n\\n    # Plot ROC curve\\n    plt.figure(figsize=(8, 6))\\n    plt.plot(fpr, tpr, color=\\'blue\\', lw=2, label=\\'ROC curve (AUC = %0.2f)\\' % roc_score)\\n    plt.plot([0, 1], [0, 1], color=\\'gray\\', linestyle=\\'--\\')\\n    plt.xlim([0.0, 1.0])\\n    plt.ylim([0.0, 1.05])\\n    plt.xlabel(\\'False Positive Rate\\')\\n    plt.ylabel(\\'True Positive Rate\\')\\n    plt.title(\\'Receiver Operating Characteristic (ROC) Curve\\')\\n    plt.legend(loc=\"lower right\")\\n    plt.grid(True)\\n    plt.show()\\n'"},"metadata":{}}]},{"cell_type":"code","source":"def group(df_to_agg, prefix, aggregations, aggregate_by='case_id', datatype='polars'):\n    # Create a dictionary mapping aggregation functions to their string representations\n    \n    if datatype=='polars':\n        func_mapping = {\n        'min': pl.min,\n        'max': pl.max,\n        'mean': pl.mean,\n        'sum': pl.sum,\n        'count': pl.count,\n         'median': pl.median\n        }\n\n    # Perform the aggregation\n        agg_df = df_to_agg.group_by(aggregate_by).agg(**{\n            f\"{func}_{col}\": func_mapping[func](col) for col, funcs in aggregations.items() for func in funcs\n        })\n        '''\n        # Rename columns\n        for col, funcs in aggregations.items():\n            for func in funcs:\n                old_name = f\"{col}_{func}\"\n                new_name = f\"{prefix}{col}_{func.upper()}\"\n                agg_df = agg_df.select(pl.col(old_name).alias(new_name))\n        '''\n        return agg_df\n    \n    if datatype=='pandas':\n            # Create a dictionary mapping aggregation functions to their string representations\n        func_mapping = {\n            'min': 'min',\n            'max': 'max',\n            'mean': 'mean',\n            'sum': 'sum',\n            'count': 'count',\n            \n        }\n\n        # Perform the aggregation\n        agg_df = df_to_agg.groupby(aggregate_by).agg(**{\n            f\"{prefix}{col}_{func.upper()}\": (col, func_mapping[func]) for col, funcs in aggregations.items() for func in funcs\n        }).reset_index()\n        \n        return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.833228Z","iopub.execute_input":"2024-04-02T19:07:44.833633Z","iopub.status.idle":"2024-04-02T19:07:44.847100Z","shell.execute_reply.started":"2024-04-02T19:07:44.833598Z","shell.execute_reply":"2024-04-02T19:07:44.845503Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# **SELECTKBEST METHOD**","metadata":{}},{"cell_type":"code","source":"def preprocessingX(data):\n    \n        \n\n        def one_hot_encode(data):\n            \n            \n            original_columns = list(data.columns)\n            categories = [cat for cat in data.columns if data[cat].dtype == 'category']\n            df = pd.get_dummies(data, columns= categories, dummy_na= True) #one_hot_encode the categorical features\n            categorical_columns = [cat for cat in df.columns if cat not in original_columns]\n            return df, categorical_columns\n        \n        \n        df,categorical_columns=one_hot_encode(data)\n        del data;gc.collect()\n        \n        total_nan_count = df.isna().sum().sum()\n\n        print(\"Total count of NaN values in the DataFrame:\", total_nan_count)\n        for column in (set(df.columns)-{'target'}):\n            # Calculate the mean value of the column excluding NaNs\n            \n            df[column]=df[column].fillna(0)\n           \n\n        total_nan_count = df.isna().sum().sum()\n\n        print(\"Total count of NaN values in the DataFrame:\", total_nan_count)\n\n        return df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.849017Z","iopub.execute_input":"2024-04-02T19:07:44.849522Z","iopub.status.idle":"2024-04-02T19:07:44.863630Z","shell.execute_reply.started":"2024-04-02T19:07:44.849475Z","shell.execute_reply":"2024-04-02T19:07:44.862223Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def selectkbestX(data):\n    #########################################################################################\n    \n    #########################################################################################\n    def selectkbest_base(X_train, y_train):\n        \n        # Define SelectKBest with desired parameters\n        k = 500  # Number of top features to select\n        S = SelectKBest(score_func=f_classif, k=k)\n\n        # Fit SelectKBest on training data and transform features\n        X_train_k_best = S.fit_transform(X_train, y_train)\n\n        # Get scores assigned to each feature\n        feature_scores = S.scores_\n        \n        # Create a DataFrame to store feature names and their scores\n        feature_scores_df = pd.DataFrame({'Feature': X_train.columns, 'Score': feature_scores})\n\n        # Sort DataFrame by scores in descending order\n        #feature_scores_df_sorted = feature_scores_df.sort_values(by='Score', ascending=False)\n\n        # Print the table of top features and their scores\n      \n        # Return DataFrame with feature names and their scores\n        return feature_scores_df\n    #########################################################################################\n    \n    \n    df=preprocessingX(data)\n    del data;gc.collect()\n    \n    \n    \n    \n   \n    N_CHUNKS=5\n    df.drop(df[df['target'].isnull()].index, inplace=True)\n    \n   \n    del_features = ['target', 'case_id']\n    predictors = [col for col in df.columns if col not in del_features]\n    \n    feats_df = pd.DataFrame({'feature': predictors}, columns=['feature'])\n    \n    results=[]\n    \n    with tqdm(total=N_CHUNKS) as pbar:\n        for i in range(N_CHUNKS):\n\n            sub_df = df[df.index % N_CHUNKS == i]\n            df.drop(df.index[df.index % N_CHUNKS == i], inplace=True)\n            X_train=sub_df[predictors]\n            y_train=sub_df['target']\n\n\n            result_df=selectkbest_base(X_train, y_train)\n            \n            del sub_df\n            gc.collect()\n\n            results.append(result_df)\n            pbar.update(1)\n            \n    del df; gc.collect()\n    merged_df = results[0]\n\n# Merge the remaining dataframes horizontally on the 'Feature' column\n    for df_index in range(1, len(results)):\n        suffix = '_' + str(df_index)  # Add a suffix to distinguish overlapping column names\n        merged_df = pd.merge(merged_df, results[df_index], on='Feature', suffixes=('', suffix))\n\n    merged_df.rename(columns={'Score': 'Score_0'}, inplace=True)\n    merged_df['mean_score'] = 0\n    \n    for i in range(N_CHUNKS):\n        merged_df['mean_score']+=merged_df[\"Score_\"+str(i)]\n    \n    \n    final_df=merged_df[['Feature', 'mean_score']]\n    final_df = final_df.sort_values(by='mean_score', ascending=False)\n    pd.set_option('display.max_rows', None)  # Show all rows\n# Display the DataFrame\n    print(final_df)\n   \n\n    final_df.to_csv(\"/kaggle/working/SelectKBest.csv\")\n    \n    return merged_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.865542Z","iopub.execute_input":"2024-04-02T19:07:44.865928Z","iopub.status.idle":"2024-04-02T19:07:44.884300Z","shell.execute_reply.started":"2024-04-02T19:07:44.865895Z","shell.execute_reply":"2024-04-02T19:07:44.882960Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"#  **MODEL** <a id='model'></a>\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"code","source":"class VotingModel(BaseEstimator, RegressorMixin):\n    def __init__(self, estimators):\n        super().__init__()\n        self.estimators = estimators\n        \n        \n    def fit(self, X, y=None):\n        return self\n    \n    def predict(self, X):\n        y_preds = [estimator.predict(X) for estimator in self.estimators]\n        return np.mean(y_preds, axis=0)\n    \n    def predict_proba(self, X):\n        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n        # Use tqdm to create a progress bar during the prediction\n        with tqdm(total=len(self.estimators), desc=\"Predicting\", unit=\" models\") as pbar:\n            for i, estimator in enumerate(self.estimators):\n                y_preds[i] = estimator.predict_proba(X)\n                pbar.update(1)  # Update the progress bar\n        return np.mean(y_preds, axis=0)\n\n    \n    def get_splits(self, aggregation_method=np.mean):\n        \n        feature_importances_list=[]\n        for x in self.estimators:\n            feature_importances_list.append(x.feature_importance(importance_type='split'))\n            \n        # Aggregate feature importances across all models\n        if all(importances is not None for importances in feature_importances_list):\n            combined_importances = aggregation_method(feature_importances_list, axis=0)\n        else:\n            combined_importances = None   \n        return combined_importances\n    \n    \n    def get_gains(self, aggregation_method=np.mean):\n        \n        feature_importances_list=[]\n        for model in self.estimators:\n            feature_importances_list.append(x.feature_importance(importance_type='gain'))\n            \n        # Aggregate feature importances across all models\n        if all(importances is not None for importances in feature_importances_list):\n            combined_importances = aggregation_method(feature_importances_list, axis=0)\n        else:\n            combined_importances = None\n              \n        return combined_importances\n    \n    def get_features_importances_df(self, predictors):\n        \n        \n        importance_df = pd.DataFrame()\n        eval_results = dict()\n        for model in self.estimators:\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = predictors\n            fold_importance[\"gain\"] = model.feature_importance(importance_type='gain')\n            fold_importance[\"split\"] = model.feature_importance(importance_type='split')\n            importance_df = pd.concat([importance_df, fold_importance], axis=0)\n            importance_df= importance_df.groupby('feature').mean().reset_index()\n        return importance_df\n    \n    \n    def add_predictions(self, predictions):\n        self.predictions=predictions\n        \n    def get_predictions(self):\n        return self.predictions\n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.885868Z","iopub.execute_input":"2024-04-02T19:07:44.886581Z","iopub.status.idle":"2024-04-02T19:07:44.906799Z","shell.execute_reply.started":"2024-04-02T19:07:44.886547Z","shell.execute_reply":"2024-04-02T19:07:44.905152Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def kfold_lightgbm_sklearn(data, categorical_feature = None):\n    \n    \n    \n   \n    #time.sleep(30)\n    start_time = time.time()\n    \n    \n    \n    numerical_columns = data.select_dtypes(include=['number']).columns\n\n    for column in numerical_columns:\n        min_value = data[column].min()\n        max_value = data[column].max()\n        print(f\"Column: {column}, Min Value: {min_value}, Max Value: {max_value}\")\n        \n    df=data.copy()\n    df.drop(df[df['target'].isnull()].index, inplace=True)\n    #test=data.copy()\n    #test.drop(test[test['target'].notnull()].index, inplace=True)\n    del data; gc.collect()\n    \n    print(\"shape before preprocessing\", df.shape)\n    df=preprocessingX(df)\n    print(\"shape after preprocessing\", df.shape)\n \n \n    \n    \n  \n\n \n    \n   \n    \n    df=reduce_mem_usage(df)\n   \n    print(\"Train/valid shape: {}, \".format(df.shape))\n    del_features = ['target', 'case_id', 'WEEK_NUM']\n    predictors = list(filter(lambda v: v not in del_features, df.columns))\n\n    if not STRATIFIED_KFOLD:\n        folds = KFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n    else:\n        folds = StratifiedKFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n    \n        # Hold oof predictions, test predictions, feature importance and training/valid auc\n    oof_preds = np.zeros(df.shape[0])\n    \n    importance_df = pd.DataFrame()\n    eval_results = dict()\n    \n    fitted_models = []\n    \n    \n    \n    \n    \n    \n    with tqdm(total=NUM_FOLDS) as pbar:\n        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[predictors], df['target'])):\n           \n          \n            train_x, train_y = df[predictors].iloc[train_idx], df['target'].iloc[train_idx]\n            valid_x, valid_y = df[predictors].iloc[valid_idx], df['target'].iloc[valid_idx]\n            \n            \n          \n            param_grid = {\n    'n_estimators': [25, 50, 100, 300, 500],  # Varying the number of trees\n    'max_depth': [None, 10, 20, 30, 40, 50]  # Varying the maximum depth of each tree\n}\n            #time.sleep(30)\n            params = {'random_state': RANDOM_SEED}\n            clf = RandomForestClassifier(**{**params, **RF_PARAMS})\n\n          \n           \n \n            clf.fit(train_x, train_y)\n\n\n            fitted_models.append(clf)\n\n            if EVALUATE_VALIDATION_SET:\n                oof_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n\n\n                # Feature importance by GAIN and SPLIT\n\n            #eval_results['train_{}'.format(n_fold+1)]  = clf.evals_result_['training']['auc']\n            #eval_results['valid_{}'.format(n_fold+1)] = clf.evals_result_['valid_1']['auc']\n\n            elapsed_time = time.time() - start_time\n            remaining_time = elapsed_time * (NUM_FOLDS - n_fold - 1) / (n_fold + 1)\n            print('Fold %2d AUC : %.6f. Elapsed time: %.2f seconds. Remaining time: %.2f seconds.'\n                  % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx]), elapsed_time, remaining_time))\n            del clf, train_x, train_y, valid_x, valid_y\n            gc.collect()\n            pbar.update(1)\n            \n    print('Full AUC score %.6f' % roc_auc_score(df['target'], oof_preds))\n    # Get the average feature importance between folds\n    \n    \n    \n    if len(df)>0:\n        base=get_base(DATA_DIRECTORY, len(df))\n        base, cat_cols = to_pandas(base)\n        base=base[base['target'].notnull()]\n        base['score']= oof_preds\n        gini_score = gini_stability(base)\n        print(\"Gini Score of the valid set:\", gini_score)\n    \n    \n    \n    \n    # Save feature importance, test predictions and oof predictions as csv\n    \n        \n        \n  \n        \n        \n    model = VotingModel(fitted_models)\n    if GENERATE_SUBMISSION_FILES:\n        \n\n\n            # Generate oof csv\n            oof = pd.DataFrame()\n            oof['case_id'] = df['case_id'].copy()\n            df['PREDICTIONS'] = oof_preds.copy()\n            df['target'] = df['target'].copy()\n            df.to_csv('oof{}.csv'.format(SUBMISSION_SUFIX), index=False)\n    model.add_predictions(oof_preds.copy())\n    del df; gc.collect()\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.908693Z","iopub.execute_input":"2024-04-02T19:07:44.909160Z","iopub.status.idle":"2024-04-02T19:07:44.934797Z","shell.execute_reply.started":"2024-04-02T19:07:44.909125Z","shell.execute_reply":"2024-04-02T19:07:44.933503Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# **SUBMISSION**","metadata":{}},{"cell_type":"code","source":"def generate_submission_file(data, model):\n    test=data.copy()\n    test.drop(test[test['target'].notnull()].index, inplace=True)\n    del data;gc.collect()\n\n    '''\n    length=len(test)\n    y_pred = pd.Series([0.5] * length,index=test['case_id'])\n    df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n    df_subm = df_subm.set_index(\"case_id\")\n    df_subm[\"score\"] = y_pred\n    df_subm.to_csv(\"submission.csv\")\n    '''\n    test=preprocessingX(test)\n    del_features = ['target', 'case_id','WEEK_NUM']\n    predictors = list(filter(lambda v: v not in del_features, test.columns))\n    y_pred = pd.Series(model.predict_proba(test[predictors])[:, 1], index=test['case_id']) \n\n    df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n    df_subm = df_subm.set_index(\"case_id\")\n    df_subm[\"score\"] = y_pred\n\n    df_subm.to_csv(\"submission.csv\")\n    \n    return True\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.936773Z","iopub.execute_input":"2024-04-02T19:07:44.938255Z","iopub.status.idle":"2024-04-02T19:07:44.950785Z","shell.execute_reply.started":"2024-04-02T19:07:44.938219Z","shell.execute_reply":"2024-04-02T19:07:44.949255Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# **EVALUATE FEATURES IMPORTANCES**","metadata":{}},{"cell_type":"code","source":"def get_features_importances(predictors, model):\n    importance_df = model.get_features_importances_df(predictors)\n    mean_importance = importance_df.groupby('feature').mean().reset_index()\n    mean_importance.to_csv('feature_importance{}.csv'.format(SUBMISSION_SUFIX), index=False)\n    mean_importance.sort_values(by= 'gain', ascending=False, inplace=True)\n    mean_importance.to_csv('feature_importance_gain{}.csv'.format(SUBMISSION_SUFIX), index=False)\n    mean_importance.sort_values(by= 'split', ascending=False, inplace=True)\n    mean_importance.to_csv('feature_importance_split{}.csv'.format(SUBMISSION_SUFIX), index=False)\n    return True","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.952848Z","iopub.execute_input":"2024-04-02T19:07:44.953616Z","iopub.status.idle":"2024-04-02T19:07:44.961847Z","shell.execute_reply.started":"2024-04-02T19:07:44.953574Z","shell.execute_reply":"2024-04-02T19:07:44.960685Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# **FEATURE ENGINEERING FUNCTION**","metadata":{}},{"cell_type":"code","source":"def feature_engineering(df):\n    \n    \n    \n    df=df.pipe(Pipeline.handle_dates) \n    #df=df.pipe(Pipeline.filter_cols)\n    \n    '''\n     data['CREDIT_INCOME_PERCENT'] = data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n                                    final credit amount on the previous application./Income of the client\n    \n    \n    credamount_590A/byoccupationinc_3656910L\n    '''\n    \n    \n    columns_to_add = [\n        (pl.col(\"days30_165L\")/ pl.col(\"days360_512L\")).alias(\"ratio_queries_30\"),\n        ((pl.col(\"days90_310L\") / pl.col(\"days360_512L\")).alias(\"ratio_queries_90\")),\n        ((pl.col(\"days120_123L\") / pl.col(\"days360_512L\")).alias(\"ratio_queries_120\")),\n        ((pl.col(\"days180_256L\") / pl.col(\"days360_512L\")).alias(\"ratio_queries_180\")),\n        \n        \n        ((pl.col(\"credamount_770A\") / pl.col(\"max_mainoccupationinc_437A\")).alias(\"CREDIT_INCOME_PERCENT\")),\n        ((pl.col(\"annuity_780A\") / pl.col(\"max_mainoccupationinc_437A\")).alias(\"ANNUITY_INCOME_PERCENT\")),\n        ((pl.col(\"credamount_770A\") / pl.col(\"annuity_780A\")).alias(\"CREDIT_ANNUITY_PERCENT\")),\n        \n        ((pl.col(\"annuity_780A\") / pl.col(\"credamount_770A\")).alias(\"CREDIT_TERM\")),\n       # ((pl.col(\"max_mainoccupationinc_437A\") / pl.col(\"childnum_21L\")).alias(\"CHILDREN_CNT_INCOME_PERCENT\")),\n        \n        #data['ANNUITY_LENGTH_EMPLOYED_PERCENT'] = data['CREDIT_TERM']/ data['DAYS_EMPLOYED']\n        ((pl.col(\"CREDIT_TERM\") / pl.col(\"max_empl_employedfrom_271D\")).alias(\"ANNUITY_LENGTH_EMPLOYED_PERCENT\")),\n        \n        #data['PHONE_CHANGE_EMP_PERCENT'] = data['DAYS_LAST_PHONE_CHANGE']/data['DAYS_EMPLOYED']\n        \n        \n        \n        #((pl.col(\"credamount_590A\") / pl.col(\"byoccupationinc_3656910L\")).alias(\"credit_income_percent\")),\n        \n        \n        \n        #((pl.col(\"collater_typofvalofguarant_298M\") + pl.col(\"collater_typofvalofguarant_407M\")).alias(\"sum_collater\")),\n        #((pl.col(\"collater_typofvalofguarant_298M\") + pl.col(\"sum_collater\"))).alias(\"ratio_collater_active\")),\n        #((pl.col(\"collater_typofvalofguarant_407M\") + pl.col(\"sum_collater\"))).alias(\"ratio_collater_close\")),\n        #((pl.col(\"overdueamount_31A\") + pl.col(\"overdueamount_659A\")).alias(\"sum_overdue_amount\")),\n        #((pl.col(\"overdueamount_31A\") / pl.col(\"sum_overdue_amount\")).alias(\"ratio_overdue_amount_active\")),\n        #((pl.col(\"overdueamount_659A\") / pl.col(\"sum_overdue_amount\")).alias(\"ratio_overdue_amount_close\")),\n        #((pl.col(\"overdueamount_31A\") / pl.col(\"total_overdue_amount\")).alias(\"ratio_overdue_amount_active\")),\n        #((pl.col(\"overdueamount_659A\") / pl.col(\"total_overdue_amount\")).alias(\"ratio_overdue_amount_close\")),\n        #((pl.col(\"totalamount\")).alias(\"sum_totalcredit_contract\")),\n        #((pl.col(\"totalamount_503A\") / pl.col(\"sum_totalcredit_contract\")).alias(\"ratio_totalcredit_contract_active\")),\n        #((pl.col(\"totalamount_6A\") / pl.col(\"sum_totalcredit_contract\")).alias(\"ratio_totalcredit_contract_close\")),\n        #((pl.col(\"totaldebtoverduevalue_178A\") / pl.col(\"totaldebt_9A\")).alias(\"ratio_overdue_debt_active\")),\n        #((pl.col(\"totaldebtoverduevalue_718A\") / pl.col(\"totaldebt_9A\")).alias(\"ratio_overdue_debt_close\")),\n        #((pl.col(\"numberofinstls_229L\") + pl.col(\"numberofinstls_320L\")).alias(\"sum_instalments\")),\n        #((pl.col(\"numberofinstls_320L\") / pl.col(\"sum_instalments\")).alias(\"ratio_instalments_active\")),\n        #((pl.col(\"numberofinstls_229L\") / pl.col(\"sum_instalments\")).alias(\"ratio_instalments_close\"))\n    ]\n\n# Add the calculated columns to the DataFrame\n\n    \n    for column in columns_to_add:\n        df = df.with_columns([column])\n        \n    new_cols=[\"ratio_queries_30\",\"ratio_queries_90\",\"ratio_queries_120\",\"ratio_queries_180\",\"CREDIT_INCOME_PERCENT\",\n                       \"ANNUITY_INCOME_PERCENT\",\"CREDIT_ANNUITY_PERCENT\",\"CREDIT_TERM\",\"CHILDREN_CNT_INCOME_PERCENT\",\n                        \"ANNUITY_LENGTH_EMPLOYED_PERCENT\"]\n    for column_name in new_cols:\n        if column_name in df.columns:\n            df=df.with_columns(\n            pl.when(pl.col(column_name).is_infinite())\n            .then(None)\n            .otherwise(pl.col(column_name))\n            .keep_name()\n        )\n\n        \n    '''\n    df = df.with_columns(\n    'ratio_queries_30',\n    df['days30_165L'] / df['days360_512L']\n)\n    df['ratio_queries_90'] = df['days90_310L'] / df['days360_512L']\n    df['ratio_queries_120'] = df['days120_123L'] / df['days360_512L']\n    df['ratio_queries_180'] = df['days180_256L'] / df['days360_512L']\n    df['sum_collater'] = df['collater_typofvalofguarant_298M'] +    df['collater_typofvalofguarant_407M']\n    df['ratio_collater_active'] = df['collater_typofvalofguarant_298M'] +    df['sum_collater']\n    df['ratio_collater_close'] = df['collater_typofvalofguarant_407M'] +    df['sum_collater']\n    df['sum_overdue_amount'] = df['overdueamount_31A'] +    df['overdueamount_659A']\n    df['ratio_overdue_amount_active'] = df['overdueamount_31A'] /    df['sum_overdue_amount']\n    df['ratio_overdue_amount_close'] = df['overdueamount_659A'] /    df['sum_overdue_amount']\n    df['ratio_overdue_amount_active'] = df['overdueamount_31A'] /    df['total_overdue_amount']\n    df['ratio_overdue_amount_close'] = df['overdueamount_659A'] /    df['total_overdue_amount']\n    df['sum_totalcredit_contract'] = df['totalamount']\n    df['ratio_totalcredit_contract_active'] = df['totalamount_503A'] /    df['sum_totalcredit_contract']\n    df['ratio_totalcredit_contract_close'] = df['totalamount_6A'] /    df['sum_totalcredit_contract']\n    df['ratio_overdue_debt_active'] = df['totaldebtoverduevalue_178A'] /    df['totaldebt_9A']\n    df['ratio_overdue_debt_close'] = df['totaldebtoverduevalue_718A'] /    df['totaldebt_9A']\n    df['sum_instalments'] = df['numberofinstls_229L'] +    df['numberofinstls_320L']\n    df['ratio_instalments_active'] = df['numberofinstls_320L'] /    df['sum_instalments']\n    df['ratio_instalments_close'] = df['numberofinstls_229L'] /    df['sum_instalments']\n    '''\n    df=df.pipe(Pipeline.filter_cols)\n    \n    columns_to_drop=[\n     \n   'min_pmts_year_1139T',              \n'mean_pmts_year_1139T',                            \n'max_pmts_year_1139T',                             \n'min_pmts_year_507T' ,                               \n'mean_pmts_year_507T',                              \n'max_pmts_year_507T',\n        \n        'min_overdueamountmaxdateyear_2T'  ,               \n'mean_overdueamountmaxdateyear_2T'   ,              \n'max_overdueamountmaxdateyear_2T'  ,              \n'min_overdueamountmaxdateyear_994T'  ,              \n'mean_overdueamountmaxdateyear_994T' ,             \n'max_overdueamountmaxdateyear_994T'\n]\n    \n    '''\n    columns_to_drop_existing = [col for col in columns_to_drop if col in df.columns]\n\n    df=df.drop(columns_to_drop_existing)\n    \n    \n    \n    '''\n    features400=[\n            #0\n        'max_role_1084L', 'max_language1_981M', 'max_sex_738L','max_incometype_1044T','max_education_927M',\n        'max_type_25L','max_safeguarantyflag_411L','min_pmts_month_158T','min_pmts_month_706T','max_pmts_month_158T',\n        'max_pmts_month_706T','mean_pmts_month_706T','mean_pmts_month_158T','pctinstlsallpaidlate1d_3546856L','pctinstlsallpaidlate4d_3546849L',\n        'pctinstlsallpaidlate6d_3546844L','pctinstlsallpaidlat10d_839L','max_contaddr_smempladdr_334L','max_contaddr_matchlist_1032L','numinstlswithdpd10_728L',\n        'pctinstlsallpaidearl3d_427L','lastrejectreason_759M','days120_123L','days180_256L','days90_310L',\n        'lastrejectreasonclient_4145040M','lastcancelreason_561M','lastst_736L','numrejects9m_859L',\n        'avgmaxdpdlast9m_3716943P','numberofqueries_373L','days360_512L','days30_165L','mobilephncnt_593L',\n        'max_birth_259D','numcontrs3months_479L','dateofbirth_337D','numinstpaidearly3d_3546850L','sum_maxdpdtolerance_577P',\n        'max_maxdpdtolerance_577P','numinstlallpaidearly3d_817L','maxdpdtolerance_374P','numinstlsallpaid_934L','daysoverduetolerancedd_3976961L',\n        'max_employedfrom_700D','mean_maxdpdtolerance_577P','mean_employedfrom_700D','numinstpaidearly_338L','avgdpdtolclosure24_3658938P',\n        \n        'mean_pmtnum_8L','mean_tenor_203L','lastrejectdate_50D','numinstlswithoutdpd_562L','avgdbddpdlast24m_3658932P',\n        'max_pmtnum_8L','max_tenor_203L','numinstpaidearly3dest_4493216L','numinstmatpaidtearly2d_4499204L','min_employedfrom_700D',\n        'requesttype_4525192L','maxdpdfrom6mto36m_3546853P','maxdpdlast24m_143P','datelastinstal40dpd_247D','mindbddpdlast24m_3658935P',\n        'amtinstpaidbefduel24m_4187115A','avgdbdtollast24m_4525197P','maxdpdlast12m_727P','maxdbddpdtollast12m_3658940P',\n        'max_empl_employedfrom_271D','min_empl_employedfrom_271D','mean_empl_employedfrom_271D','min_maxdpdtolerance_577P','firstclxcampaign_1125D',\n        'max_status_219L','sum_pmtnum_8L','sum_tenor_203L','monthsannuity_845L','pmtnum_254L',\n        'max_education_1138M','maxdpdlast9m_1059P','sum_amount_4527230A','mindbdtollast24m_4525191P','min_subjectroles_name_541M',\n        'birthdate_574D','max_subjectroles_name_838M','max_subjectroles_name_541M','min_subjectroles_name_838M','ratio_queries_120',\n        'ratio_queries_90','mean_outstandingdebt_522A','cntpmts24_3658933L','ratio_queries_180','maxdbddpdtollast6m_4187119P',\n        'mean_currdebt_94A','max_familystate_726L','numinstregularpaidest_4493210L','numincomingpmts_3546848L','numinstpaid_4499208L',\n        \n         'numinstregularpaid_973L','disbursedcredamount_1113A','secondquarter_766L','pmtssum_45A','min_dtlastpmtallstes_3545839D',\n        'count_num_group1_tax_registry_a','max_inittransactioncode_279L','max_credtype_587L','max_conts_type_509L','min_isbidproduct_390L',\n        'max_rejectreasonclient_4145042M','max_rejectreason_755M','max_isbidproduct_390L','max_amount_4527230A','mean_pmts_dpd_303P',\n        'maxdpdlast6m_474P','mean_firstnonzeroinstldate_307D','max_relationshiptoclient_642T','sum_credamount_590A','credamount_770A',\n        'pmtscount_423L','numinstunpaidmaxest_4493212L','numinsttopaygrest_4493213L','avgdbddpdlast3m_4187120P',\n        'numinsttopaygr_769L','sum_credacc_actualbalance_314A','numinstunpaidmax_3546851L','max_empl_employedtotal_800L','price_1097A',\n        'ratio_queries_30','max_postype_4733339M','mean_creationdate_885D','maxdebt4_972A',\n        'mean_amount_4527230A','thirdquarter_1082L','sum_mainoccupationinc_437A','sum_pmtamount_36A','maxdpdinstldate_3546855D',\n        'min_purposeofcred_874M','max_description_351M','description_5085714M','min_dtlastpmt_581D',\n        'totaldebt_9A','max_contractst_964M','currdebt_22A','min_firstnonzeroinstldate_307D',\n        \n         'max_contractst_545M','max_purposeofcred_426M','max_pmts_dpd_303P',\n        'max_classificationofcontr_13M','max_financialinstitution_591M','max_classificationofcontr_400M','max_financialinstitution_382M','count_num_group1',\n        'eir_270L','interestrate_311L','min_purposeofcred_426M','maxdbddpdlast1m_3658939P',\n        'sum_revolvingaccount_394A','max_firstnonzeroinstldate_307D','min_dateactivated_425D','firstdatedue_489D','min_approvaldate_319D',\n        'min_refreshdate_3813885D','totalsettled_863A','count_persontype_1072L','max_credacc_cards_status_52L','min_creationdate_885D',\n        'max_pmtamount_36A','min_pmtnum_8L','min_tenor_203L','count_num_group1_tax_registry_c','max_credacc_status_367L',\n        'sumoutstandtotalest_4493215A','datelastunpaid_3546854D','sum_persontype_1072L','sumoutstandtotal_3546847A',\n        'numinstls_657L','mean_dtlastpmtallstes_3545839D','max_familystate_447L','mean_pmtamount_36A',\n        'max_purposeofcred_874M','maxdpdlast3m_392P','mean_credacc_actualbalance_314A','currdebtcredtyperange_828A',\n        'sum_persontype_792L','lastapplicationdate_877D','max_creationdate_885D','max_outstandingdebt_522A','max_credacc_actualbalance_314A',\n        \n        'max_currdebt_94A','max_pmts_dpd_1073P','mean_credamount_590A','sum_personindex_1023L','min_credacc_actualbalance_314A',\n        'sum_outstandingdebt_522A','min_amount_4527230A','mean_persontype_792L','mean_credacc_credlmt_575A','lastactivateddate_801D',\n        'sum_currdebt_94A','count_personindex_1023L','count_relationshiptoclient_642T','max_dateactivated_425D','max_housetype_905L',\n        'min_currdebt_94A','max_relationshiptoclient_415T','min_lastupdate_388D','min_processingdate_168D',\n        'min_dateofrealrepmt_138D','mean_lastupdate_388D','max_persontype_1072L','max_persontype_792L','min_pmtamount_36A',\n        'lastapprcommoditycat_1041M','pmtaverage_4527227A','annuity_780A','mean_dateofrealrepmt_138D',\n        'sum_annuity_853A','mean_pmts_dpd_1073P','min_credacc_credlmt_575A','lastapprdate_640D','mean_credacc_minhisbal_90A',\n        'min_dateofcredend_353D','mean_dtlastpmt_581D','max_credacc_minhisbal_90A','avgoutstandbalancel6m_4187114A','max_approvaldate_319D',\n        'maxannuity_159A','min_credacc_minhisbal_90A','sum_amount_4917619A','cntincpaycont9m_3716944L','min_dateofcredstart_181D',\n        'mean_refreshdate_3813885D','max_remitter_829L','pmtaverage_3A','avglnamtstart24m_4525187A','education_1103M',\n       'mean_dpdmax_139P','mean_numberofoverdueinstlmax_1039L','min_recorddate_4527225D','min_annuity_853A',\n        'max_dpdmax_139P','sum_dpdmax_139P','lastdelinqdate_224D','mean_persontype_1072L',\n        'count_num_group1_cb_a_2','count_num_group2_cb_a_2','twobodfilling_608L','sum_numberofoverdueinstlmax_1039L','homephncnt_628L',\n        'count_num_group1_tax_registry_b','datefirstoffer_1144D','max_numberofoverdueinstlmax_1039L','min_numberofoverdueinstlmax_1039L',\n        'mean_downpmt_134A','max_empls_economicalst_849M','min_revolvingaccount_394A','responsedate_4527233D',\n        'sum_isbidproduct_390L','max_mainoccupationinc_437A','count_familystate_447L','min_dateofcredstart_739D','max_amount_4917619A',\n        'mean_dateofcredend_353D','min_dpdmax_139P','mean_revolvingaccount_394A','maininc_215A','lastrejectcredamount_222A',\n        'max_processingdate_168D','min_totaldebtoverduevalue_178A','inittransactioncode_186L','max_deductiondate_4917603D',\n        'min_deductiondate_4917603D','mean_processingdate_168D','contractssum_5085716L','mean_dateofcredstart_181D','applicationscnt_867L',\n        'mean_amount_4917619A','max_revolvingaccount_394A','mean_isbidproduct_390L','mean_dateofcredstart_739D','min_pmts_dpd_1073P',\n        \n        'sum_credacc_credlmt_575A','min_pmts_dpd_303P','lastapprcredamount_781A','max_empl_industry_691L',\n        'min_amount_4917619A','mean_annuity_853A',\n       'max_overdueamountmaxdatemonth_365T','max_downpmt_134A','disbursementtype_67L',\n        'min_overdueamountmaxdatemonth_284T','sum_numberofcontrsvalue_358L','count_num_group1_person2','sum_byoccupationinc_3656910L','mean_deductiondate_4917603D',\n        'sellerplacescnt_216L','mean_overdueamountmaxdatemonth_365T','max_overdueamountmaxdatemonth_284T','mean_approvaldate_319D','credtype_322L',\n        'max_numberofcontrsvalue_358L','mean_numberofcontrsvalue_358L','min_downpmt_134A','min_credacc_maxhisbal_375A','mean_isdebitcard_527L',\n        'min_mainoccupationinc_384A','bankacctype_710L','mean_pmts_overdue_1152A','min_numberofcontrsvalue_358L','min_mainoccupationinc_437A',\n        'min_residualamount_856A','mean_byoccupationinc_3656910L','downpmt_116A','isbidproduct_1095L','clientscnt12m_3712952L',\n        'mean_credacc_maxhisbal_375A','max_nominalrate_281L','mean_dateactivated_425D','sum_downpmt_134A','mean_totaldebtoverduevalue_178A',\n        \n         'mean_numberofinstls_320L','max_numberofinstls_320L','max_isdebitcard_527L','mean_nominalrate_281L','dtlastpmtallstes_4499206D',\n        'max_lastupdate_388D','responsedate_4917613D','sum_credacc_minhisbal_90A','max_byoccupationinc_3656910L',\n        'min_credacc_transactions_402L','min_instlamount_768A','inittransactionamount_650A','max_totaldebtoverduevalue_178A','min_isdebitcard_527L',\n        'clientscnt6m_3712949L','mean_credacc_transactions_402L','max_credacc_maxhisbal_375A','min_numberofinstls_320L','mean_totalamount_996A',\n        'validfrom_1069D','count_num_group1_cb_a_1','mean_residualamount_856A','max_debtoverdue_47A',\n        'max_dateofrealrepmt_138D','mean_totalamount_6A','min_pmts_overdue_1152A',\"max_cancelreason_3545846M\",\n    ]\n    \n    features125=[\n        \n        'max_role_1084L', 'max_language1_981M', 'max_sex_738L','max_incometype_1044T','max_education_927M',\n        'max_type_25L','max_safeguarantyflag_411L','min_pmts_month_158T','min_pmts_month_706T','max_pmts_month_158T',\n        'max_pmts_month_706T','mean_pmts_month_706T','mean_pmts_month_158T','pctinstlsallpaidlate1d_3546856L','pctinstlsallpaidlate4d_3546849L',\n        'pctinstlsallpaidlate6d_3546844L','pctinstlsallpaidlat10d_839L','max_contaddr_smempladdr_334L','max_contaddr_matchlist_1032L','numinstlswithdpd10_728L',\n        'pctinstlsallpaidearl3d_427L','lastrejectreason_759M','days120_123L','days180_256L','days90_310L',\n        'lastrejectreasonclient_4145040M','lastcancelreason_561M','lastst_736L','numrejects9m_859L',\n        'avgmaxdpdlast9m_3716943P','numberofqueries_373L','days360_512L','days30_165L','mobilephncnt_593L',\n        'max_birth_259D','numcontrs3months_479L','dateofbirth_337D','numinstpaidearly3d_3546850L','sum_maxdpdtolerance_577P',\n        'max_maxdpdtolerance_577P','numinstlallpaidearly3d_817L','maxdpdtolerance_374P','numinstlsallpaid_934L','daysoverduetolerancedd_3976961L',\n        'max_employedfrom_700D','mean_maxdpdtolerance_577P','mean_employedfrom_700D','numinstpaidearly_338L','avgdpdtolclosure24_3658938P',\n        \n        'mean_pmtnum_8L','mean_tenor_203L','lastrejectdate_50D','numinstlswithoutdpd_562L','avgdbddpdlast24m_3658932P',\n        'max_pmtnum_8L','max_tenor_203L','numinstpaidearly3dest_4493216L','numinstmatpaidtearly2d_4499204L','min_employedfrom_700D',\n        'requesttype_4525192L','maxdpdfrom6mto36m_3546853P','maxdpdlast24m_143P','datelastinstal40dpd_247D','mindbddpdlast24m_3658935P',\n        'amtinstpaidbefduel24m_4187115A','avgdbdtollast24m_4525197P','maxdpdlast12m_727P','maxdbddpdtollast12m_3658940P',\n        'max_empl_employedfrom_271D','min_empl_employedfrom_271D','mean_empl_employedfrom_271D','min_maxdpdtolerance_577P','firstclxcampaign_1125D',\n        'max_status_219L','sum_pmtnum_8L','sum_tenor_203L','monthsannuity_845L','pmtnum_254L',\n        'max_education_1138M','maxdpdlast9m_1059P','sum_amount_4527230A','mindbdtollast24m_4525191P','min_subjectroles_name_541M',\n        'birthdate_574D','max_subjectroles_name_838M','max_subjectroles_name_541M','min_subjectroles_name_838M','ratio_queries_120',\n        'ratio_queries_90','mean_outstandingdebt_522A','cntpmts24_3658933L','ratio_queries_180','maxdbddpdtollast6m_4187119P',\n        'mean_currdebt_94A','max_familystate_726L','numinstregularpaidest_4493210L','numincomingpmts_3546848L','numinstpaid_4499208L',\n         'numinstregularpaid_973L','disbursedcredamount_1113A','secondquarter_766L','pmtssum_45A','min_dtlastpmtallstes_3545839D',\n        'count_num_group1_tax_registry_a','max_inittransactioncode_279L','max_credtype_587L','max_conts_type_509L','min_isbidproduct_390L',\n        'max_rejectreasonclient_4145042M','max_rejectreason_755M','max_isbidproduct_390L','max_amount_4527230A','mean_pmts_dpd_303P',\n        'maxdpdlast6m_474P','mean_firstnonzeroinstldate_307D','max_relationshiptoclient_642T','sum_credamount_590A','credamount_770A',\n        'pmtscount_423L','max_empl_industry_691L','numinstunpaidmaxest_4493212L','numinsttopaygrest_4493213L','avgdbddpdlast3m_4187120P',\n        \n    ]\n    \n    features200=[\n         'max_role_1084L', 'max_language1_981M', 'max_sex_738L','max_incometype_1044T','max_education_927M',\n        'max_type_25L','max_safeguarantyflag_411L','min_pmts_month_158T','min_pmts_month_706T','max_pmts_month_158T',\n        'max_pmts_month_706T','mean_pmts_month_706T','mean_pmts_month_158T','pctinstlsallpaidlate1d_3546856L','pctinstlsallpaidlate4d_3546849L',\n        'pctinstlsallpaidlate6d_3546844L','pctinstlsallpaidlat10d_839L','max_contaddr_smempladdr_334L','max_contaddr_matchlist_1032L','numinstlswithdpd10_728L',\n        'pctinstlsallpaidearl3d_427L','lastrejectreason_759M','days120_123L','days180_256L','days90_310L',\n        'lastrejectreasonclient_4145040M','lastcancelreason_561M','lastst_736L','numrejects9m_859L',\n        'avgmaxdpdlast9m_3716943P','numberofqueries_373L','days360_512L','days30_165L','mobilephncnt_593L',\n        'max_birth_259D','numcontrs3months_479L','dateofbirth_337D','numinstpaidearly3d_3546850L','sum_maxdpdtolerance_577P',\n        'max_maxdpdtolerance_577P','numinstlallpaidearly3d_817L','maxdpdtolerance_374P','numinstlsallpaid_934L','daysoverduetolerancedd_3976961L',\n        'max_employedfrom_700D','mean_maxdpdtolerance_577P','mean_employedfrom_700D','numinstpaidearly_338L','avgdpdtolclosure24_3658938P',\n        \n        'mean_pmtnum_8L','mean_tenor_203L','lastrejectdate_50D','numinstlswithoutdpd_562L','avgdbddpdlast24m_3658932P',\n        'max_pmtnum_8L','max_tenor_203L','numinstpaidearly3dest_4493216L','numinstmatpaidtearly2d_4499204L','min_employedfrom_700D',\n        'requesttype_4525192L','maxdpdfrom6mto36m_3546853P','maxdpdlast24m_143P','datelastinstal40dpd_247D','mindbddpdlast24m_3658935P',\n        'amtinstpaidbefduel24m_4187115A','avgdbdtollast24m_4525197P','maxdpdlast12m_727P','maxdbddpdtollast12m_3658940P',\n        'max_empl_employedfrom_271D','min_empl_employedfrom_271D','mean_empl_employedfrom_271D','min_maxdpdtolerance_577P','firstclxcampaign_1125D',\n        'max_status_219L','sum_pmtnum_8L','sum_tenor_203L','monthsannuity_845L','pmtnum_254L',\n        'max_education_1138M','maxdpdlast9m_1059P','sum_amount_4527230A','mindbdtollast24m_4525191P','min_subjectroles_name_541M',\n        'birthdate_574D','max_subjectroles_name_838M','max_subjectroles_name_541M','min_subjectroles_name_838M','ratio_queries_120',\n        'ratio_queries_90','mean_outstandingdebt_522A','cntpmts24_3658933L','ratio_queries_180','maxdbddpdtollast6m_4187119P',\n        'mean_currdebt_94A','max_familystate_726L','numinstregularpaidest_4493210L','numincomingpmts_3546848L','numinstpaid_4499208L',\n        \n         'numinstregularpaid_973L','disbursedcredamount_1113A','secondquarter_766L','pmtssum_45A','min_dtlastpmtallstes_3545839D',\n        'count_num_group1_tax_registry_a','max_inittransactioncode_279L','max_credtype_587L','max_conts_type_509L','min_isbidproduct_390L',\n        'max_rejectreasonclient_4145042M','max_rejectreason_755M','max_isbidproduct_390L','max_amount_4527230A','mean_pmts_dpd_303P',\n        'maxdpdlast6m_474P','mean_firstnonzeroinstldate_307D','max_relationshiptoclient_642T','sum_credamount_590A','credamount_770A',\n        'pmtscount_423L','numinstunpaidmaxest_4493212L','numinsttopaygrest_4493213L','avgdbddpdlast3m_4187120P',\n        'numinsttopaygr_769L','sum_credacc_actualbalance_314A','numinstunpaidmax_3546851L','max_empl_employedtotal_800L','price_1097A',\n        'ratio_queries_30','max_postype_4733339M','mean_creationdate_885D','maxdebt4_972A',\n        'mean_amount_4527230A','thirdquarter_1082L','sum_mainoccupationinc_437A','sum_pmtamount_36A','maxdpdinstldate_3546855D',\n        'min_purposeofcred_874M','max_description_351M','description_5085714M','min_dtlastpmt_581D',\n        'totaldebt_9A','max_contractst_964M','currdebt_22A','min_firstnonzeroinstldate_307D',\n        \n         'max_contractst_545M','max_purposeofcred_426M','max_pmts_dpd_303P',\n        'max_classificationofcontr_13M','max_financialinstitution_591M','max_classificationofcontr_400M','max_financialinstitution_382M','count_num_group1',\n        'eir_270L','interestrate_311L','min_purposeofcred_426M','maxdbddpdlast1m_3658939P',\n        'sum_revolvingaccount_394A','max_firstnonzeroinstldate_307D','min_dateactivated_425D','firstdatedue_489D','min_approvaldate_319D',\n        'min_refreshdate_3813885D','totalsettled_863A','count_persontype_1072L','max_credacc_cards_status_52L','min_creationdate_885D',\n        'max_pmtamount_36A','min_pmtnum_8L','min_tenor_203L','count_num_group1_tax_registry_c','max_credacc_status_367L',\n        'sumoutstandtotalest_4493215A','datelastunpaid_3546854D','sum_persontype_1072L','sumoutstandtotal_3546847A',\n        'numinstls_657L','mean_dtlastpmtallstes_3545839D','max_familystate_447L','mean_pmtamount_36A',\n        'max_purposeofcred_874M','maxdpdlast3m_392P','mean_credacc_actualbalance_314A','currdebtcredtyperange_828A',\n        'sum_persontype_792L','lastapplicationdate_877D','max_creationdate_885D','max_outstandingdebt_522A','max_credacc_actualbalance_314A',\n        \n        'max_currdebt_94A','max_pmts_dpd_1073P','mean_credamount_590A','sum_personindex_1023L','min_credacc_actualbalance_314A',\n        'sum_outstandingdebt_522A','min_amount_4527230A','mean_persontype_792L','mean_credacc_credlmt_575A','lastactivateddate_801D',\n        'sum_currdebt_94A','count_personindex_1023L','count_relationshiptoclient_642T','max_dateactivated_425D','max_housetype_905L',\n        'min_currdebt_94A','max_relationshiptoclient_415T','min_lastupdate_388D','min_processingdate_168D',\n        'min_dateofrealrepmt_138D','mean_lastupdate_388D','max_persontype_1072L','max_persontype_792L','min_pmtamount_36A',\n        'lastapprcommoditycat_1041M','pmtaverage_4527227A','annuity_780A','mean_dateofrealrepmt_138D'\n    ]\n    \n    \n    \n    features200 = [\"avgdpdtolclosure24_3658938P\", \"mean_maxdpdtolerance_577P\", \"pctinstlsallpaidlate1d_3546856L\", \"price_1097A\", \"max_birth_259D\", \"pmtnum_254L\", \"mobilephncnt_593L\", \"max_incometype_1044T\", \"max_sex_738L\", \"lastrejectreason_759M\", \"lastrejectdate_50D\", \"sum_amount_4527230A\", \"avgdbddpdlast24m_3658932P\", \"days120_123L\", \"maxdbddpdtollast12m_3658940P\", \"lastst_736L\", \"mean_empl_employedfrom_271D\", \"numrejects9m_859L\", \"pctinstlsallpaidlate4d_3546849L\", \"days180_256L\", \"firstclxcampaign_1125D\", \"pmtssum_45A\", \"min_empl_employedfrom_271D\", \"lastcancelreason_561M\", \"maxdpdlast12m_727P\", \"dateofbirth_337D\", \"days90_310L\", \"maxdpdlast24m_143P\", \"validfrom_1069D\", \"numinstpaidearly3d_3546850L\", \"annuity_780A\", \"cntpmts24_3658933L\", \"max_relationshiptoclient_415T\", \"mean_outstandingdebt_522A\", \"credamount_770A\", \"numinstlswithdpd10_728L\", \"eir_270L\", \"max_employedfrom_700D\", \"max_firstnonzeroinstldate_307D\", \"pctinstlsallpaidlate6d_3546844L\", \"disbursedcredamount_1113A\", \"mean_pmts_dpd_1073P\", \"count_num_group1_tax_registry_a\", \"mean_tenor_203L\", \"maxdpdlast9m_1059P\", \"mean_employedfrom_700D\", \"interestrate_311L\", \"lastdelinqdate_224D\", \"max_relationshiptoclient_642T\", \"numincomingpmts_3546848L\", \"education_1103M\", \"max_maxdpdtolerance_577P\", \"numinstlsallpaid_934L\", \"monthsannuity_845L\", \"max_empl_employedfrom_271D\", \"sum_pmtnum_8L\", \"days30_165L\", \"sum_pmtamount_36A\", \"datelastinstal40dpd_247D\", \"numinstlswithoutdpd_562L\", \"pctinstlsallpaidlat10d_839L\", \"numinstlallpaidearly3d_817L\", \"isbidproduct_1095L\", \"numberofqueries_373L\", \"sum_tenor_203L\", \"applicationscnt_867L\", \"requesttype_4525192L\", \"mean_pmts_dpd_303P\", \"pmtscount_423L\", \"max_familystate_726L\", \"max_amount_4527230A\", \"numinsttopaygr_769L\", \"max_familystate_447L\", \"mean_pmtnum_8L\", \"mean_currdebt_94A\", \"responsedate_4527233D\", \"maxdpdinstldate_3546855D\", \"numinstunpaidmax_3546851L\", \"days360_512L\", \"pctinstlsallpaidearl3d_427L\", \"pmtaverage_3A\", \"datelastunpaid_3546854D\", \"mean_dpdmax_139P\", \"maxdpdlast3m_392P\", \"max_education_1138M\", \"totalsettled_863A\", \"amtinstpaidbefduel24m_4187115A\", \"ratio_queries_120\", \"maxdbddpdlast1m_3658939P\", \"count_num_group1_tax_registry_c\", \"avgmaxdpdlast9m_3716943P\", \"inittransactionamount_650A\", \"avgdbddpdlast3m_4187120P\", \"pmtaverage_4527227A\", \"mean_pmts_overdue_1140A\", \"maxdebt4_972A\", \"currdebt_22A\", \"max_dtlastpmt_581D\", \"disbursementtype_67L\", \"mean_annuity_853A\", \"ratio_queries_180\", \"sum_amount_4917619A\", \"maxdbddpdtollast6m_4187119P\", \"maxdpdlast6m_474P\", \"ratio_queries_30\", \"totaldebt_9A\", \"ratio_queries_90\", \"min_employedfrom_700D\", \"lastapprcommoditycat_1041M\", \"daysoverduetolerancedd_3976961L\", \"sum_outstandingdebt_522A\", \"mean_amount_4527230A\", \"lastrejectreasonclient_4145040M\", \"inittransactioncode_186L\", \"credtype_322L\", \"numinstunpaidmaxest_4493212L\", \"max_pmtnum_8L\", \"max_dpdmax_139P\", \"min_dateactivated_425D\", \"homephncnt_628L\", \"max_empl_industry_691L\", \"datefirstoffer_1144D\", \"mean_dateofcredstart_739D\", \"min_maxdpdtolerance_577P\", \"max_tenor_203L\", \"sum_maxdpdtolerance_577P\", \"lastrejectcredamount_222A\", \"maxdpdtolerance_374P\", \"mean_firstnonzeroinstldate_307D\", \"max_dtlastpmtallstes_3545839D\", \"maxannuity_159A\", \"lastrejectcommoditycat_161M\", \"numinstpaidearly_338L\", \"birthdate_574D\", \"mean_numberofoverdueinstlmax_1039L\", \"min_amount_4527230A\", \"cntincpaycont9m_3716944L\", \"max_creationdate_885D\", \"min_credamount_590A\", \"avgdbdtollast24m_4525197P\", \"max_pmts_dpd_1073P\", \"mean_dateactivated_425D\", \"mean_pmts_overdue_1152A\", \"mean_mainoccupationinc_437A\", \"maxinstallast24m_3658928A\", \"min_mainoccupationinc_437A\", \"downpmt_116A\", \"mindbddpdlast24m_3658935P\", \"max_pmts_dpd_303P\", \"max_totalamount_6A\", \"max_language1_981M\", \"min_pmtnum_8L\", \"min_approvaldate_319D\", \"max_annuity_853A\", \"mean_approvaldate_319D\", \"max_credacc_actualbalance_314A\", \"thirdquarter_1082L\", \"clientscnt12m_3712952L\", \"min_firstnonzeroinstldate_307D\", \"min_dateofcredstart_739D\", \"lastapplicationdate_877D\", \"max_outstandingdebt_522A\", \"mean_dtlastpmtallstes_3545839D\", \"min_tenor_203L\", \"mean_credacc_actualbalance_314A\", \"mean_dtlastpmt_581D\", \"max_contractst_964M\", \"sum_currdebt_94A\", \"min_dtlastpmt_581D\", \"numinstregularpaid_973L\", \"max_status_219L\", \"max_pmtamount_36A\", \"mean_credamount_590A\", \"numinsttopaygrest_4493213L\", \"min_dpdmax_139P\", \"min_processingdate_168D\", \"count_num_group1_cb_a_2\", \"max_numberofoverdueinstlmax_1039L\", \"avgoutstandbalancel6m_4187114A\", \"min_pmtamount_36A\", \"min_annuity_853A\", \"max_mainoccupationinc_437A\", \"max_approvaldate_319D\", \"maxdpdfrom6mto36m_3546853P\", \"min_amount_4917619A\", \"min_creationdate_885D\", \"sellerplacescnt_216L\", \"mean_processingdate_168D\", \"lastapprdate_640D\", \"sum_dpdmax_139P\", \"numinstpaidlate1d_3546852L\", \"sumoutstandtotal_3546847A\", \"sum_credacc_actualbalance_314A\", \"sum_mainoccupationinc_437A\", \"max_credamount_590A\", \"min_dtlastpmtallstes_3545839D\", \"fourthquarter_440L\", \"dtlastpmtallstes_4499206D\", \"max_pmts_overdue_1140A\", \"maininc_215A\"]\n    \n    \n    seen = set()\n    duplicates = []\n    for item in features400:\n        if item in seen:\n            duplicates.append(item)\n        else:\n            seen.add(item)\n    print(\"duplicates:\")\n    print(duplicates)\n    print()\n    \n    print(\"Length of features400: \", len(features400))\n    print(\"Length of features200: \", len(features200))\n    print(\"Length of features125: \", len(features125))\n    missing_columns = [col for col in features200 if col not in df.columns]\n\n    # Print missing columns, if any\n    if missing_columns:\n        print(\"The following columns are missing in the DataFrame:\")\n        for col in missing_columns:\n            print(col)\n    else:\n        print(\"All columns from features400 are present in the DataFrame.\")\n    \n    # Columns to preserve\n    preserved_columns = ['target', 'case_id', 'WEEK_NUM']\n\n    # Identify columns to drop excluding the preserved columns\n    columns_to_drop = [col for col in df.columns if col not in preserved_columns + features200]\n\n    # Drop columns that are not in features_selected and not preserved\n    \n    df=df.drop(columns=columns_to_drop)\n    \n    \n    if BALANCE_COLUMNS:\n\n        # the test set might be different, so lets drop the columns that have many nan values in test set\n        train = df.filter(df['target'].is_not_null())\n        test = df.filter(df['target'].is_null())\n\n        valid_percentage_train = []\n        valid_percentage_test=[]\n        for col in df.columns:\n            valid_percentage_train.append(train[col].count())\n            valid_percentage_test.append(test[col].count())\n\n        valid_percentage_train = pd.Series(valid_percentage_train)\n        valid_percentage_test= pd.Series(valid_percentage_test)\n\n        print(train.count())\n        print(test.count())\n        print(\"length of train\",len(valid_percentage_train))\n        print(\"length of test\",len(valid_percentage_test))\n        print(\"df columns\",len(df.columns))\n\n        info_df = pd.DataFrame({'column': df.columns, 'valid_train': valid_percentage_train, 'valid_test': valid_percentage_test})\n        irrelevant_columns = info_df[info_df['valid_test'] < 0.5 * info_df['valid_train']]['column'].to_list()\n        columns_to_drop = [col for col in df.columns if (col not in preserved_columns) and (col in irrelevant_columns) ]\n        df = df.drop(columns=columns_to_drop)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:44.964174Z","iopub.execute_input":"2024-04-02T19:07:44.964872Z","iopub.status.idle":"2024-04-02T19:07:45.045931Z","shell.execute_reply.started":"2024-04-02T19:07:44.964841Z","shell.execute_reply":"2024-04-02T19:07:45.044552Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"'''\ndf = get_base(DATA_DIRECTORY)\ndf_applprev1 = get_applprev1(DATA_DIRECTORY)\ndf_applprev1 = df_applprev1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\ndf = df.join(df_applprev1, on='case_id', how='left', suffix='_applprev1')\nprint(\"Previous applications depth 1 test dataframe shape:\", df_applprev1.shape)\nprint(\"DATAFRAME shape:\", df.shape)\ndel df_applprev1\ngc.collect()\n\n\ndf=feature_engineering(df)\nprint(df['credit_income_percent'])\n'''","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.047901Z","iopub.execute_input":"2024-04-02T19:07:45.048293Z","iopub.status.idle":"2024-04-02T19:07:45.056046Z","shell.execute_reply.started":"2024-04-02T19:07:45.048263Z","shell.execute_reply":"2024-04-02T19:07:45.054686Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'\\ndf = get_base(DATA_DIRECTORY)\\ndf_applprev1 = get_applprev1(DATA_DIRECTORY)\\ndf_applprev1 = df_applprev1.filter(pl.col(\\'case_id\\').is_in(df[\\'case_id\\'].unique()))\\ndf = df.join(df_applprev1, on=\\'case_id\\', how=\\'left\\', suffix=\\'_applprev1\\')\\nprint(\"Previous applications depth 1 test dataframe shape:\", df_applprev1.shape)\\nprint(\"DATAFRAME shape:\", df.shape)\\ndel df_applprev1\\ngc.collect()\\n\\n\\ndf=feature_engineering(df)\\nprint(df[\\'credit_income_percent\\'])\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"# **GET FUNCTIONS**","metadata":{}},{"cell_type":"markdown","source":"### get_base()","metadata":{}},{"cell_type":"code","source":"def get_base(path, num_rows = None):\n    # Read the Parquet file using scan() method\n    train={}\n    test={}\n    \n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_base.parquet'))\n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_base.parquet')).limit(num_rows) \n        \n    test = pl.read_parquet(os.path.join(path, 'test/test_base.parquet'))    \n    length=len(test)\n    nan_series=pl.Series([None] * length)\n    test = test.select(pl.col(\"*\"), nan_series.alias(\"target\"))\n    df=pl.concat([train, test])\n    del test;del train;gc.collect()\n    \n    \n    df = df.with_columns(pl.col('date_decision').cast(pl.Date))\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.058035Z","iopub.execute_input":"2024-04-02T19:07:45.058451Z","iopub.status.idle":"2024-04-02T19:07:45.079277Z","shell.execute_reply.started":"2024-04-02T19:07:45.058423Z","shell.execute_reply":"2024-04-02T19:07:45.077643Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### get_static()","metadata":{}},{"cell_type":"code","source":"def get_static(path, num_rows = None):\n# Read the Parquet file using scan() method\n    chunks = []\n    for path in glob(DATA_DIRECTORY+str('train/train_static_0_*.parquet')):\n        chunks.append(pl.read_parquet(path,low_memory=True).pipe(Pipeline.set_table_dtypes) )\n    train = (pl.concat(chunks, how=\"vertical_relaxed\")).pipe(Pipeline.filter_cols)\n    \n    if num_rows!= None:\n        df1 = train.slice(0,num_rows)\n        df2 = train.slice(num_rows,len(train))\n        \n        train=df1\n        del df2\n        gc.collect()\n    chunks = []\n    for path in glob(DATA_DIRECTORY+str('test/test_static_0_*.parquet')):\n        chunks.append(pl.read_parquet(path,low_memory=True).pipe(Pipeline.set_table_dtypes) )\n    test = pl.concat(chunks, how=\"vertical_relaxed\")\n    \n    \n    columns_to_keep = train.columns\n\n# Find columns in 'test' that are not in 'train'\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n\n# Drop columns from 'test' that are not in 'train'\n    test = test.drop(columns_to_remove)\n    df=pl.concat([train, test])\n    del test;del train;gc.collect()\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.081082Z","iopub.execute_input":"2024-04-02T19:07:45.081501Z","iopub.status.idle":"2024-04-02T19:07:45.093076Z","shell.execute_reply.started":"2024-04-02T19:07:45.081471Z","shell.execute_reply":"2024-04-02T19:07:45.091950Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### get_static_cb()","metadata":{}},{"cell_type":"code","source":"def get_static_cb(path, num_rows = None):\n    \n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_static_cb_0.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_static_cb_0.parquet'),low_memory=True).limit(num_rows).pipe(Pipeline.set_table_dtypes) \n       \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_static_cb_0.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del test;del train;gc.collect()\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.094673Z","iopub.execute_input":"2024-04-02T19:07:45.095378Z","iopub.status.idle":"2024-04-02T19:07:45.114252Z","shell.execute_reply.started":"2024-04-02T19:07:45.095341Z","shell.execute_reply":"2024-04-02T19:07:45.112793Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### get_applprev1(DATA_DIRECTORY, num_rows=num_rows)","metadata":{}},{"cell_type":"code","source":"def get_applprev1(path, num_rows = None):\n    \n    \n    chunks = []\n    for path in glob(DATA_DIRECTORY+str('train/train_applprev_1_*.parquet')):\n        chunks.append(pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes))\n    train = pl.concat(chunks, how=\"vertical_relaxed\")#.pipe(Pipeline.filter_cols)\n    \n    \n    if num_rows!= None:\n        df1 = train.slice(0,num_rows)\n        df2 = train.slice(num_rows,len(train))\n\n        train=df1\n        del df2   \n        gc.collect()\n    chunks = []\n    for path in glob(DATA_DIRECTORY+str('test/test_applprev_1_*.parquet')):\n        chunks.append(pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes))\n    test = pl.concat(chunks, how=\"vertical_relaxed\")\n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n    df=pl.concat([train, test])\n    del test;del train;gc.collect()\n    agg_df = group(df, '', APPLPREV1_AGG)\n    del df;gc.collect()\n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.116484Z","iopub.execute_input":"2024-04-02T19:07:45.117281Z","iopub.status.idle":"2024-04-02T19:07:45.131440Z","shell.execute_reply.started":"2024-04-02T19:07:45.117223Z","shell.execute_reply":"2024-04-02T19:07:45.129852Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### get_applprev2(DATA_DIRECTORY, num_rows=num_rows)","metadata":{}},{"cell_type":"code","source":"def get_applprev2(path, num_rows = None):\n    train={}\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_applprev_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n     \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_applprev_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n       \n    \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_applprev_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', APPLPREV2_AGG)\n    del df ;gc.collect()\n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.133318Z","iopub.execute_input":"2024-04-02T19:07:45.133832Z","iopub.status.idle":"2024-04-02T19:07:45.149235Z","shell.execute_reply.started":"2024-04-02T19:07:45.133790Z","shell.execute_reply":"2024-04-02T19:07:45.147633Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### get_person1","metadata":{}},{"cell_type":"code","source":"def get_person1(path, num_rows = None):\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_person_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_person_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n      \n    \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_person_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', PERSON1_AGG)\n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.150786Z","iopub.execute_input":"2024-04-02T19:07:45.151296Z","iopub.status.idle":"2024-04-02T19:07:45.163728Z","shell.execute_reply.started":"2024-04-02T19:07:45.151262Z","shell.execute_reply":"2024-04-02T19:07:45.162123Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### get_person2","metadata":{}},{"cell_type":"code","source":"def get_person2(path, num_rows = None):\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_person_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_person_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes)\n        \n    test = pl.read_parquet(os.path.join(path, 'test/test_person_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', PERSON2_AGG)\n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.165846Z","iopub.execute_input":"2024-04-02T19:07:45.166378Z","iopub.status.idle":"2024-04-02T19:07:45.180048Z","shell.execute_reply.started":"2024-04-02T19:07:45.166338Z","shell.execute_reply":"2024-04-02T19:07:45.179083Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### other","metadata":{}},{"cell_type":"code","source":"def get_other(path, num_rows = None):\n     # Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_other_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_other_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n         \n    test = pl.read_parquet(os.path.join(path, 'test/test_other_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', OTHER_AGG)\n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.187568Z","iopub.execute_input":"2024-04-02T19:07:45.188660Z","iopub.status.idle":"2024-04-02T19:07:45.200411Z","shell.execute_reply.started":"2024-04-02T19:07:45.188612Z","shell.execute_reply":"2024-04-02T19:07:45.198675Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## get_debitcard","metadata":{}},{"cell_type":"code","source":"def get_debitcard(path, num_rows = None):\n    # Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_debitcard_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n     \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_debitcard_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n      \n        \n    test = pl.read_parquet(os.path.join(path, 'test/test_debitcard_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', DEBITCARD_AGG)\n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.202096Z","iopub.execute_input":"2024-04-02T19:07:45.202842Z","iopub.status.idle":"2024-04-02T19:07:45.215563Z","shell.execute_reply.started":"2024-04-02T19:07:45.202809Z","shell.execute_reply":"2024-04-02T19:07:45.214287Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### get_tax_registry_a","metadata":{}},{"cell_type":"code","source":"def get_tax_registry_a(path, num_rows = None):\n    \n    # Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_a_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_a_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n  \n    \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_tax_registry_a_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', TAX_REGISTRY_A_AGG)    \n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.217288Z","iopub.execute_input":"2024-04-02T19:07:45.217633Z","iopub.status.idle":"2024-04-02T19:07:45.229708Z","shell.execute_reply.started":"2024-04-02T19:07:45.217605Z","shell.execute_reply":"2024-04-02T19:07:45.228134Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### get_tax_registry_b","metadata":{}},{"cell_type":"code","source":"def get_tax_registry_b(path, num_rows = None):\n    # Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_b_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes)\n        \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_b_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_tax_registry_b_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', TAX_REGISTRY_B_AGG) \n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.231179Z","iopub.execute_input":"2024-04-02T19:07:45.232444Z","iopub.status.idle":"2024-04-02T19:07:45.247348Z","shell.execute_reply.started":"2024-04-02T19:07:45.232401Z","shell.execute_reply":"2024-04-02T19:07:45.245946Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### get_tax_registry_c","metadata":{}},{"cell_type":"code","source":"def get_tax_registry_c(path, num_rows = None):\n     # Read the Parquet file using scan() method\n# Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_c_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_c_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_tax_registry_c_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', TAX_REGISTRY_C_AGG)    \n    del df; gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.249332Z","iopub.execute_input":"2024-04-02T19:07:45.250458Z","iopub.status.idle":"2024-04-02T19:07:45.259895Z","shell.execute_reply.started":"2024-04-02T19:07:45.250421Z","shell.execute_reply":"2024-04-02T19:07:45.258881Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### get_credit_bureau_a_1","metadata":{}},{"cell_type":"code","source":"def get_credit_bureau_a_1(path, num_rows = None):\n    \n    \n    \n    agg_chunks=[]\n    \n    for path in glob(DATA_DIRECTORY + 'train/train_credit_bureau_a_1_*.parquet'):\n        file_df=pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes)\n        agg_file_df = group(file_df, '', CREDIT_BUREAU_A_1_AGG, datatype='polars')\n        agg_chunks.append(agg_file_df)\n        del file_df; gc.collect()\n    \n    \n    train_agg_df=agg_chunks[0]\n    for agg_chunk in agg_chunks[1:]:\n        train_agg_df.vstack(agg_chunk)\n    train_agg_df.rechunk()\n        \n        \n    \n    \n    \n    agg_chunks=[]\n    \n    for path in glob(DATA_DIRECTORY + 'test/test_credit_bureau_a_1_*.parquet'):\n        file_df=pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes)\n        agg_file_df = group(file_df, '', CREDIT_BUREAU_A_1_AGG, datatype='polars')\n        agg_chunks.append(agg_file_df)\n        del file_df; gc.collect()\n        \n        \n    test_agg_df=agg_chunks[0]\n    for agg_chunk in agg_chunks[1:]:\n        test_agg_df.vstack(agg_chunk)\n    test_agg_df.rechunk()\n    \n    \n    \n\n    \n    agg_df=train_agg_df\n    agg_df.extend(test_agg_df)\n    \n\n    \n    \n    print(\"agg df \", agg_df.shape)\n   \n    unique_count = agg_df['case_id'].n_unique()\n\n    print(\"Number of unique values in 'case_id' column:\", unique_count)\n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.261556Z","iopub.execute_input":"2024-04-02T19:07:45.262193Z","iopub.status.idle":"2024-04-02T19:07:45.275712Z","shell.execute_reply.started":"2024-04-02T19:07:45.262160Z","shell.execute_reply":"2024-04-02T19:07:45.274654Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### get_credit_bureau_b_1","metadata":{}},{"cell_type":"code","source":"def get_credit_bureau_b_1(path, num_rows = None):\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_1.parquet')).pipe(Pipeline.set_table_dtypes) \n        \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_1.parquet')).pipe(Pipeline.set_table_dtypes) \n   \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_credit_bureau_b_1.parquet')).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test ; gc.collect()\n    agg_df = group(df, '', CREDIT_BUREAU_B_1_AGG) \n    \n    \n    del df; gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.277479Z","iopub.execute_input":"2024-04-02T19:07:45.278112Z","iopub.status.idle":"2024-04-02T19:07:45.292527Z","shell.execute_reply.started":"2024-04-02T19:07:45.278056Z","shell.execute_reply":"2024-04-02T19:07:45.291088Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### get_credit_bureau_a_2","metadata":{}},{"cell_type":"code","source":"def get_credit_bureau_a_2(path, num_rows = None):\n    \n    \n    \n    agg_chunks=[]\n    \n    for path in glob(DATA_DIRECTORY + 'train/train_credit_bureau_a_2_*.parquet'):\n        file_df=pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes)\n        agg_file_df = group(file_df, '', CREDIT_BUREAU_A_2_AGG, datatype='polars')\n        agg_chunks.append(agg_file_df)\n        del file_df;gc.collect()\n    \n    train_agg_df=agg_chunks[0]\n    for agg_chunk in agg_chunks[1:]:\n        train_agg_df.vstack(agg_chunk)\n    train_agg_df.rechunk()\n    \n    \n    agg_chunks=[]\n    \n    for path in glob(DATA_DIRECTORY + 'test/test_credit_bureau_a_2_*.parquet'):\n        file_df=pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes)\n        agg_file_df = group(file_df, '', CREDIT_BUREAU_A_2_AGG, datatype='polars')\n        agg_chunks.append(agg_file_df)\n        del file_df;gc.collect()\n    \n    test_agg_df=agg_chunks[0]\n    for agg_chunk in agg_chunks[1:]:\n        test_agg_df.vstack(agg_chunk)\n    test_agg_df.rechunk()\n    \n    agg_df=train_agg_df\n    agg_df.extend(test_agg_df)\n    \n    print(\"agg df \", agg_df.shape)\n   \n    unique_count = agg_df['case_id'].n_unique()\n\n    print(\"Number of unique values in 'case_id' column:\", unique_count)\n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.294706Z","iopub.execute_input":"2024-04-02T19:07:45.295147Z","iopub.status.idle":"2024-04-02T19:07:45.308724Z","shell.execute_reply.started":"2024-04-02T19:07:45.295113Z","shell.execute_reply":"2024-04-02T19:07:45.307282Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### get_credit_bureau_b_2","metadata":{}},{"cell_type":"code","source":"def get_credit_bureau_b_2(path, num_rows = None):\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_2.parquet')).pipe(Pipeline.set_table_dtypes) \n   \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_2.parquet')).pipe(Pipeline.set_table_dtypes) \n\n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_credit_bureau_b_2.parquet')).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n    \n    df=pl.concat([train, test])\n    del train;del test; gc.collect()\n    agg_df = group(df, '', CREDIT_BUREAU_B_2_AGG) \n    \n    del df; gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.310315Z","iopub.execute_input":"2024-04-02T19:07:45.311475Z","iopub.status.idle":"2024-04-02T19:07:45.326122Z","shell.execute_reply.started":"2024-04-02T19:07:45.311436Z","shell.execute_reply":"2024-04-02T19:07:45.324852Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# **EXECUTION** <a id='execution'></a>\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\nif __name__ == \"__main__\":\n    pd.set_option('display.max_rows', 60)\n    pd.set_option('display.max_columns', 100)\n    with timer(\"Pipeline total time\"):\n        main(debug= True)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T19:07:45.327995Z","iopub.execute_input":"2024-04-02T19:07:45.328819Z","iopub.status.idle":"2024-04-02T19:12:08.009350Z","shell.execute_reply.started":"2024-04-02T19:07:45.328776Z","shell.execute_reply":"2024-04-02T19:12:08.008000Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Notebook started:\nbase dataframe shape: (11121, 5)\nbase - done in 0s\nstatic dataframe shape: (11121, 156)\nDATAFRAME shape: (11121, 160)\nstatic - done in 9s\nstatic cb dataframe shape: (10541, 23)\nDATAFRAME shape: (11121, 182)\nstatic_cb - done in 1s\nPrevious applications depth 1 test dataframe shape: (2, 115)\nDATAFRAME shape: (11121, 296)\nPrevious applications depth 1 test - done in 15s\nPrevious applications depth 2 test dataframe shape: (4530, 5)\nDATAFRAME shape: (11121, 300)\nPrevious applications depth 2 test - done in 4s\nPerson depth 1 test dataframe shape: (11117, 47)\nDATAFRAME shape: (11121, 346)\nPerson depth 1 test - done in 8s\nPerson depth 2 test dataframe shape: (10706, 4)\nDATAFRAME shape: (11121, 349)\nPerson depth 2 test - done in 1s\nOther test dataframe shape: (2, 12)\nDATAFRAME shape: (11121, 360)\nOther test - done in 0s\nDebit card test dataframe shape: (152, 5)\nDATAFRAME shape: (11121, 364)\nDebit card test - done in 0s\nTax registry a test dataframe shape: (0, 10)\nDATAFRAME shape: (11121, 373)\nTax registry a test - done in 2s\nTax registry b test dataframe shape: (2, 10)\nDATAFRAME shape: (11121, 382)\nTax registry b test - done in 1s\nTax registry c test dataframe shape: (6592, 10)\nDATAFRAME shape: (11121, 391)\nTax registry c test - done in 2s\nagg df  (176609, 134)\nNumber of unique values in 'case_id' column: 176609\nCredit bureau a 1 test dataframe shape: (1, 134)\nDATAFRAME shape: (11121, 524)\nCredit bureau a 1 test - done in 63s\nCredit bureau b 1 test dataframe shape: (15, 2)\nDATAFRAME shape: (11121, 525)\nCredit bureau b 1 test - done in 1s\nagg df  (150427, 33)\nNumber of unique values in 'case_id' column: 150427\nCredit bureau a 2 test dataframe shape: (1, 33)\nDATAFRAME shape: (11121, 557)\nCredit bureau a 2 test - done in 92s\nCredit bureau b 2 test dataframe shape: (15, 12)\nDATAFRAME shape: (11121, 568)\nCredit bureau b 2 test - done in 1s\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2808906809.py:75: DeprecationWarning: `keep_name` is deprecated. It has been moved to `name.keep`.\n  .keep_name()\n","output_type":"stream"},{"name":"stdout","text":"duplicates:\n[]\n\nLength of features400:  347\nLength of features200:  200\nLength of features125:  123\nThe following columns are missing in the DataFrame:\navgdpdtolclosure24_3658938P\nmean_maxdpdtolerance_577P\npctinstlsallpaidlate1d_3546856L\nsum_amount_4527230A\navgdbddpdlast24m_3658932P\nmaxdbddpdtollast12m_3658940P\npctinstlsallpaidlate4d_3546849L\nfirstclxcampaign_1125D\nvalidfrom_1069D\nnuminstpaidearly3d_3546850L\ncntpmts24_3658933L\nmean_outstandingdebt_522A\nnuminstlswithdpd10_728L\nmax_employedfrom_700D\nmax_firstnonzeroinstldate_307D\npctinstlsallpaidlate6d_3546844L\nmean_pmts_dpd_1073P\ncount_num_group1_tax_registry_a\nmean_tenor_203L\nmean_employedfrom_700D\nlastdelinqdate_224D\nnumincomingpmts_3546848L\nmax_maxdpdtolerance_577P\nnuminstlsallpaid_934L\nmonthsannuity_845L\nsum_pmtnum_8L\ndatelastinstal40dpd_247D\nnuminstlswithoutdpd_562L\npctinstlsallpaidlat10d_839L\nnuminstlallpaidearly3d_817L\nsum_tenor_203L\nrequesttype_4525192L\nmean_pmts_dpd_303P\nmax_familystate_726L\nmax_amount_4527230A\nnuminsttopaygr_769L\nmean_pmtnum_8L\nmean_currdebt_94A\nresponsedate_4527233D\nmaxdpdinstldate_3546855D\nnuminstunpaidmax_3546851L\npctinstlsallpaidearl3d_427L\ndatelastunpaid_3546854D\nmean_dpdmax_139P\nmax_education_1138M\namtinstpaidbefduel24m_4187115A\nmaxdbddpdlast1m_3658939P\navgmaxdpdlast9m_3716943P\navgdbddpdlast3m_4187120P\npmtaverage_4527227A\nmean_pmts_overdue_1140A\nmax_dtlastpmt_581D\nmean_annuity_853A\nsum_amount_4917619A\nmaxdbddpdtollast6m_4187119P\nmin_employedfrom_700D\ndaysoverduetolerancedd_3976961L\nsum_outstandingdebt_522A\nmean_amount_4527230A\nnuminstunpaidmaxest_4493212L\nmax_pmtnum_8L\nmax_dpdmax_139P\nmin_dateactivated_425D\ndatefirstoffer_1144D\nmean_dateofcredstart_739D\nmin_maxdpdtolerance_577P\nmax_tenor_203L\nsum_maxdpdtolerance_577P\nmean_firstnonzeroinstldate_307D\nmax_dtlastpmtallstes_3545839D\nnuminstpaidearly_338L\nmean_numberofoverdueinstlmax_1039L\nmin_amount_4527230A\ncntincpaycont9m_3716944L\nmax_creationdate_885D\nmin_credamount_590A\navgdbdtollast24m_4525197P\nmax_pmts_dpd_1073P\nmean_dateactivated_425D\nmean_pmts_overdue_1152A\nmean_mainoccupationinc_437A\nmaxinstallast24m_3658928A\nmin_mainoccupationinc_437A\nmindbddpdlast24m_3658935P\nmax_pmts_dpd_303P\nmax_totalamount_6A\nmin_pmtnum_8L\nmin_approvaldate_319D\nmax_annuity_853A\nmean_approvaldate_319D\nmax_credacc_actualbalance_314A\nmin_firstnonzeroinstldate_307D\nmin_dateofcredstart_739D\nmax_outstandingdebt_522A\nmean_dtlastpmtallstes_3545839D\nmin_tenor_203L\nmean_credacc_actualbalance_314A\nmean_dtlastpmt_581D\nmax_contractst_964M\nsum_currdebt_94A\nmin_dtlastpmt_581D\nnuminstregularpaid_973L\nmax_status_219L\nmean_credamount_590A\nnuminsttopaygrest_4493213L\nmin_dpdmax_139P\ncount_num_group1_cb_a_2\nmax_numberofoverdueinstlmax_1039L\navgoutstandbalancel6m_4187114A\nmin_annuity_853A\nmax_mainoccupationinc_437A\nmax_approvaldate_319D\nmin_amount_4917619A\nmin_creationdate_885D\nlastapprdate_640D\nsum_dpdmax_139P\nnuminstpaidlate1d_3546852L\nsumoutstandtotal_3546847A\nsum_credacc_actualbalance_314A\nsum_mainoccupationinc_437A\nmax_credamount_590A\nmin_dtlastpmtallstes_3545839D\ndtlastpmtallstes_4499206D\nmax_pmts_overdue_1140A\nmaininc_215A\nDataFrame Shape: (11121, 78)\n------------------------------------------------------------\nColumn Name                                        Data Type                      NaN Percentage      \n------------------------------------------------------------\ncase_id                                            Int64                          0.00%\nWEEK_NUM                                           Int64                          0.00%\ntarget                                             Int64                          0.09%\nannuity_780A                                       Float64                        0.00%\napplicationscnt_867L                               Float64                        0.00%\nclientscnt12m_3712952L                             Float64                        0.00%\ncredamount_770A                                    Float64                        0.00%\ncredtype_322L                                      String                         0.00%\ncurrdebt_22A                                       Float64                        0.00%\ndisbursedcredamount_1113A                          Float64                        0.00%\ndisbursementtype_67L                               String                         0.00%\ndownpmt_116A                                       Float64                        0.00%\neir_270L                                           Float64                        15.46%\nhomephncnt_628L                                    Float64                        0.00%\ninittransactionamount_650A                         Float64                        84.54%\ninittransactioncode_186L                           String                         0.00%\ninterestrate_311L                                  Float64                        15.46%\nisbidproduct_1095L                                 Boolean                        0.00%\nlastapplicationdate_877D                           Int64                          59.19%\nlastapprcommoditycat_1041M                         String                         0.00%\nlastcancelreason_561M                              String                         0.00%\nlastrejectcommoditycat_161M                        String                         0.00%\nlastrejectcredamount_222A                          Float64                        65.47%\nlastrejectdate_50D                                 Int64                          65.47%\nlastrejectreason_759M                              String                         0.00%\nlastrejectreasonclient_4145040M                    String                         0.00%\nlastst_736L                                        String                         59.19%\nmaxannuity_159A                                    Float64                        58.71%\nmaxdebt4_972A                                      Float64                        58.71%\nmaxdpdfrom6mto36m_3546853P                         Float64                        81.71%\nmaxdpdlast12m_727P                                 Float64                        58.71%\nmaxdpdlast24m_143P                                 Float64                        58.71%\nmaxdpdlast3m_392P                                  Float64                        58.71%\nmaxdpdlast6m_474P                                  Float64                        58.71%\nmaxdpdlast9m_1059P                                 Float64                        58.71%\nmaxdpdtolerance_374P                               Float64                        58.71%\nmobilephncnt_593L                                  Float64                        0.00%\nnumrejects9m_859L                                  Float64                        0.00%\npmtnum_254L                                        Float64                        14.35%\nprice_1097A                                        Float64                        88.00%\nsellerplacescnt_216L                               Float64                        0.00%\ntotaldebt_9A                                       Float64                        0.00%\ntotalsettled_863A                                  Float64                        0.00%\nbirthdate_574D                                     Int64                          5.85%\ndateofbirth_337D                                   Int64                          34.70%\ndays120_123L                                       Float64                        34.70%\ndays180_256L                                       Float64                        34.70%\ndays30_165L                                        Float64                        34.70%\ndays360_512L                                       Float64                        34.70%\ndays90_310L                                        Float64                        34.70%\neducation_1103M                                    String                         5.22%\nfourthquarter_440L                                 Float64                        34.70%\nnumberofqueries_373L                               Float64                        34.70%\npmtaverage_3A                                      Float64                        66.76%\npmtscount_423L                                     Float64                        39.65%\npmtssum_45A                                        Float64                        39.65%\nthirdquarter_1082L                                 Float64                        34.70%\nmax_birth_259D                                     Int64                          0.04%\nmax_empl_employedfrom_271D                         Int64                          34.63%\nmean_empl_employedfrom_271D                        Int64                          34.63%\nmin_empl_employedfrom_271D                         Int64                          34.63%\nmax_empl_industry_691L                             String                         35.14%\nmax_familystate_447L                               String                         0.05%\nmax_incometype_1044T                               String                         0.04%\nmax_language1_981M                                 String                         0.04%\nmax_relationshiptoclient_415T                      String                         0.24%\nmax_relationshiptoclient_642T                      String                         0.24%\nmax_sex_738L                                       String                         0.04%\ncount_num_group1_tax_registry_c                    UInt32                         40.72%\nmin_pmtamount_36A                                  Float64                        40.72%\nmax_pmtamount_36A                                  Float64                        40.72%\nsum_pmtamount_36A                                  Float64                        40.72%\nmean_processingdate_168D                           Int64                          40.72%\nmin_processingdate_168D                            Int64                          40.72%\nratio_queries_30                                   Float64                        34.70%\nratio_queries_90                                   Float64                        34.70%\nratio_queries_120                                  Float64                        34.70%\nratio_queries_180                                  Float64                        34.70%\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2808906809.py:337: DeprecationWarning: named `columns` param is deprecated; use positional `*args` instead.\n  df=df.drop(columns=columns_to_drop)\n","output_type":"stream"},{"name":"stdout","text":"DATAFRAME shape: (11121, 78)\nFeature engineering / preprocessing - done in 1s\nColumn: case_id, Min Value: 0, Max Value: 57634\nColumn: WEEK_NUM, Min Value: 0, Max Value: 100\nColumn: target, Min Value: 0.0, Max Value: 1.0\nColumn: annuity_780A, Min Value: 452.0, Max Value: 37793.2\nColumn: applicationscnt_867L, Min Value: 0.0, Max Value: 20.0\nColumn: clientscnt12m_3712952L, Min Value: 0.0, Max Value: 3.0\nColumn: credamount_770A, Min Value: 3000.0, Max Value: 200000.0\nColumn: currdebt_22A, Min Value: 0.0, Max Value: 263474.8\nColumn: disbursedcredamount_1113A, Min Value: 0.0, Max Value: 200000.0\nColumn: downpmt_116A, Min Value: 0.0, Max Value: 76000.0\nColumn: eir_270L, Min Value: 0.0, Max Value: 0.45\nColumn: homephncnt_628L, Min Value: 0.0, Max Value: 6.0\nColumn: inittransactionamount_650A, Min Value: 0.0, Max Value: 98608.0\nColumn: interestrate_311L, Min Value: 0.0, Max Value: 0.45\nColumn: lastapplicationdate_877D, Min Value: -4797.0, Max Value: 14.0\nColumn: lastrejectcredamount_222A, Min Value: 0.0, Max Value: 300000.0\nColumn: lastrejectdate_50D, Min Value: -4797.0, Max Value: 14.0\nColumn: maxannuity_159A, Min Value: 0.0, Max Value: 591704.0\nColumn: maxdebt4_972A, Min Value: 0.0, Max Value: 231440.03\nColumn: maxdpdfrom6mto36m_3546853P, Min Value: 0.0, Max Value: 2865.0\nColumn: maxdpdlast12m_727P, Min Value: 0.0, Max Value: 2865.0\nColumn: maxdpdlast24m_143P, Min Value: 0.0, Max Value: 2865.0\nColumn: maxdpdlast3m_392P, Min Value: 0.0, Max Value: 49.0\nColumn: maxdpdlast6m_474P, Min Value: 0.0, Max Value: 49.0\nColumn: maxdpdlast9m_1059P, Min Value: 0.0, Max Value: 2865.0\nColumn: maxdpdtolerance_374P, Min Value: 0.0, Max Value: 2865.0\nColumn: mobilephncnt_593L, Min Value: 0.0, Max Value: 8.0\nColumn: numrejects9m_859L, Min Value: 0.0, Max Value: 14.0\nColumn: pmtnum_254L, Min Value: 3.0, Max Value: 48.0\nColumn: price_1097A, Min Value: 0.0, Max Value: 131998.0\nColumn: sellerplacescnt_216L, Min Value: 0.0, Max Value: 14.0\nColumn: totaldebt_9A, Min Value: 0.0, Max Value: 263474.8\nColumn: totalsettled_863A, Min Value: 0.0, Max Value: 456031.1\nColumn: birthdate_574D, Min Value: -27757.0, Max Value: -7745.0\nColumn: dateofbirth_337D, Min Value: -27360.0, Max Value: -7973.0\nColumn: days120_123L, Min Value: 0.0, Max Value: 21.0\nColumn: days180_256L, Min Value: 0.0, Max Value: 27.0\nColumn: days30_165L, Min Value: 0.0, Max Value: 10.0\nColumn: days360_512L, Min Value: 0.0, Max Value: 44.0\nColumn: days90_310L, Min Value: 0.0, Max Value: 19.0\nColumn: fourthquarter_440L, Min Value: 0.0, Max Value: 31.0\nColumn: numberofqueries_373L, Min Value: 0.0, Max Value: 44.0\nColumn: pmtaverage_3A, Min Value: 0.0, Max Value: 53186.2\nColumn: pmtscount_423L, Min Value: 0.0, Max Value: 32.0\nColumn: pmtssum_45A, Min Value: 0.0, Max Value: 227919.62\nColumn: thirdquarter_1082L, Min Value: 0.0, Max Value: 25.0\nColumn: max_birth_259D, Min Value: -27757.0, Max Value: -7745.0\nColumn: max_empl_employedfrom_271D, Min Value: -16639.0, Max Value: 7.0\nColumn: mean_empl_employedfrom_271D, Min Value: -16639.0, Max Value: 7.0\nColumn: min_empl_employedfrom_271D, Min Value: -16639.0, Max Value: 7.0\nColumn: count_num_group1_tax_registry_c, Min Value: 1.0, Max Value: 32.0\nColumn: min_pmtamount_36A, Min Value: 0.032, Max Value: 22793.027\nColumn: max_pmtamount_36A, Min Value: 0.2, Max Value: 42500.0\nColumn: sum_pmtamount_36A, Min Value: 0.2, Max Value: 227919.624\nColumn: mean_processingdate_168D, Min Value: -169.0, Max Value: 13.0\nColumn: min_processingdate_168D, Min Value: -181.0, Max Value: 13.0\nColumn: ratio_queries_30, Min Value: 0.0, Max Value: 1.0\nColumn: ratio_queries_90, Min Value: 0.0, Max Value: 1.0\nColumn: ratio_queries_120, Min Value: 0.0, Max Value: 1.0\nColumn: ratio_queries_180, Min Value: 0.0, Max Value: 1.0\nshape before preprocessing (11111, 78)\nTotal count of NaN values in the DataFrame: 216754\nTotal count of NaN values in the DataFrame: 0\nshape after preprocessing (11111, 246)\nMemory usage after optimization is: 3.51 MB\nDecreased by 50.3%\nTrain/valid shape: (11111, 246), \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4739d7f33cae4efa96a5397e4ab7568c"}},"metadata":{}},{"name":"stdout","text":"Fold  1 AUC : 0.672288. Elapsed time: 11.59 seconds. Remaining time: 46.36 seconds.\nFold  2 AUC : 0.607181. Elapsed time: 22.82 seconds. Remaining time: 34.23 seconds.\nFold  3 AUC : 0.669998. Elapsed time: 34.09 seconds. Remaining time: 22.73 seconds.\nFold  4 AUC : 0.709001. Elapsed time: 45.24 seconds. Remaining time: 11.31 seconds.\nFold  5 AUC : 0.648963. Elapsed time: 56.41 seconds. Remaining time: 0.00 seconds.\nFull AUC score 0.659401\nGini Score of the valid set: -0.6687391994692076\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/576559558.py:135: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df['PREDICTIONS'] = oof_preds.copy()\n","output_type":"stream"},{"name":"stdout","text":"Model training - done in 59s\nTotal count of NaN values in the DataFrame: 162\nTotal count of NaN values in the DataFrame: 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting:   0%|          | 0/5 [00:00<?, ? models/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e8b7eb869bc4d6b9b73debb9bb6a2d6"}},"metadata":{}},{"name":"stdout","text":"Submission file has been created.\nSubmission - done in 1s\nNOTEBOOK HAS BEEN SUCCESSFULLY EXECUTED !!!\nPipeline total time - done in 263s\n","output_type":"stream"}]}]}