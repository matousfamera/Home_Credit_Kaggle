
[+] - Create Excel file for submission logging (completed 24-03-31)
      # In this file all submission will be stored. (including model parameters, CV score, LB score) That can give good information about what works and what does not.


[+] - Download completed dataframe and develop notebooks for importing, and also fix one-hot encoding and filling nan values
      [+] - Modify LightGBM notebook for export/import dataframe
      [+] - Modify RandomForestClassifier notebook for export/import dataframe
      [+] - Modify Tensorflow notebook for export/import dataframe
      [+] - Modify RF notebook for working one-hot-encoding and nan filling(reached CV about 0.77 with tuning)
      [+] - Modify Tensorflow notebook for working one-hot-encoding and nan filling

[+] - Create a special notebook for Feature Preparation, Engineering
      The notebook will be used for creating features and exporting final dataframe.
      [+] - Create working Notebook "Home-credit-2024-feature-selection"
      [+] - Update Kaggle dataset "home-credit-2024-additional-dataset" with exported dataframes
            [+] - processed_000.parquet, this file includes each and every feature
            [+] - processed_debug_000.parquet - this file includes just 11k with only about 150 columns, it is for debug purposes
            [+] - processed_001.parquet - this file includes the 250 best features
      [+] - Add function "data_tranformation"
      [+] - create "processed_001_std.parquet"

[+] - Copy the 0.575 LGB solution
      [+] - Fix bug in get functions
      [+] - Replicate the submission in "home-credit-2024-v2-lgb"

[ ] - Deploy the first generation of ensemble model (LGBM, CatBoost, NN)
      [+] - Tune LightGBM
      [+] - Tune RandomForestClassifier, it will not be used for ensemble, it is weak
      [ ] - Tensorflow https://www.tensorflow.org/tutorials/structured_data/imbalanced_data
            [+] - Creating working notebook
            [ ] - Create proper dataset for Tensorflow
            [ ] - Implement PCA as input for Tensorflow
            [ ] - Tune the features and hyperparameters
      [ ] - CatBoost
            [ ] - Create working notebook
            [ ] - Create proper notebook, hyperparameter tuning
            [ ] - Create proper dataset as input for CatBoost
      [ ] - Combine LGBM and CatBoost
            [ ] - Create proper notebook
            [ ] - Send submission
      [ ] - Combine the 3 models into 1 notebook
      [ ] - Run a submission on Kaggle

[ ] - Create version 3 notebook - generic notebook where any ensemble models can be created and deployed
      # The notebook will be prepared to handle level 1, level 2 and level 3 ensemble models. At the header of the notebook the models will be specified. The blending operation will be defined.



