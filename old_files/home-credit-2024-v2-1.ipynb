{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **LIBRARIES**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:19.073033Z","iopub.status.busy":"2024-03-17T21:16:19.072608Z","iopub.status.idle":"2024-03-17T21:16:23.682696Z","shell.execute_reply":"2024-03-17T21:16:23.681127Z","shell.execute_reply.started":"2024-03-17T21:16:19.072984Z"},"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import time\n","import numpy as np\n","import pandas as pd\n","from contextlib import contextmanager\n","import multiprocessing as mp\n","from functools import partial\n","from scipy.stats import kurtosis, iqr, skew\n","from lightgbm import LGBMClassifier\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.metrics import roc_auc_score\n","from glob import glob\n","from pathlib import Path\n","from datetime import datetime\n","import polars as pl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import StratifiedGroupKFold\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.metrics import roc_auc_score \n","from sklearn.metrics import roc_curve, auc\n","from tqdm.notebook import tqdm\n","import joblib\n","import lightgbm as lgb\n","import warnings\n","\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n"]},{"cell_type":"markdown","metadata":{},"source":["# **CONFIGURATION**"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.685750Z","iopub.status.busy":"2024-03-17T21:16:23.684943Z","iopub.status.idle":"2024-03-17T21:16:23.696258Z","shell.execute_reply":"2024-03-17T21:16:23.693970Z","shell.execute_reply.started":"2024-03-17T21:16:23.685701Z"},"trusted":true},"outputs":[],"source":["# GENERAL CONFIGURATIONS\n","NUM_THREADS = 4\n","DATA_DIRECTORY = \"./parquet_files/\"\n","# DATA_DIRECTORY = \"/kaggle/input/home-credit-credit-risk-model-stability/parquet_files/\"\n","SUBMISSION_SUFIX = \"_model2_0\"\n","# LIGHTGBM CONFIGURATION AND HYPER-PARAMETERS\n","GENERATE_SUBMISSION_FILES = True\n","EVALUATE_VALIDATION_SET = True\n","STRATIFIED_KFOLD = False\n","RANDOM_SEED = 737851\n","NUM_FOLDS = 10\n","EARLY_STOPPING = 100\n","ROOT            = Path(\"./\")\n","\n","LIGHTGBM_PARAMS = {\n","    'boosting_type': 'goss',\n","    'n_estimators': 10000,\n","    'learning_rate': 0.005134,\n","    'num_leaves': 54,\n","    'max_depth': 10,\n","    'subsample_for_bin': 240000,\n","    'reg_alpha': 0.436193,\n","    'reg_lambda': 0.479169,\n","    'colsample_bytree': 0.508716,\n","    'min_split_gain': 0.024766,\n","    'subsample': 1,\n","    'is_unbalance': False,\n","    'silent':-1,\n","    'verbose':-1,\n","    \n","}"]},{"cell_type":"markdown","metadata":{},"source":["### Set aggregations"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.700507Z","iopub.status.busy":"2024-03-17T21:16:23.699668Z","iopub.status.idle":"2024-03-17T21:16:23.732802Z","shell.execute_reply":"2024-03-17T21:16:23.731659Z","shell.execute_reply.started":"2024-03-17T21:16:23.700446Z"},"trusted":true},"outputs":[],"source":["# AGGREGATIONS\n","APPLPREV1_AGG = {\n","    'annuity_853A' : ['min', 'max', 'mean'],\n","    'currdebt_94A' : ['max', 'mean', 'sum'] ,\n","    'mainoccupationinc_437A' : ['max', 'mean', 'sum'] ,\n","    'cancelreason_3545846M' : ['mean']\n","}\n","APPLPREV2_AGG = {\n","    \n","}\n","PERSON1_AGG={}\n","PERSON2_AGG={}\n","OTHER_AGG={}\n","DEBITCARD_AGG={}\n","TAX_REGISTRY_A_AGG={}\n","TAX_REGISTRY_B_AGG={}\n","TAX_REGISTRY_C_AGG={}\n","CREDIT_BUREAU_B_1_AGG={}\n","CREDIT_BUREAU_B_2_AGG={}\n"]},{"cell_type":"markdown","metadata":{},"source":["# **MAIN FUNCTION**"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.736988Z","iopub.status.busy":"2024-03-17T21:16:23.736230Z","iopub.status.idle":"2024-03-17T21:16:23.763767Z","shell.execute_reply":"2024-03-17T21:16:23.761771Z","shell.execute_reply.started":"2024-03-17T21:16:23.736932Z"},"trusted":true},"outputs":[],"source":["def main(debug= False):\n","    num_rows = 1111 if debug else None\n","    with timer(\"base\"):\n","        df = get_base(DATA_DIRECTORY, num_rows=num_rows)\n","        print(\"base dataframe shape:\", df.shape)\n","\n","    with timer(\"static\"):\n","        df_static = get_static(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_static, on='case_id', how='left', suffix='_static')\n","        print(\"static dataframe shape:\", df_static.shape)\n","        del df_static\n","        gc.collect()\n","\n","    with timer(\"static_cb\"):\n","        df_static_cb = get_static_cb(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_static_cb, on='case_id', how='left', suffix='_static_cb')\n","        print(\"static cb dataframe shape:\", df_static_cb.shape)\n","        del df_static_cb\n","        gc.collect()\n","\n","    with timer(\"Previous applications depth 1 test\"):\n","        df_applprev1 = get_applprev1(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_applprev1, on='case_id', how='left', suffix='_applprev1')\n","        print(\"Previous applications depth 1 test dataframe shape:\", df_applprev1.shape)\n","        del df_applprev1\n","        gc.collect()\n","\n","    with timer(\"Previous applications depth 2 test\"):\n","        df_applprev2 = get_applprev2(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_applprev2, on='case_id', how='left', suffix='_applprev2')\n","        print(\"Previous applications depth 2 test dataframe shape:\", df_applprev2.shape)\n","        del df_applprev2\n","        gc.collect()\n","\n","    with timer(\"Person depth 1 test\"):\n","        df_person1 = get_person1(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_person1, on='case_id', how='left', suffix='_person1')\n","        print(\"Person depth 1 test dataframe shape:\", df_person1.shape)\n","        del df_person1\n","        gc.collect()\n","\n","    with timer(\"Person depth 2 test\"):\n","        df_person2 = get_person2(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_person2, on='case_id', how='left', suffix='_person2')\n","        print(\"Person depth 2 test dataframe shape:\", df_person2.shape)\n","        del df_person2\n","        gc.collect()\n","\n","    with timer(\"Other test\"):\n","        df_other = get_other(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_other, on='case_id', how='left', suffix='_other')\n","        print(\"Other test dataframe shape:\", df_other.shape)\n","        del df_other\n","        gc.collect()\n","\n","    with timer(\"Debit card test\"):\n","        df_debitcard = get_debitcard(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_debitcard, on='case_id', how='left', suffix='_debitcard')\n","        print(\"Debit card test dataframe shape:\", df_debitcard.shape)\n","        del df_debitcard\n","        gc.collect()\n","\n","    with timer(\"Tax registry a test\"):\n","        df_tax_registry_a = get_tax_registry_a(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_tax_registry_a, on='case_id', how='left', suffix='_tax_registry_a')\n","        print(\"Tax registry a test dataframe shape:\", df_tax_registry_a.shape)\n","        del df_tax_registry_a\n","        gc.collect()\n","\n","    with timer(\"Tax registry b test\"):\n","        df_tax_registry_b = get_tax_registry_b(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_tax_registry_b, on='case_id', how='left', suffix='_tax_registry_b')\n","        print(\"Tax registry b test dataframe shape:\", df_tax_registry_b.shape)\n","        del df_tax_registry_b\n","        gc.collect()\n","\n","    with timer(\"Tax registry c test\"):\n","        df_tax_registry_c = get_tax_registry_c(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_tax_registry_c, on='case_id', how='left', suffix='_tax_registry_c')\n","        print(\"Tax registry c test dataframe shape:\", df_tax_registry_c.shape)\n","        del df_tax_registry_c\n","        gc.collect()\n","    '''\n","    with timer(\"Credit bureau a 1 test\"):\n","        df_credit_bureau_a_1 = get_credit_bureau_a_1(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_credit_bureau_a_1, on='case_id', how='left', suffix='_cb_a_1')\n","        print(\"Credit bureau a 1 test dataframe shape:\", df_credit_bureau_a_1.shape)\n","        del df_credit_bureau_a_1\n","        gc.collect()\n","        '''\n","\n","    with timer(\"Credit bureau b 1 test\"):\n","        df_credit_bureau_b_1 = get_credit_bureau_b_1(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_credit_bureau_b_1, on='case_id', how='left', suffix='_cb_b_1')\n","        print(\"Credit bureau b 1 test dataframe shape:\", df_credit_bureau_b_1.shape)\n","        del df_credit_bureau_b_1\n","        gc.collect()\n","\n","    '''\n","    with timer(\"Credit bureau a 2 test\"):\n","        df_credit_bureau_a_2 = get_credit_bureau_a_2(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_credit_bureau_a_2, on='case_id', how='left', suffix='_cb_a_2')\n","        print(\"Credit bureau a 2 test dataframe shape:\", df_credit_bureau_a_2.shape)\n","        # Free memory\n","        del df_credit_bureau_a_2\n","        gc.collect()\n","'''   \n","    with timer(\"Credit bureau b 2 test\"):\n","        df_credit_bureau_b_2 = get_credit_bureau_b_2(DATA_DIRECTORY, num_rows=num_rows)\n","        df = df.join(df_credit_bureau_b_2, on='case_id', how='left', suffix='_cb_b_2')\n","\n","    \n","    with timer(\"Feature engineering / preprocessing\"):    \n","        df=feature_engineering(df)\n","   \n","   \n","    with timer(\"Model training\"):\n","        df, cat_cols = to_pandas(df)\n","        model = kfold_lightgbm_sklearn(df, cat_cols)\n","       \n","    with timer(\"Feature importance assesment\"):\n","        get_features_importances(df, model)\n","        \n","    with timer(\"Submission\"):\n","        if generate_submission_file(df, model):\n","            \"Submission file has been created.\"\n","        \n","    del df\n","    del model\n","    \n","    print(\"NOTEBOOK HAS BEEN SUCCESSFULLY EXECUTED !!!\")"]},{"cell_type":"markdown","metadata":{},"source":["# **UTILITY FUNCTIONS**"]},{"cell_type":"markdown","metadata":{},"source":["### Pipeline"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.767279Z","iopub.status.busy":"2024-03-17T21:16:23.765640Z","iopub.status.idle":"2024-03-17T21:16:23.785666Z","shell.execute_reply":"2024-03-17T21:16:23.784221Z","shell.execute_reply.started":"2024-03-17T21:16:23.767223Z"},"trusted":true},"outputs":[],"source":["class Pipeline:\n","    @staticmethod\n","    \n","    \n","    # Sets datatypes accordingly\n","    def set_table_dtypes(df):\n","        for col in df.columns:\n","            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Int64))\n","            elif col in [\"date_decision\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Date))\n","            elif col[-1] in (\"P\", \"A\"):\n","                df = df.with_columns(pl.col(col).cast(pl.Float64))\n","            elif col[-1] in (\"M\",):\n","                df = df.with_columns(pl.col(col).cast(pl.String))\n","            elif col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col).cast(pl.Date))            \n","\n","        return df\n","    \n","    \n","    # Changes the values of all date columns. The result will not be a date but number of days since date_decision.\n","    @staticmethod\n","    def handle_dates(df):\n","        for col in df.columns:\n","            if col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n","                df = df.with_columns(pl.col(col).dt.total_days())\n","                \n","        df = df.drop(\"date_decision\", \"MONTH\")\n","\n","        return df\n","    \n","    # It drops columns with a lot of NaN values.\n","    @staticmethod\n","    def filter_cols(df):\n","        for col in df.columns:\n","            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n","                isnull = df[col].is_null().mean()\n","\n","                if isnull > 0.95:\n","                    df = df.drop(col)\n","\n","        for col in df.columns:\n","            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n","                freq = df[col].n_unique()\n","\n","                if (freq == 1) | (freq > 200):\n","                    df = df.drop(col)\n","\n","        return df"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.788875Z","iopub.status.busy":"2024-03-17T21:16:23.787364Z","iopub.status.idle":"2024-03-17T21:16:23.809186Z","shell.execute_reply":"2024-03-17T21:16:23.806822Z","shell.execute_reply.started":"2024-03-17T21:16:23.788823Z"},"trusted":true},"outputs":[],"source":["def get_info(dataframe):\n","    \"\"\"\n","    View data types, shape, and calculate the percentage of NaN (missing) values in each column\n","    of a Polars DataFrame simultaneously.\n","    \n","    Parameters:\n","    dataframe (polars.DataFrame): The DataFrame to analyze.\n","    \n","    Returns:\n","    None\n","    \"\"\"\n","    # Print DataFrame shape\n","    print(\"DataFrame Shape:\", dataframe.shape)\n","    print(\"-\" * 60)\n","    \n","    # Print column information\n","    print(\"{:<50} {:<30} {:<20}\".format(\"Column Name\", \"Data Type\", \"NaN Percentage\"))\n","    print(\"-\" * 60)\n","    \n","    # Total number of rows in the DataFrame\n","    total_rows = len(dataframe)\n","    \n","    # Iterate over each column\n","    for column in dataframe.columns:\n","        # Get the data type of the column\n","        dtype = str(dataframe[column].dtype)\n","        \n","        # Count the number of NaN values in the column\n","        nan_count = dataframe[column].null_count()\n","        \n","        # Calculate the percentage of NaN values\n","        nan_percentage = (nan_count / total_rows) * 100\n","        \n","        # Print the information\n","        print(\"{:<50} {:<30} {:.2f}%\".format(column, dtype, nan_percentage))\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.810967Z","iopub.status.busy":"2024-03-17T21:16:23.810553Z","iopub.status.idle":"2024-03-17T21:16:23.831057Z","shell.execute_reply":"2024-03-17T21:16:23.829849Z","shell.execute_reply.started":"2024-03-17T21:16:23.810934Z"},"trusted":true},"outputs":[],"source":["def to_pandas(df_data, cat_cols=None):\n","    df_data = df_data.to_pandas()\n","    \n","    if cat_cols is None:\n","        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n","    \n","    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n","    \n","    return df_data, cat_cols"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.834666Z","iopub.status.busy":"2024-03-17T21:16:23.833274Z","iopub.status.idle":"2024-03-17T21:16:23.854574Z","shell.execute_reply":"2024-03-17T21:16:23.852612Z","shell.execute_reply.started":"2024-03-17T21:16:23.834600Z"},"trusted":true},"outputs":[],"source":["def reduce_mem_usage(df, verbose=True):\n","    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    for col in df.columns:\n","        col_type = df[col].dtypes\n","        if col_type in numerics:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)\n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","\n","    return df"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.856831Z","iopub.status.busy":"2024-03-17T21:16:23.856274Z","iopub.status.idle":"2024-03-17T21:16:23.872840Z","shell.execute_reply":"2024-03-17T21:16:23.871265Z","shell.execute_reply.started":"2024-03-17T21:16:23.856794Z"},"trusted":true},"outputs":[],"source":["@contextmanager\n","def timer(name):\n","    t0 = time.time()\n","    yield\n","    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.879386Z","iopub.status.busy":"2024-03-17T21:16:23.878507Z","iopub.status.idle":"2024-03-17T21:16:23.890927Z","shell.execute_reply":"2024-03-17T21:16:23.888796Z","shell.execute_reply.started":"2024-03-17T21:16:23.879343Z"},"trusted":true},"outputs":[],"source":["def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n","    \n","\n","    temp=base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]] \\\n","        .sort_values(\"WEEK_NUM\") \\\n","        .groupby(\"WEEK_NUM\").mean()\n","   \n","    week_nums_to_drop = temp[(temp[\"target\"] == 0) | (temp[\"target\"] == 1)].index.tolist()\n","\n","    base_filtered = base[~base[\"WEEK_NUM\"].isin(week_nums_to_drop)]\n","\n","    # Apply the aggregator\n","    gini_in_time = base_filtered.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]] \\\n","        .sort_values(\"WEEK_NUM\") \\\n","        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]] \\\n","        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n","\n","    \n","\n","    x = np.arange(len(gini_in_time))\n","    y = gini_in_time\n","    a, b = np.polyfit(x, y, 1)\n","    y_hat = a * x + b\n","    residuals = y - y_hat\n","    res_std = np.std(residuals)\n","    avg_gini = np.nanmean(gini_in_time)  # Use np.nanmean to handle NaN values\n","    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std"]},{"cell_type":"markdown","metadata":{},"source":["#  **MODEL**"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.893947Z","iopub.status.busy":"2024-03-17T21:16:23.892897Z","iopub.status.idle":"2024-03-17T21:16:23.915699Z","shell.execute_reply":"2024-03-17T21:16:23.913582Z","shell.execute_reply.started":"2024-03-17T21:16:23.893906Z"},"trusted":true},"outputs":[],"source":["class VotingModel(BaseEstimator, RegressorMixin):\n","    def __init__(self, estimators):\n","        super().__init__()\n","        self.estimators = estimators\n","        \n","    def fit(self, X, y=None):\n","        return self\n","    \n","    def predict(self, X):\n","        y_preds = [estimator.predict(X) for estimator in self.estimators]\n","        return np.mean(y_preds, axis=0)\n","    \n","    def predict_proba(self, X):\n","        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n","        # Use tqdm to create a progress bar during the prediction\n","        with tqdm(total=len(self.estimators), desc=\"Predicting\", unit=\" models\") as pbar:\n","            for i, estimator in enumerate(self.estimators):\n","                y_preds[i] = estimator.predict_proba(X)\n","                pbar.update(1)  # Update the progress bar\n","        return np.mean(y_preds, axis=0)\n","\n","    \n","    def get_splits(self, aggregation_method=np.mean):\n","        \n","        feature_importances_list=[]\n","        for x in self.estimators:\n","            feature_importances_list.append(x.booster_.feature_importance(importance_type='split'))\n","            \n","        # Aggregate feature importances across all models\n","        if all(importances is not None for importances in feature_importances_list):\n","            combined_importances = aggregation_method(feature_importances_list, axis=0)\n","        else:\n","            combined_importances = None   \n","        return combined_importances\n","    \n","    \n","    def get_gains(self, aggregation_method=np.mean):\n","        \n","        feature_importances_list=[]\n","        for model in self.estimators:\n","            feature_importances_list.append(x.booster_.feature_importance(importance_type='gain'))\n","            \n","        # Aggregate feature importances across all models\n","        if all(importances is not None for importances in feature_importances_list):\n","            combined_importances = aggregation_method(feature_importances_list, axis=0)\n","        else:\n","            combined_importances = None\n","              \n","        return combined_importances\n","    \n","    def get_features_importances_df(self, df):\n","        del_features = ['target', 'case_id']\n","        predictors = list(filter(lambda v: v not in del_features, df.columns))\n","        importance_df = pd.DataFrame()\n","        eval_results = dict()\n","        for model in self.estimators:\n","            fold_importance = pd.DataFrame()\n","            fold_importance[\"feature\"] = predictors\n","            fold_importance[\"gain\"] = model.booster_.feature_importance(importance_type='gain')\n","            fold_importance[\"split\"] = model.booster_.feature_importance(importance_type='split')\n","            importance_df = pd.concat([importance_df, fold_importance], axis=0)\n","        return importance_df"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:23.918668Z","iopub.status.busy":"2024-03-17T21:16:23.918100Z","iopub.status.idle":"2024-03-17T21:16:24.064416Z","shell.execute_reply":"2024-03-17T21:16:24.062724Z","shell.execute_reply.started":"2024-03-17T21:16:23.918620Z"},"trusted":true},"outputs":[],"source":["def kfold_lightgbm_sklearn(data, categorical_feature = None):\n","    start_time = time.time()\n","    df = data[data['target'].notnull()]\n","    test = data[data['target'].isnull()]\n","    print(\"Train/valid shape: {}, test shape: {}\".format(df.shape, test.shape))\n","    del_features = ['target', 'case_id']\n","    predictors = list(filter(lambda v: v not in del_features, df.columns))\n","\n","    if not STRATIFIED_KFOLD:\n","        folds = KFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n","    else:\n","        folds = StratifiedKFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n","    \n","        # Hold oof predictions, test predictions, feature importance and training/valid auc\n","    oof_preds = np.zeros(df.shape[0])\n","    \n","    importance_df = pd.DataFrame()\n","    eval_results = dict()\n","    \n","    fitted_models = []\n","    with tqdm(total=NUM_FOLDS) as pbar:\n","        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[predictors], df['target'])):\n","            train_x, train_y = df[predictors].iloc[train_idx], df['target'].iloc[train_idx]\n","            valid_x, valid_y = df[predictors].iloc[valid_idx], df['target'].iloc[valid_idx]\n","\n","            params = {'random_state': RANDOM_SEED, 'nthread': NUM_THREADS}\n","            clf = LGBMClassifier(**{**params, **LIGHTGBM_PARAMS})\n","\n","\n","            if not categorical_feature:\n","                    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n","                            eval_metric='auc' )\n","            else:\n","                clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],eval_metric='auc',\n","                        feature_name= list(df[predictors].columns), categorical_feature= categorical_feature)\n","\n","\n","            fitted_models.append(clf)\n","\n","            if EVALUATE_VALIDATION_SET:\n","                oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n","\n","\n","\n","                # Feature importance by GAIN and SPLIT\n","\n","            eval_results['train_{}'.format(n_fold+1)]  = clf.evals_result_['training']['auc']\n","            eval_results['valid_{}'.format(n_fold+1)] = clf.evals_result_['valid_1']['auc']\n","\n","            elapsed_time = time.time() - start_time\n","            remaining_time = elapsed_time * (NUM_FOLDS - n_fold - 1) / (n_fold + 1)\n","            print('Fold %2d AUC : %.6f. Elapsed time: %.2f seconds. Remaining time: %.2f seconds.'\n","                  % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx]), elapsed_time, remaining_time))\n","            del clf, train_x, train_y, valid_x, valid_y\n","            gc.collect()\n","            pbar.update(1)\n","            \n","    print('Full AUC score %.6f' % roc_auc_score(df['target'], oof_preds))\n","    # Get the average feature importance between folds\n","    \n","    \n","    \n","    if len(df)>0:\n","        base=get_base(DATA_DIRECTORY, len(df))\n","        base, cat_cols = to_pandas(base)\n","        base=base[base['target'].notnull()]\n","        base['score']= oof_preds\n","        gini_score = gini_stability(base)\n","        print(\"Gini Score of the valid set:\", gini_score)\n","    \n","    \n","    \n","    \n","    # Save feature importance, test predictions and oof predictions as csv\n","    if GENERATE_SUBMISSION_FILES:\n","\n","        # Generate oof csv\n","        oof = pd.DataFrame()\n","        oof['case_id'] = df['case_id'].copy()\n","        df['PREDICTIONS'] = oof_preds.copy()\n","        df['target'] = df['target'].copy()\n","        df.to_csv('oof{}.csv'.format(SUBMISSION_SUFIX), index=False)\n","        \n","        \n","        \n","    model = VotingModel(fitted_models)\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# **SUBMISSION**"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:24.068487Z","iopub.status.busy":"2024-03-17T21:16:24.066058Z","iopub.status.idle":"2024-03-17T21:16:24.083767Z","shell.execute_reply":"2024-03-17T21:16:24.082094Z","shell.execute_reply.started":"2024-03-17T21:16:24.068415Z"},"trusted":true},"outputs":[],"source":["def generate_submission_file(data, model):\n","    \n","    test = data[data['target'].isnull()]\n","    del_features = ['target', 'case_id']\n","    predictors = list(filter(lambda v: v not in del_features, data.columns))\n","    y_pred = pd.Series(model.predict_proba(test[predictors])[:, 1], index=test[predictors].index)    \n","    df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n","    df_subm = df_subm.set_index(\"case_id\")\n","    df_subm[\"score\"] = y_pred\n","    df_subm.to_csv(\"submission.csv\")\n","    \n","    return True\n","    \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# **EVALUATE FEATURES IMPORTANCES**"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:24.086258Z","iopub.status.busy":"2024-03-17T21:16:24.085518Z","iopub.status.idle":"2024-03-17T21:16:24.098241Z","shell.execute_reply":"2024-03-17T21:16:24.096340Z","shell.execute_reply.started":"2024-03-17T21:16:24.086206Z"},"trusted":true},"outputs":[],"source":["def get_features_importances(data, model):\n","    importance_df = model.get_features_importances_df(data)\n","    mean_importance = importance_df.groupby('feature').mean().reset_index()\n","    mean_importance.sort_values(by= 'gain', ascending=False, inplace=True)\n","    mean_importance.to_csv('feature_importance{}.csv'.format(SUBMISSION_SUFIX), index=False)\n","    return True"]},{"cell_type":"markdown","metadata":{},"source":["# **FEATURE ENGINEERING FUNCTION**"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:24.100974Z","iopub.status.busy":"2024-03-17T21:16:24.100072Z","iopub.status.idle":"2024-03-17T21:16:24.119860Z","shell.execute_reply":"2024-03-17T21:16:24.117575Z","shell.execute_reply.started":"2024-03-17T21:16:24.100933Z"},"trusted":true},"outputs":[],"source":["def feature_engineering(df):\n","    df = df.pipe(Pipeline.handle_dates) \n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["# **GET FUNCTIONS**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:24.123720Z","iopub.status.busy":"2024-03-17T21:16:24.122065Z","iopub.status.idle":"2024-03-17T21:16:24.135134Z","shell.execute_reply":"2024-03-17T21:16:24.133911Z","shell.execute_reply.started":"2024-03-17T21:16:24.123406Z"},"trusted":true},"outputs":[],"source":["def group(df_to_agg, prefix, aggregations, aggregate_by='case_id'):\n","    # Create a dictionary mapping aggregation functions to their string representations\n","    func_mapping = {\n","        'min': pl.min,\n","        'max': pl.max,\n","        'mean': pl.mean,\n","        'sum': pl.sum\n","    }\n","    \n","# Perform the aggregation\n","    agg_df = df_to_agg.group_by(aggregate_by).agg(**{\n","        f\"{func}_{col}\": func_mapping[func](col) for col, funcs in aggregations.items() for func in funcs\n","    })\n","    '''\n","    # Rename columns\n","    for col, funcs in aggregations.items():\n","        for func in funcs:\n","            old_name = f\"{col}_{func}\"\n","            new_name = f\"{prefix}{col}_{func.upper()}\"\n","            agg_df = agg_df.select(pl.col(old_name).alias(new_name))\n","    '''\n","    return agg_df"]},{"cell_type":"markdown","metadata":{},"source":["### get_base()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:24.138703Z","iopub.status.busy":"2024-03-17T21:16:24.137350Z","iopub.status.idle":"2024-03-17T21:16:24.152691Z","shell.execute_reply":"2024-03-17T21:16:24.151502Z","shell.execute_reply.started":"2024-03-17T21:16:24.138640Z"},"trusted":true},"outputs":[],"source":["def get_base(path, num_rows = None):\n","    # Read the Parquet file using scan() method\n","    train={}\n","    test={}\n","    \n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_base.parquet'))\n","        \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_base.parquet')).limit(num_rows) \n","        \n","    test = pl.read_parquet(os.path.join(path, 'test/test_base.parquet'))    \n","    length=len(test)\n","    nan_series=pl.Series([None] * length)\n","    test = test.select(pl.col(\"*\"), nan_series.alias(\"target\"))\n","    df=pl.concat([train, test])\n","    df = df.with_columns(pl.col('date_decision').cast(pl.Date))\n","    return df"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:24.154851Z","iopub.status.busy":"2024-03-17T21:16:24.154017Z","iopub.status.idle":"2024-03-17T21:16:24.565733Z","shell.execute_reply":"2024-03-17T21:16:24.564184Z","shell.execute_reply.started":"2024-03-17T21:16:24.154817Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (10010, 5)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n","date_decision                                      Date                           0.00%\n","MONTH                                              Int64                          0.00%\n","WEEK_NUM                                           Int64                          0.00%\n","target                                             Int64                          0.10%\n"]}],"source":["A=get_base(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_static()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:24.568076Z","iopub.status.busy":"2024-03-17T21:16:24.567396Z","iopub.status.idle":"2024-03-17T21:16:24.576676Z","shell.execute_reply":"2024-03-17T21:16:24.575368Z","shell.execute_reply.started":"2024-03-17T21:16:24.568045Z"},"trusted":true},"outputs":[],"source":["def get_static(path, num_rows = None):\n","# Read the Parquet file using scan() method\n","    chunks = []\n","    for path in glob(DATA_DIRECTORY+str('train/train_static_0_*.parquet')):\n","        chunks.append(pl.read_parquet(path).pipe(Pipeline.set_table_dtypes))\n","    train = (pl.concat(chunks, how=\"vertical_relaxed\")).pipe(Pipeline.filter_cols)\n","    \n","    if num_rows!= None:\n","        df1 = train.slice(0,num_rows)\n","        df2 = train.slice(num_rows,len(train))\n","        \n","        train=df1\n","        del df2\n","    \n","    chunks = []\n","    for path in glob(DATA_DIRECTORY+str('test/test_static_0_*.parquet')):\n","        chunks.append(pl.read_parquet(path).pipe(Pipeline.set_table_dtypes))\n","        test = pl.concat(chunks, how=\"vertical_relaxed\")\n","    \n","    \n","    columns_to_keep = train.columns\n","\n","# Find columns in 'test' that are not in 'train'\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","\n","# Drop columns from 'test' that are not in 'train'\n","    test = test.drop(columns_to_remove)\n","    df=pl.concat([train, test])\n","    return df"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:24.578582Z","iopub.status.busy":"2024-03-17T21:16:24.578111Z","iopub.status.idle":"2024-03-17T21:16:31.934244Z","shell.execute_reply":"2024-03-17T21:16:31.932377Z","shell.execute_reply.started":"2024-03-17T21:16:24.578548Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (10030, 156)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n","actualdpdtolerance_344P                            Float64                        88.05%\n","amtinstpaidbefduel24m_4187115A                     Float64                        99.10%\n","annuity_780A                                       Float64                        0.00%\n","annuitynextmonth_57A                               Float64                        0.00%\n","applicationcnt_361L                                Float64                        0.00%\n","applications30d_658L                               Float64                        0.00%\n","applicationscnt_1086L                              Float64                        0.00%\n","applicationscnt_464L                               Float64                        0.00%\n","applicationscnt_629L                               Float64                        0.00%\n","applicationscnt_867L                               Float64                        0.00%\n","avgdbddpdlast24m_3658932P                          Float64                        96.57%\n","avgdbddpdlast3m_4187120P                           Float64                        99.24%\n","avgdbdtollast24m_4525197P                          Float64                        99.79%\n","avgdpdtolclosure24_3658938P                        Float64                        96.54%\n","avginstallast24m_3658937A                          Float64                        96.57%\n","avglnamtstart24m_4525187A                          Float64                        99.94%\n","avgmaxdpdlast9m_3716943P                           Float64                        96.63%\n","avgoutstandbalancel6m_4187114A                     Float64                        99.17%\n","avgpmtlast12m_4525200A                             Float64                        99.83%\n","bankacctype_710L                                   String                         19.02%\n","cardtype_51L                                       String                         84.06%\n","clientscnt12m_3712952L                             Float64                        0.00%\n","clientscnt3m_3712950L                              Float64                        0.00%\n","clientscnt6m_3712949L                              Float64                        0.00%\n","clientscnt_100L                                    Float64                        0.00%\n","clientscnt_1022L                                   Float64                        0.00%\n","clientscnt_1071L                                   Float64                        0.00%\n","clientscnt_1130L                                   Float64                        0.00%\n","clientscnt_157L                                    Float64                        0.00%\n","clientscnt_257L                                    Float64                        0.00%\n","clientscnt_304L                                    Float64                        0.00%\n","clientscnt_360L                                    Float64                        0.00%\n","clientscnt_493L                                    Float64                        0.00%\n","clientscnt_533L                                    Float64                        0.00%\n","clientscnt_887L                                    Float64                        0.00%\n","clientscnt_946L                                    Float64                        0.00%\n","cntincpaycont9m_3716944L                           Float64                        96.47%\n","cntpmts24_3658933L                                 Float64                        96.47%\n","commnoinclast6m_3546845L                           Float64                        81.44%\n","credamount_770A                                    Float64                        0.00%\n","credtype_322L                                      String                         0.00%\n","currdebt_22A                                       Float64                        0.00%\n","currdebtcredtyperange_828A                         Float64                        0.00%\n","datefirstoffer_1144D                               Date                           99.79%\n","datelastinstal40dpd_247D                           Date                           99.97%\n","datelastunpaid_3546854D                            Date                           99.10%\n","daysoverduetolerancedd_3976961L                    Float64                        96.45%\n","deferredmnthsnum_166L                              Float64                        0.26%\n","disbursedcredamount_1113A                          Float64                        0.00%\n","disbursementtype_67L                               String                         0.05%\n","downpmt_116A                                       Float64                        0.00%\n","dtlastpmtallstes_4499206D                          Date                           99.89%\n","eir_270L                                           Float64                        15.94%\n","equalitydataagreement_891L                         Boolean                        94.78%\n","firstclxcampaign_1125D                             Date                           99.79%\n","firstdatedue_489D                                  Date                           96.60%\n","homephncnt_628L                                    Float64                        0.00%\n","inittransactionamount_650A                         Float64                        84.06%\n","inittransactioncode_186L                           String                         0.00%\n","interestrate_311L                                  Float64                        15.94%\n","isbidproduct_1095L                                 Boolean                        0.00%\n","isdebitcard_729L                                   Boolean                        83.80%\n","lastactivateddate_801D                             Date                           96.45%\n","lastapplicationdate_877D                           Date                           58.40%\n","lastapprcommoditycat_1041M                         String                         0.00%\n","lastapprcredamount_781A                            Float64                        95.20%\n","lastapprdate_640D                                  Date                           95.20%\n","lastcancelreason_561M                              String                         0.00%\n","lastdelinqdate_224D                                Date                           99.47%\n","lastrejectcommoditycat_161M                        String                         0.00%\n","lastrejectcommodtypec_5251769M                     String                         0.00%\n","lastrejectcredamount_222A                          Float64                        64.89%\n","lastrejectdate_50D                                 Date                           64.89%\n","lastrejectreason_759M                              String                         0.00%\n","lastrejectreasonclient_4145040M                    String                         0.00%\n","lastst_736L                                        String                         58.40%\n","maininc_215A                                       Float64                        96.56%\n","mastercontrelectronic_519L                         Float64                        58.08%\n","mastercontrexist_109L                              Float64                        58.08%\n","maxannuity_159A                                    Float64                        58.08%\n","maxdbddpdlast1m_3658939P                           Float64                        97.27%\n","maxdbddpdtollast12m_3658940P                       Float64                        96.61%\n","maxdbddpdtollast6m_4187119P                        Float64                        99.22%\n","maxdebt4_972A                                      Float64                        58.08%\n","maxdpdfrom6mto36m_3546853P                         Float64                        81.44%\n","maxdpdinstldate_3546855D                           Date                           99.03%\n","maxdpdinstlnum_3546846P                            Float64                        99.04%\n","maxdpdlast12m_727P                                 Float64                        58.08%\n","maxdpdlast24m_143P                                 Float64                        58.08%\n","maxdpdlast3m_392P                                  Float64                        58.08%\n","maxdpdlast6m_474P                                  Float64                        58.08%\n","maxdpdlast9m_1059P                                 Float64                        58.08%\n","maxdpdtolerance_374P                               Float64                        58.08%\n","maxinstallast24m_3658928A                          Float64                        96.57%\n","maxlnamtstart6m_4525199A                           Float64                        99.82%\n","maxoutstandbalancel12m_4187113A                    Float64                        99.16%\n","maxpmtlast3m_4525190A                              Float64                        99.88%\n","mindbddpdlast24m_3658935P                          Float64                        96.57%\n","mindbdtollast24m_4525191P                          Float64                        99.79%\n","mobilephncnt_593L                                  Float64                        0.00%\n","monthsannuity_845L                                 Float64                        96.45%\n","numactivecreds_622L                                Float64                        0.00%\n","numactivecredschannel_414L                         Float64                        0.00%\n","numactiverelcontr_750L                             Float64                        0.00%\n","numcontrs3months_479L                              Float64                        0.00%\n","numincomingpmts_3546848L                           Float64                        96.47%\n","numinstlallpaidearly3d_817L                        Float64                        95.47%\n","numinstls_657L                                     Float64                        0.00%\n","numinstlsallpaid_934L                              Float64                        95.47%\n","numinstlswithdpd10_728L                            Float64                        96.49%\n","numinstlswithdpd5_4187116L                         Float64                        99.10%\n","numinstlswithoutdpd_562L                           Float64                        96.49%\n","numinstmatpaidtearly2d_4499204L                    Float64                        99.76%\n","numinstpaid_4499208L                               Float64                        99.76%\n","numinstpaidearly3d_3546850L                        Float64                        95.47%\n","numinstpaidearly3dest_4493216L                     Float64                        99.76%\n","numinstpaidearly5d_1087L                           Float64                        96.45%\n","numinstpaidearly5dest_4493211L                     Float64                        99.76%\n","numinstpaidearly5dobd_4499205L                     Float64                        99.76%\n","numinstpaidearly_338L                              Float64                        96.45%\n","numinstpaidearlyest_4493214L                       Float64                        99.76%\n","numinstpaidlastcontr_4325080L                      Float64                        99.76%\n","numinstpaidlate1d_3546852L                         Float64                        96.45%\n","numinstregularpaid_973L                            Float64                        96.45%\n","numinstregularpaidest_4493210L                     Float64                        99.76%\n","numinsttopaygr_769L                                Float64                        96.45%\n","numinsttopaygrest_4493213L                         Float64                        99.76%\n","numinstunpaidmax_3546851L                          Float64                        96.45%\n","numinstunpaidmaxest_4493212L                       Float64                        99.76%\n","numnotactivated_1143L                              Float64                        0.00%\n","numpmtchanneldd_318L                               Float64                        0.00%\n","numrejects9m_859L                                  Float64                        0.00%\n","opencred_647L                                      Boolean                        58.40%\n","paytype1st_925L                                    String                         0.22%\n","paytype_783L                                       String                         0.22%\n","pctinstlsallpaidearl3d_427L                        Float64                        96.54%\n","pctinstlsallpaidlat10d_839L                        Float64                        96.62%\n","pctinstlsallpaidlate1d_3546856L                    Float64                        96.54%\n","pctinstlsallpaidlate4d_3546849L                    Float64                        96.57%\n","pctinstlsallpaidlate6d_3546844L                    Float64                        96.57%\n","pmtnum_254L                                        Float64                        14.80%\n","posfpd10lastmonth_333P                             Float64                        1.14%\n","posfpd30lastmonth_3976960P                         Float64                        10.55%\n","posfstqpd30lastmonth_3976962P                      Float64                        15.46%\n","price_1097A                                        Float64                        87.91%\n","sellerplacecnt_915L                                Float64                        0.00%\n","sellerplacescnt_216L                               Float64                        0.00%\n","sumoutstandtotal_3546847A                          Float64                        95.36%\n","sumoutstandtotalest_4493215A                       Float64                        99.76%\n","totaldebt_9A                                       Float64                        0.00%\n","totalsettled_863A                                  Float64                        0.00%\n","totinstallast1m_4525188A                           Float64                        99.88%\n","twobodfilling_608L                                 String                         0.10%\n","typesuite_864L                                     String                         19.92%\n","validfrom_1069D                                    Date                           99.98%\n"]}],"source":["A=get_static(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_static_cb()"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:31.937069Z","iopub.status.busy":"2024-03-17T21:16:31.936258Z","iopub.status.idle":"2024-03-17T21:16:31.946579Z","shell.execute_reply":"2024-03-17T21:16:31.945373Z","shell.execute_reply.started":"2024-03-17T21:16:31.937016Z"},"trusted":true},"outputs":[],"source":["def get_static_cb(path, num_rows = None):\n","    \n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_static_cb_0.parquet')).pipe(Pipeline.set_table_dtypes)\n","        \n","        \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_static_cb_0.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","       \n","    \n","    test = pl.read_parquet(os.path.join(path, 'test/test_static_cb_0.parquet')).pipe(Pipeline.set_table_dtypes)\n","    \n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    return df"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:31.949369Z","iopub.status.busy":"2024-03-17T21:16:31.948225Z","iopub.status.idle":"2024-03-17T21:16:32.921495Z","shell.execute_reply":"2024-03-17T21:16:32.919997Z","shell.execute_reply.started":"2024-03-17T21:16:31.949328Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (10010, 23)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n","assignmentdate_238D                                Date                           65.48%\n","birthdate_574D                                     Date                           0.71%\n","dateofbirth_337D                                   Date                           31.05%\n","days120_123L                                       Float64                        31.05%\n","days180_256L                                       Float64                        31.05%\n","days30_165L                                        Float64                        31.05%\n","days360_512L                                       Float64                        31.05%\n","days90_310L                                        Float64                        31.05%\n","education_1103M                                    String                         0.00%\n","education_88M                                      String                         0.00%\n","firstquarter_103L                                  Float64                        31.05%\n","fourthquarter_440L                                 Float64                        31.05%\n","maritalst_385M                                     String                         0.00%\n","maritalst_893M                                     String                         0.00%\n","numberofqueries_373L                               Float64                        31.05%\n","pmtaverage_3A                                      Float64                        65.30%\n","pmtcount_693L                                      Float64                        65.30%\n","pmtscount_423L                                     Float64                        35.96%\n","pmtssum_45A                                        Float64                        35.96%\n","responsedate_1012D                                 Date                           0.71%\n","secondquarter_766L                                 Float64                        31.05%\n","thirdquarter_1082L                                 Float64                        31.05%\n"]}],"source":["A=get_static_cb(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_applprev1(DATA_DIRECTORY, num_rows=num_rows)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:32.923154Z","iopub.status.busy":"2024-03-17T21:16:32.922800Z","iopub.status.idle":"2024-03-17T21:16:32.933753Z","shell.execute_reply":"2024-03-17T21:16:32.932216Z","shell.execute_reply.started":"2024-03-17T21:16:32.923128Z"},"trusted":true},"outputs":[],"source":["def get_applprev1(path, num_rows = None):\n","    \n","    \n","    chunks = []\n","    for path in glob(DATA_DIRECTORY+str('train/train_applprev_1_*.parquet')):\n","        chunks.append(pl.read_parquet(path).pipe(Pipeline.set_table_dtypes))\n","    train = pl.concat(chunks, how=\"vertical_relaxed\").pipe(Pipeline.filter_cols)\n","    \n","    \n","    if num_rows!= None:\n","        df1 = train.slice(0,num_rows)\n","        df2 = train.slice(num_rows,len(train))\n","\n","        train=df1\n","        del df2   \n","    \n","    chunks = []\n","    for path in glob(DATA_DIRECTORY+str('test/test_applprev_1_*.parquet')):\n","        chunks.append(pl.read_parquet(path).pipe(Pipeline.set_table_dtypes))\n","        test = pl.concat(chunks, how=\"vertical_relaxed\")\n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', APPLPREV1_AGG)\n","    del df \n","    return agg_df"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:32.935897Z","iopub.status.busy":"2024-03-17T21:16:32.935499Z","iopub.status.idle":"2024-03-17T21:16:44.597881Z","shell.execute_reply":"2024-03-17T21:16:44.596598Z","shell.execute_reply.started":"2024-03-17T21:16:32.935867Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (4653, 11)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n","min_annuity_853A                                   Float64                        1.59%\n","max_annuity_853A                                   Float64                        1.59%\n","mean_annuity_853A                                  Float64                        1.59%\n","max_currdebt_94A                                   Float64                        72.25%\n","mean_currdebt_94A                                  Float64                        72.25%\n","sum_currdebt_94A                                   Float64                        0.00%\n","max_mainoccupationinc_437A                         Float64                        0.04%\n","mean_mainoccupationinc_437A                        Float64                        0.04%\n","sum_mainoccupationinc_437A                         Float64                        0.00%\n","mean_cancelreason_3545846M                         String                         100.00%\n"]}],"source":["A=get_applprev1(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_applprev2(DATA_DIRECTORY, num_rows=num_rows)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:44.599746Z","iopub.status.busy":"2024-03-17T21:16:44.599393Z","iopub.status.idle":"2024-03-17T21:16:44.608602Z","shell.execute_reply":"2024-03-17T21:16:44.607120Z","shell.execute_reply.started":"2024-03-17T21:16:44.599719Z"},"trusted":true},"outputs":[],"source":["def get_applprev2(path, num_rows = None):\n","    train={}\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_applprev_2.parquet')).pipe(Pipeline.set_table_dtypes)\n","        \n","     \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_applprev_2.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","       \n","    \n","    \n","    test = pl.read_parquet(os.path.join(path, 'test/test_applprev_2.parquet')).pipe(Pipeline.set_table_dtypes)\n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', APPLPREV2_AGG)\n","    del df \n","    return agg_df"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:44.611419Z","iopub.status.busy":"2024-03-17T21:16:44.610678Z","iopub.status.idle":"2024-03-17T21:16:46.144430Z","shell.execute_reply":"2024-03-17T21:16:46.142978Z","shell.execute_reply.started":"2024-03-17T21:16:44.611367Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (2483, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_applprev2(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_person1"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:46.147885Z","iopub.status.busy":"2024-03-17T21:16:46.147381Z","iopub.status.idle":"2024-03-17T21:16:46.156541Z","shell.execute_reply":"2024-03-17T21:16:46.155227Z","shell.execute_reply.started":"2024-03-17T21:16:46.147846Z"},"trusted":true},"outputs":[],"source":["def get_person1(path, num_rows = None):\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_person_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","        \n","    \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_person_1.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","      \n","    \n","    \n","    test = pl.read_parquet(os.path.join(path, 'test/test_person_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', PERSON1_AGG)\n","    del df\n","    \n","    return agg_df"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:46.163397Z","iopub.status.busy":"2024-03-17T21:16:46.162535Z","iopub.status.idle":"2024-03-17T21:16:48.058486Z","shell.execute_reply":"2024-03-17T21:16:48.057054Z","shell.execute_reply.started":"2024-03-17T21:16:46.163351Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (2811, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_person1(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_person2"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.060922Z","iopub.status.busy":"2024-03-17T21:16:48.059793Z","iopub.status.idle":"2024-03-17T21:16:48.069875Z","shell.execute_reply":"2024-03-17T21:16:48.068026Z","shell.execute_reply.started":"2024-03-17T21:16:48.060886Z"},"trusted":true},"outputs":[],"source":["def get_person2(path, num_rows = None):\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_person_2.parquet')).pipe(Pipeline.set_table_dtypes)\n","        \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_person_2.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","        \n","    test = pl.read_parquet(os.path.join(path, 'test/test_person_2.parquet')).pipe(Pipeline.set_table_dtypes)\n","    \n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', PERSON2_AGG)\n","    del df\n","    \n","    return agg_df"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.072838Z","iopub.status.busy":"2024-03-17T21:16:48.072238Z","iopub.status.idle":"2024-03-17T21:16:48.422231Z","shell.execute_reply":"2024-03-17T21:16:48.420691Z","shell.execute_reply.started":"2024-03-17T21:16:48.072793Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (8622, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_person2(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### other"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.424671Z","iopub.status.busy":"2024-03-17T21:16:48.424259Z","iopub.status.idle":"2024-03-17T21:16:48.433889Z","shell.execute_reply":"2024-03-17T21:16:48.432564Z","shell.execute_reply.started":"2024-03-17T21:16:48.424641Z"},"trusted":true},"outputs":[],"source":["def get_other(path, num_rows = None):\n","     # Read the Parquet file using scan() method\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_other_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","        \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_other_1.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","         \n","    test = pl.read_parquet(os.path.join(path, 'test/test_other_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","    \n","    \n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', OTHER_AGG)\n","    del df\n","    \n","    return agg_df"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.436676Z","iopub.status.busy":"2024-03-17T21:16:48.435593Z","iopub.status.idle":"2024-03-17T21:16:48.478765Z","shell.execute_reply":"2024-03-17T21:16:48.477298Z","shell.execute_reply.started":"2024-03-17T21:16:48.436623Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (10009, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_other(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["## get_debitcard"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.481024Z","iopub.status.busy":"2024-03-17T21:16:48.480489Z","iopub.status.idle":"2024-03-17T21:16:48.490553Z","shell.execute_reply":"2024-03-17T21:16:48.489225Z","shell.execute_reply.started":"2024-03-17T21:16:48.480969Z"},"trusted":true},"outputs":[],"source":["def get_debitcard(path, num_rows = None):\n","    # Read the Parquet file using scan() method\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_debitcard_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","        \n","     \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_debitcard_1.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","      \n","        \n","    test = pl.read_parquet(os.path.join(path, 'test/test_debitcard_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","    \n","    \n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', DEBITCARD_AGG)\n","    del df\n","    \n","    return agg_df"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.492394Z","iopub.status.busy":"2024-03-17T21:16:48.491815Z","iopub.status.idle":"2024-03-17T21:16:48.535970Z","shell.execute_reply":"2024-03-17T21:16:48.534715Z","shell.execute_reply.started":"2024-03-17T21:16:48.492362Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (6761, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_debitcard(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_tax_registry_a"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.537966Z","iopub.status.busy":"2024-03-17T21:16:48.537369Z","iopub.status.idle":"2024-03-17T21:16:48.546509Z","shell.execute_reply":"2024-03-17T21:16:48.544980Z","shell.execute_reply.started":"2024-03-17T21:16:48.537935Z"},"trusted":true},"outputs":[],"source":["def get_tax_registry_a(path, num_rows = None):\n","    \n","    # Read the Parquet file using scan() method\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_a_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","        \n","    \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_a_1.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","  \n","    \n","    \n","    test = pl.read_parquet(os.path.join(path, 'test/test_tax_registry_a_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', TAX_REGISTRY_A_AGG)    \n","    del df\n","    \n","    return agg_df"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.549185Z","iopub.status.busy":"2024-03-17T21:16:48.548430Z","iopub.status.idle":"2024-03-17T21:16:48.944948Z","shell.execute_reply":"2024-03-17T21:16:48.943496Z","shell.execute_reply.started":"2024-03-17T21:16:48.549118Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (1518, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_tax_registry_a(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_tax_registry_b"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.946950Z","iopub.status.busy":"2024-03-17T21:16:48.946576Z","iopub.status.idle":"2024-03-17T21:16:48.956929Z","shell.execute_reply":"2024-03-17T21:16:48.955396Z","shell.execute_reply.started":"2024-03-17T21:16:48.946923Z"},"trusted":true},"outputs":[],"source":["def get_tax_registry_b(path, num_rows = None):\n","    # Read the Parquet file using scan() method\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_b_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","        \n","        \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_b_1.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","        \n","    \n","    test = pl.read_parquet(os.path.join(path, 'test/test_tax_registry_b_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","    \n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', TAX_REGISTRY_B_AGG) \n","    del df\n","    \n","    return agg_df"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:48.958910Z","iopub.status.busy":"2024-03-17T21:16:48.958520Z","iopub.status.idle":"2024-03-17T21:16:49.123177Z","shell.execute_reply":"2024-03-17T21:16:49.121928Z","shell.execute_reply.started":"2024-03-17T21:16:48.958882Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (1389, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_tax_registry_b(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_tax_registry_c"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:49.125654Z","iopub.status.busy":"2024-03-17T21:16:49.124991Z","iopub.status.idle":"2024-03-17T21:16:49.134782Z","shell.execute_reply":"2024-03-17T21:16:49.133521Z","shell.execute_reply.started":"2024-03-17T21:16:49.125610Z"},"trusted":true},"outputs":[],"source":["def get_tax_registry_c(path, num_rows = None):\n","     # Read the Parquet file using scan() method\n","# Read the Parquet file using scan() method\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_c_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","    \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_c_1.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","        \n","    \n","    test = pl.read_parquet(os.path.join(path, 'test/test_tax_registry_c_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","    \n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', TAX_REGISTRY_C_AGG)    \n","    del df\n","    \n","    return agg_df"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:49.136946Z","iopub.status.busy":"2024-03-17T21:16:49.136370Z","iopub.status.idle":"2024-03-17T21:16:49.641695Z","shell.execute_reply":"2024-03-17T21:16:49.640221Z","shell.execute_reply.started":"2024-03-17T21:16:49.136913Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (1645, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_tax_registry_c(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_credit_bureau_a_1"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:49.644974Z","iopub.status.busy":"2024-03-17T21:16:49.643605Z","iopub.status.idle":"2024-03-17T21:16:49.654158Z","shell.execute_reply":"2024-03-17T21:16:49.652999Z","shell.execute_reply.started":"2024-03-17T21:16:49.644936Z"},"trusted":true},"outputs":[],"source":["def get_credit_bureau_a_1(path, num_rows = None):\n","    chunks = []\n","    for path in glob(DATA_DIRECTORY+str('train/train_credit_bureau_a_1_*.parquet')):\n","        chunks.append(pl.read_parquet(path).pipe(Pipeline.set_table_dtypes))\n","    train = pl.concat(chunks, how=\"vertical_relaxed\").pipe(Pipeline.filter_cols)\n","    if num_rows!= None:\n","        df1 = train.slice(0,num_rows)\n","        df2 = train.slice(num_rows,len(train))\n","        \n","        train=df1\n","        del df2\n","    \n","    \n","    chunks = []\n","    for path in glob(DATA_DIRECTORY+str('test/test_credit_bureau_a_1_*.parquet')):\n","        chunks.append(pl.read_parquet(path).pipe(Pipeline.set_table_dtypes))\n","        test = pl.concat(chunks, how=\"vertical_relaxed\")\n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', CREDIT_BUREAU_A_1_AGG) \n","    del df\n","    \n","    return agg_df"]},{"cell_type":"markdown","metadata":{},"source":["### get_credit_bureau_b_1"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:49.656532Z","iopub.status.busy":"2024-03-17T21:16:49.655981Z","iopub.status.idle":"2024-03-17T21:16:49.669599Z","shell.execute_reply":"2024-03-17T21:16:49.667592Z","shell.execute_reply.started":"2024-03-17T21:16:49.656483Z"},"trusted":true},"outputs":[],"source":["def get_credit_bureau_b_1(path, num_rows = None):\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","        \n","        \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_1.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","   \n","    \n","    test = pl.read_parquet(os.path.join(path, 'test/test_credit_bureau_b_1.parquet')).pipe(Pipeline.set_table_dtypes)\n","    \n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","\n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', CREDIT_BUREAU_B_1_AGG) \n","    \n","    \n","    del df\n","    \n","    return agg_df"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:49.671311Z","iopub.status.busy":"2024-03-17T21:16:49.670932Z","iopub.status.idle":"2024-03-17T21:16:49.786337Z","shell.execute_reply":"2024-03-17T21:16:49.784952Z","shell.execute_reply.started":"2024-03-17T21:16:49.671283Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (4125, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_credit_bureau_b_1(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["### get_credit_bureau_a_2"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:49.789095Z","iopub.status.busy":"2024-03-17T21:16:49.787865Z","iopub.status.idle":"2024-03-17T21:16:49.797655Z","shell.execute_reply":"2024-03-17T21:16:49.796361Z","shell.execute_reply.started":"2024-03-17T21:16:49.789056Z"},"trusted":true},"outputs":[],"source":["def get_credit_bureau_a_2(path, num_rows = None):\n","    chunks = []\n","    for path in glob(DATA_DIRECTORY+str('train/train_credit_bureau_a_2_*.parquet')):\n","        chunks.append(reduce_mem_usage(pl.read_parquet(path))) #.pipe(Pipeline.set_table_dtypes))\n","        print(path)\n","    train = pl.concat(chunks, how=\"vertical_relaxed\").pipe(Pipeline.filter_cols)\n","    \n","    '''\n","    if num_rows!= None:\n","        df1 = train.slice(0,num_rows)\n","        df2 = train.slice(num_rows,len(df))\n","        \n","        train=df1\n","        del df2\n","    \n","    '''\n","    chunks = []\n","    for path in glob(DATA_DIRECTORY+str('test/test_credit_bureau_a_2_*.parquet')):\n","        chunks.append(reduce_mem_usage(pl.read_parquet(path))) #.pipe(Pipeline.set_table_dtypes))\n","        test = pl.concat(chunks, how=\"vertical_relaxed\")\n","        print(path)\n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","    df=pl.concat([train, test])\n","    return df\n","                      \n","                      \n","   "]},{"cell_type":"markdown","metadata":{},"source":["### get_credit_bureau_b_2"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:49.799519Z","iopub.status.busy":"2024-03-17T21:16:49.798968Z","iopub.status.idle":"2024-03-17T21:16:49.811216Z","shell.execute_reply":"2024-03-17T21:16:49.809814Z","shell.execute_reply.started":"2024-03-17T21:16:49.799485Z"},"trusted":true},"outputs":[],"source":["def get_credit_bureau_b_2(path, num_rows = None):\n","    if num_rows == None:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_2.parquet')).pipe(Pipeline.set_table_dtypes)\n","   \n","    else:\n","        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_2.parquet')).limit(num_rows).pipe(Pipeline.set_table_dtypes)\n","\n","    \n","    test = pl.read_parquet(os.path.join(path, 'test/test_credit_bureau_b_2.parquet')).pipe(Pipeline.set_table_dtypes)\n","    \n","    train = train.pipe(Pipeline.filter_cols)\n","   \n","    columns_to_keep = train.columns\n","    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n","    test = test.drop(columns_to_remove)\n","    \n","    df=pl.concat([train, test])\n","    agg_df = group(df, '', CREDIT_BUREAU_B_2_AGG) \n","    \n","    del df\n","    \n","    return agg_df"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:49.813514Z","iopub.status.busy":"2024-03-17T21:16:49.812969Z","iopub.status.idle":"2024-03-17T21:16:49.965267Z","shell.execute_reply":"2024-03-17T21:16:49.963032Z","shell.execute_reply.started":"2024-03-17T21:16:49.813481Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame Shape: (358, 1)\n","------------------------------------------------------------\n","Column Name                                        Data Type                      NaN Percentage      \n","------------------------------------------------------------\n","case_id                                            Int64                          0.00%\n"]}],"source":["A=get_credit_bureau_b_2(DATA_DIRECTORY, 10000)\n","get_info(A)\n","del A"]},{"cell_type":"markdown","metadata":{},"source":["# **EXECUTION**"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T21:16:49.969260Z","iopub.status.busy":"2024-03-17T21:16:49.968396Z","iopub.status.idle":"2024-03-17T21:18:57.894393Z","shell.execute_reply":"2024-03-17T21:18:57.893541Z","shell.execute_reply.started":"2024-03-17T21:16:49.969210Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["base dataframe shape: (1121, 5)\n","base - done in 0s\n","static dataframe shape: (1141, 156)\n","static - done in 2s\n","static cb dataframe shape: (1121, 23)\n","static_cb - done in 0s\n","Previous applications depth 1 test dataframe shape: (553, 11)\n","Previous applications depth 1 test - done in 4s\n","Previous applications depth 2 test dataframe shape: (294, 1)\n","Previous applications depth 2 test - done in 1s\n","Person depth 1 test dataframe shape: (310, 1)\n","Person depth 1 test - done in 1s\n","Person depth 2 test dataframe shape: (976, 1)\n","Person depth 2 test - done in 0s\n","Other test dataframe shape: (1120, 1)\n","Other test - done in 0s\n","Debit card test dataframe shape: (792, 1)\n","Debit card test - done in 0s\n","Tax registry a test dataframe shape: (171, 1)\n","Tax registry a test - done in 0s\n","Tax registry b test dataframe shape: (165, 1)\n","Tax registry b test - done in 0s\n","Tax registry c test dataframe shape: (183, 1)\n","Tax registry c test - done in 0s\n","Credit bureau b 1 test dataframe shape: (591, 1)\n","Credit bureau b 1 test - done in 0s\n","Credit bureau b 2 test - done in 0s\n","Feature engineering / preprocessing - done in 0s\n","Train/valid shape: (1111, 190), test shape: (10, 190)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a4e3caf36804480a9c4c581c401473c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Fold  1 AUC : 0.909910. Elapsed time: 3.95 seconds. Remaining time: 35.52 seconds.\n","Fold  2 AUC : 0.788679. Elapsed time: 7.67 seconds. Remaining time: 30.70 seconds.\n","Fold  3 AUC : 0.605664. Elapsed time: 11.42 seconds. Remaining time: 26.64 seconds.\n","Fold  4 AUC : 0.701456. Elapsed time: 16.62 seconds. Remaining time: 24.93 seconds.\n","Fold  5 AUC : 0.399083. Elapsed time: 30.02 seconds. Remaining time: 30.02 seconds.\n","Fold  6 AUC : 0.720635. Elapsed time: 40.80 seconds. Remaining time: 27.20 seconds.\n","Fold  7 AUC : 0.561728. Elapsed time: 44.61 seconds. Remaining time: 19.12 seconds.\n","Fold  8 AUC : 0.981818. Elapsed time: 48.76 seconds. Remaining time: 12.19 seconds.\n","Fold  9 AUC : 0.663492. Elapsed time: 52.75 seconds. Remaining time: 5.86 seconds.\n","Fold 10 AUC : 0.574176. Elapsed time: 56.42 seconds. Remaining time: 0.00 seconds.\n","Full AUC score 0.658180\n","Gini Score of the valid set: 0.2662074053425182\n","Model training - done in 57s\n","Feature importance assesment - done in 0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Rijul\\AppData\\Local\\Temp\\ipykernel_30100\\2817924348.py:80: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['PREDICTIONS'] = oof_preds.copy()\n","C:\\Users\\Rijul\\AppData\\Local\\Temp\\ipykernel_30100\\2817924348.py:81: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['target'] = df['target'].copy()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a899583757144c22997e1ffb04e5a4ab","version_major":2,"version_minor":0},"text/plain":["Predicting:   0%|          | 0/10 [00:00<?, ? models/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Submission - done in 0s\n","NOTEBOOK HAS BEEN SUCCESSFULLY EXECUTED !!!\n","Pipeline total time - done in 65s\n"]}],"source":["if __name__ == \"__main__\":\n","    pd.set_option('display.max_rows', 60)\n","    pd.set_option('display.max_columns', 100)\n","    with timer(\"Pipeline total time\"):\n","        main(debug= True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7921029,"sourceId":50160,"sourceType":"competition"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
