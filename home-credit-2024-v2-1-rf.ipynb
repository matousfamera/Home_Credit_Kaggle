{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"},{"sourceId":7957696,"sourceType":"datasetVersion","datasetId":4680819}],"dockerImageVersionId":30665,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CONTENT\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"markdown","source":"# **LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom contextlib import contextmanager\nimport multiprocessing as mp\nfrom functools import partial\nfrom scipy.stats import kurtosis, iqr, skew\nimport lightgbm as lgb\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom glob import glob\nfrom pathlib import Path\nfrom datetime import datetime\nimport polars as pl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.base import BaseEstimator, RegressorMixin\nfrom sklearn.metrics import roc_auc_score \nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom tqdm.notebook import tqdm\nimport joblib\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nimport gc\nfrom sklearn.impute import SimpleImputer\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:19.913848Z","iopub.execute_input":"2024-03-27T19:21:19.914463Z","iopub.status.idle":"2024-03-27T19:21:23.274981Z","shell.execute_reply.started":"2024-03-27T19:21:19.914400Z","shell.execute_reply":"2024-03-27T19:21:23.273519Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **CONFIGURATION**\n<a id='configuration'></a>\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"code","source":"# GENERAL CONFIGURATIONS\nNUM_THREADS = 4\nDATA_DIRECTORY = \"/kaggle/input/home-credit-credit-risk-model-stability/parquet_files/\"\nSUBMISSION_SUFIX = \"_model_2.1_31\"\n#MODE CONFIGURATION\nSHOW_REPORT = False\nSELECTKBEST = False\nEXPORT_DATAFRAME = False\nIMPORT_DATAFRAME = False\n# LIGHTGBM CONFIGURATION AND HYPER-PARAMETERS\nGENERATE_SUBMISSION_FILES = True\nEVALUATE_VALIDATION_SET = True\nSTRATIFIED_KFOLD = True\nBALANCE_COLUMNS = False\nRANDOM_SEED = 324\nNUM_FOLDS = 10\nEARLY_STOPPING = 100\nROOT            = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n\n\nRF_PARAMS  = {\n    \"n_estimators\": 10,\n    \"max_depth\": None,\n    \n}","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.277710Z","iopub.execute_input":"2024-03-27T19:21:23.278333Z","iopub.status.idle":"2024-03-27T19:21:23.286937Z","shell.execute_reply.started":"2024-03-27T19:21:23.278293Z","shell.execute_reply":"2024-03-27T19:21:23.285412Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Set aggregations","metadata":{}},{"cell_type":"code","source":"# AGGREGATIONS\n\n# D: max, min, mean\n# M: \n# A : max, min, mean, sum\n# L : max, min, mean, sum\n\n\nAPPLPREV1_AGG = {\n\n    'num_group1':['count'],\n    'actualdpd_943P': ['min','max','mean','sum'],\n    'annuity_853A': ['min','max','mean','sum'],\n    'approvaldate_319D':['max','min','mean'],\n    'byoccupationinc_3656910L': ['min','max','mean','sum'],\n    'cancelreason_3545846M':['max'],\n    'childnum_21L': ['min','max','mean','sum'],\n    'creationdate_885D':['min','max','mean'],\n    'credacc_actualbalance_314A': ['min','max','mean','sum'],\n    'credacc_credlmt_575A': ['min','max','mean','sum'],\n    'credacc_maxhisbal_375A': ['min','max','mean','sum'],\n    'credacc_minhisbal_90A': ['min','max','mean','sum'],\n    'credacc_status_367L': ['max'],\n    'credacc_transactions_402L': ['min','max','mean','sum'],\n    'credamount_590A': ['min','max','mean','sum'],\n    'credtype_587L': ['max'],\n    'currdebt_94A': ['min','max','mean','sum'],\n    'dateactivated_425D':['min','max','mean'],\n    'district_544M':['max'],\n    'downpmt_134A': ['min','max','mean','sum'],\n    'dtlastpmt_581D':['min','max','mean'],\n    'dtlastpmtallstes_3545839D':['min','max','mean'],\n    'education_1138M':['max'],\n    'employedfrom_700D':['min','max','mean'],\n    'familystate_726L': ['max'],\n    'firstnonzeroinstldate_307D': ['min','max','mean'],\n    'inittransactioncode_279L': ['max'],\n    'isbidproduct_390L': ['min','max','mean','sum'],\n    'isdebitcard_527L': ['min','max','mean','sum'],\n    'mainoccupationinc_437A': ['min','max','mean','sum','median'],\n    'maxdpdtolerance_577P': ['min','max','mean','sum'],\n    'outstandingdebt_522A': ['min','max','mean','sum'],\n    'pmtnum_8L': ['min','max','mean','sum'],\n    'postype_4733339M':['max'],\n    #'profession_152M':['max'],\n    'rejectreason_755M':['max'],\n    'rejectreasonclient_4145042M':['max'],\n    'revolvingaccount_394A': ['min','max','mean','sum'],\n    'status_219L': ['max'],\n    'tenor_203L': ['min','max','mean','sum'],\n    \n}\nAPPLPREV2_AGG = {\n    'num_group1':['count'],\n    'num_group2':['count'],\n    'conts_type_509L':['max'],\n    #'cacccardblochreas_147M'\n    'credacc_cards_status_52L':['max']\n    \n}\nPERSON1_AGG={\n    'num_group1':['count'],\n    'birth_259D': ['max'],\n    #'childnum_185L':['max','mean','min'],\n    'contaddr_district_15M':['max'],\n    'contaddr_matchlist_1032L':['max'],\n    'contaddr_smempladdr_334L':['max'],\n    'contaddr_zipcode_807M':['max'],\n    'education_927M':['max'],\n    'empl_employedfrom_271D':['max','mean','min'],\n    'empl_employedtotal_800L':['max'],\n    'empl_industry_691L':['max'],\n    #'empladdr_district_926M'\n    #'empladdr_zipcode_114M'\n    'familystate_447L':['max','count'],\n    #'gender_992L'\n    'housetype_905L':['max'],\n    #'housingtype_772L'\n    'incometype_1044T':['max'],\n    #'isreference_387L'\n    'language1_981M':['max'],\n    'mainoccupationinc_384A':['max','mean','min', 'count'],\n    #'maritalst_703L'\n    'personindex_1023L':['max','mean','min', 'count','sum'],\n    'persontype_1072L':['max','mean','min', 'count','sum'],\n    'persontype_792L':['max','mean','min', 'count','sum'],\n    #'registaddr_district_1083M'\n    #'registaddr_zipcode_184M'\n    'relationshiptoclient_415T':['max','count'],\n    'relationshiptoclient_642T':['max','count'],\n    'remitter_829L':['max'],\n    'role_1084L':['max','count'],\n    #'role_993L'\n    'safeguarantyflag_411L':['max'],\n    'sex_738L':['max'],\n    'type_25L':['max']\n    \n\n    \n    \n    \n}\nPERSON2_AGG={\n    'num_group1':['count'],\n    'num_group2':['count'],\n    #'addres_district_368M'\n    #'addres_role_871L'\n    #'addres_zip_823M'\n    #'conts_role_79M'\n    'empls_economicalst_849M':['max'],\n    #'empls_employedfrom_796D'\n    #'empls_employer_name_740M'\n    #'relatedpersons_role_762T'\n}\nOTHER_AGG={\n    'num_group1':['count'],\n    'amtdebitincoming_4809443A':['max','mean','min', 'count','sum'],\n    'amtdebitoutgoing_4809440A':['max','mean','min', 'count','sum'],\n    #'amtdepositbalance_4809441A'\n    #'amtdepositincoming_4809444A'\n    #'amtdepositoutgoing_4809442A'\n}\nDEBITCARD_AGG={\n    'num_group1':['count'],\n    #'last180dayaveragebalance_704A'\n    #'last180dayturnover_1134A'\n    #'last30dayturnover_651A'\n    'openingdate_857D':['min','max','mean']\n}\nTAX_REGISTRY_A_AGG={\n    'num_group1':['count'],\n    'amount_4527230A': ['max','mean','min','sum'],\n    'name_4527232M':['max'],\n    'recorddate_4527225D':['max','mean','min']\n    \n}\nTAX_REGISTRY_B_AGG={\n    'num_group1':['count'],\n    'amount_4917619A':['min','mean','max','sum'],\n    'deductiondate_4917603D':['max','mean','min'],\n    'name_4917606M':['max'],\n    \n    \n}\nTAX_REGISTRY_C_AGG={\n    'num_group1':['count'],\n    'employername_160M':['max'],\n    'pmtamount_36A':['min','mean','max','sum'],\n    'processingdate_168D':['mean','min','max'],\n\n}\nCREDIT_BUREAU_A_1_AGG={\n    \n    'num_group1':['count'],\n    #'annualeffectiverate_199L'\n    #'annualeffectiverate_63L'\n    'classificationofcontr_13M':['max'],\n    'classificationofcontr_400M':['max'],\n    'contractst_545M':['max'],\n    'contractst_964M':['max'],\n    #'contractsum_5085717L'\n    #'credlmt_230A'\n    'credlmt_935A':['max'],\n    'dateofcredend_289D':['mean','min','max'],\n    'dateofcredend_353D':['mean','min','max'],\n    'dateofcredstart_181D':['mean','min','max'],\n    'dateofcredstart_739D':['mean','min','max'],\n    'dateofrealrepmt_138D':['mean','min','max'],\n    'debtoutstand_525A':['min','mean','max','sum'],\n    'debtoverdue_47A':['min','mean','max','sum'],\n    'description_351M':['max'],\n    'dpdmax_139P':['min','mean','max','sum'],\n    #'dpdmax_757P'\n    #'dpdmaxdatemonth_442T':['max'],\n    #'dpdmaxdatemonth_89T':['max'],\n    #'dpdmaxdateyear_596T'\n    #'dpdmaxdateyear_896T'\n    'financialinstitution_382M':['max'],\n    'financialinstitution_591M':['max'],\n    'instlamount_768A':['min','mean','max','sum'],\n    #'instlamount_852A'\n    #'interestrate_508L'\n    'lastupdate_1112D':['mean','min','max'],\n    'lastupdate_388D':['mean','min','max'],\n    'monthlyinstlamount_332A':['min','mean','max','sum'],\n    #'monthlyinstlamount_674A'\n    'nominalrate_281L':['mean','min','max'],\n    #'nominalrate_498L'\n    'numberofcontrsvalue_258L':['min','mean','max','sum'],\n    'numberofcontrsvalue_358L':['min','mean','max','sum'],\n    #'numberofinstls_229L':\n    'numberofinstls_320L':['min','mean','max','sum'],\n    #'numberofoutstandinstls_520L'\n    'numberofoutstandinstls_59L':['min','mean','max','sum'],\n    'numberofoverdueinstlmax_1039L':['min','mean','max','sum'],\n    #'numberofoverdueinstlmax_1151L'\n    #'numberofoverdueinstlmaxdat_148D'\n    'numberofoverdueinstlmaxdat_641D':['mean','min','max'],\n    \n    \n      \n    'overdueamountmaxdatemonth_284T': ['min', 'mean', 'max'],\n    'overdueamountmaxdatemonth_365T': ['min', 'mean', 'max'],\n    'overdueamountmaxdateyear_2T': ['min', 'mean', 'max'],\n    'overdueamountmaxdateyear_994T': ['min', 'mean', 'max'],\n    'periodicityofpmts_1102L': ['min', 'mean', 'max'],\n    'periodicityofpmts_837L': ['min', 'mean', 'max'],\n    'prolongationcount_1120L': ['min', 'mean', 'max'],\n    'prolongationcount_599L': ['min', 'mean', 'max'],\n    'purposeofcred_426M': ['min', 'mean', 'max'],\n    'purposeofcred_874M': ['min', 'mean', 'max'],\n    'refreshdate_3813885D': ['min', 'mean', 'max'],\n    'residualamount_488A': ['min', 'mean', 'max'],\n    'residualamount_856A': ['min', 'mean', 'max'],\n   \n    'totalamount_6A': ['min', 'mean', 'max'],\n    'totalamount_996A': ['min', 'mean', 'max'],\n    'totaldebtoverduevalue_178A': ['min', 'mean', 'max'],\n    'totaldebtoverduevalue_718A': ['min', 'mean', 'max'],\n    'totaloutstanddebtvalue_39A': ['min', 'mean', 'max'],\n    'totaloutstanddebtvalue_668A': ['min', 'mean', 'max']\n   \n}\nCREDIT_BUREAU_B_1_AGG={\n    'num_group1':['count'],\n    \n}\nCREDIT_BUREAU_A_2_AGG={\n \n   \n    'pmts_dpd_1073P': ['min', 'mean', 'max'],\n    'pmts_dpd_303P': ['min', 'mean', 'max'],\n    'pmts_month_158T': ['min', 'mean', 'max'],\n    'pmts_month_706T': ['min', 'mean', 'max'],\n    'pmts_overdue_1140A': ['min', 'mean', 'max'],\n    'pmts_overdue_1152A': ['min', 'mean', 'max'],\n    'pmts_year_1139T': ['min', 'mean', 'max'],\n    'pmts_year_507T': ['min', 'mean', 'max'],\n    'subjectroles_name_541M': ['min', 'mean', 'max'],\n    'subjectroles_name_838M': ['min', 'mean', 'max'],\n    \n    \n    'num_group1':['count'],\n    'num_group2':['count']\n}\nCREDIT_BUREAU_B_2_AGG={\n    'num_group1':['count'],\n    'num_group2':['count'],\n    'pmts_date_1107D':['min', 'mean', 'max'],\n    'pmts_dpdvalue_108P':['min','mean','max'],\n    'pmts_pmtsoverdue_635A':['min','mean','max'],\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.288972Z","iopub.execute_input":"2024-03-27T19:21:23.289934Z","iopub.status.idle":"2024-03-27T19:21:23.331730Z","shell.execute_reply.started":"2024-03-27T19:21:23.289877Z","shell.execute_reply":"2024-03-27T19:21:23.330159Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# **MAIN FUNCTION**\n<a id='main_function'></a>\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"code","source":"def main(debug= False):\n    num_rows = 111111 if debug else None\n    print(\"Notebook started:\")\n    if not IMPORT_DATAFRAME:\n    \n        with timer(\"base\"):\n\n            df = get_base(DATA_DIRECTORY, num_rows=num_rows)\n\n            print(\"base dataframe shape:\", df.shape)\n\n\n\n        with timer(\"static\"):\n\n            df_static = get_static(DATA_DIRECTORY, num_rows=num_rows)\n            df_static = df_static.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_static, on='case_id', how='left', suffix='_static')\n            print(\"static dataframe shape:\", df_static.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n\n            del df_static\n            gc.collect()\n        \n        with timer(\"static_cb\"):\n\n            df_static_cb = get_static_cb(DATA_DIRECTORY, num_rows=num_rows)\n            df_static_cb = df_static_cb.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_static_cb, on='case_id', how='left', suffix='_static_cb')\n            print(\"static cb dataframe shape:\", df_static_cb.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_static_cb\n            gc.collect()\n\n        with timer(\"Previous applications depth 1 test\"):\n\n            df_applprev1 = get_applprev1(DATA_DIRECTORY, num_rows=num_rows)\n            df_applprev1 = df_applprev1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_applprev1, on='case_id', how='left', suffix='_applprev1')\n            print(\"Previous applications depth 1 test dataframe shape:\", df_applprev1.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_applprev1\n            gc.collect()\n\n        with timer(\"Previous applications depth 2 test\"):\n\n            df_applprev2 = get_applprev2(DATA_DIRECTORY, num_rows=num_rows)\n            df_applprev2 = df_applprev2.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_applprev2, on='case_id', how='left', suffix='_applprev2')\n            print(\"Previous applications depth 2 test dataframe shape:\", df_applprev2.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_applprev2\n            gc.collect()\n\n        with timer(\"Person depth 1 test\"):\n\n            df_person1 = get_person1(DATA_DIRECTORY, num_rows=num_rows)\n            df_person1 = df_person1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_person1, on='case_id', how='left', suffix='_person1')\n            print(\"Person depth 1 test dataframe shape:\", df_person1.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_person1\n            gc.collect()\n\n        with timer(\"Person depth 2 test\"):\n\n            df_person2 = get_person2(DATA_DIRECTORY, num_rows=num_rows)\n            df_person2 = df_person2.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_person2, on='case_id', how='left', suffix='_person2')\n            print(\"Person depth 2 test dataframe shape:\", df_person2.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_person2\n            gc.collect()\n\n        with timer(\"Other test\"):\n\n            df_other = get_other(DATA_DIRECTORY, num_rows=num_rows)\n            df_other = df_other.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_other, on='case_id', how='left', suffix='_other')\n            print(\"Other test dataframe shape:\", df_other.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_other\n            gc.collect()\n\n        with timer(\"Debit card test\"):\n\n            df_debitcard = get_debitcard(DATA_DIRECTORY, num_rows=num_rows)\n            df_debitcard = df_debitcard.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_debitcard, on='case_id', how='left', suffix='_debitcard')\n            print(\"Debit card test dataframe shape:\", df_debitcard.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_debitcard\n            gc.collect()\n\n        with timer(\"Tax registry a test\"):\n\n            df_tax_registry_a = get_tax_registry_a(DATA_DIRECTORY, num_rows=num_rows)\n            df_tax_registry_a = df_tax_registry_a.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_tax_registry_a, on='case_id', how='left', suffix='_tax_registry_a')\n            print(\"Tax registry a test dataframe shape:\", df_tax_registry_a.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_tax_registry_a\n            gc.collect()\n\n        with timer(\"Tax registry b test\"):\n\n            df_tax_registry_b = get_tax_registry_b(DATA_DIRECTORY, num_rows=num_rows)\n            df_tax_registry_b = df_tax_registry_b.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_tax_registry_b, on='case_id', how='left', suffix='_tax_registry_b')\n            print(\"Tax registry b test dataframe shape:\", df_tax_registry_b.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_tax_registry_b\n            gc.collect()\n\n        with timer(\"Tax registry c test\"):\n\n            df_tax_registry_c = get_tax_registry_c(DATA_DIRECTORY, num_rows=num_rows)\n            df_tax_registry_c = df_tax_registry_c.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_tax_registry_c, on='case_id', how='left', suffix='_tax_registry_c')\n            print(\"Tax registry c test dataframe shape:\", df_tax_registry_c.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_tax_registry_c\n            gc.collect()\n\n\n\n        with timer(\"Credit bureau a 1 test\"):\n\n            df_credit_bureau_a_1 = get_credit_bureau_a_1(DATA_DIRECTORY, num_rows=num_rows)\n            df_credit_bureau_a_1 = df_credit_bureau_a_1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_credit_bureau_a_1, on='case_id', how='left', suffix='_cb_a_1')\n            print(\"Credit bureau a 1 test dataframe shape:\", df_credit_bureau_a_1.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_credit_bureau_a_1\n            gc.collect()\n        with timer(\"Credit bureau b 1 test\"):\n\n            df_credit_bureau_b_1 = get_credit_bureau_b_1(DATA_DIRECTORY, num_rows=num_rows)\n            df_credit_bureau_b_1 = df_credit_bureau_b_1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_credit_bureau_b_1, on='case_id', how='left', suffix='_cb_b_1')\n            print(\"Credit bureau b 1 test dataframe shape:\", df_credit_bureau_b_1.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_credit_bureau_b_1\n            gc.collect()\n\n\n\n\n        with timer(\"Credit bureau a 2 test\"):\n\n            df_credit_bureau_a_2 = get_credit_bureau_a_2(DATA_DIRECTORY, num_rows=num_rows)\n            df_credit_bureau_a_2 = df_credit_bureau_a_2.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_credit_bureau_a_2, on='case_id', how='left', suffix='_cb_a_2')\n            print(\"Credit bureau a 2 test dataframe shape:\", df_credit_bureau_a_2.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_credit_bureau_a_2\n            gc.collect()\n\n        with timer(\"Credit bureau b 2 test\"):\n\n            df_credit_bureau_b_2 = get_credit_bureau_b_2(DATA_DIRECTORY, num_rows=num_rows)\n            df_credit_bureau_b_2 = df_credit_bureau_b_2.filter(pl.col('case_id').is_in(df['case_id'].unique()))\n            df = df.join(df_credit_bureau_b_2, on='case_id', how='left', suffix='_cb_b_2')\n            print(\"Credit bureau b 2 test dataframe shape:\", df_credit_bureau_b_2.shape)\n            print(\"DATAFRAME shape:\", df.shape)\n            del df_credit_bureau_b_2\n            gc.collect()\n\n        with timer(\"Feature engineering / preprocessing\"): \n\n            df=feature_engineering(df)\n            get_info(df)\n            df_pandas, cat_cols = to_pandas(df)\n            del df;gc.collect()\n            df=df_pandas\n            df=reduce_mem_usage(df)\n            print(\"DATAFRAME shape:\", df.shape)\n    else:\n        with timer(\"Importing processed dataframe\"):\n            path=\"/kaggle/input/home-credit-2024-additional-dataset\"\n            df=pd.read_parquet(path)\n            for col in df.select_dtypes(exclude=['number']).columns:\n                df[col] = df[col].astype('category')\n            print(df.dtypes.value_counts())\n            print(\"DATAFRAME shape:\", df.shape)\n    \n    if EXPORT_DATAFRAME:\n        with timer(\"Export dataframe\"):\n            df.to_parquet(\"/kaggle/working/processed_dataframe.parquet\")\n            print(\"NOTEBOOK HAS BEEN SUCCESSFULLY EXECUTED !!!\")\n            return\n    \n    if(SELECTKBEST):\n        with timer(\"SelectKBest feature research\"):\n            \n            selectkbestX(df)\n            print(\"NOTEBOOK HAS BEEN SUCCESSFULLY EXECUTED !!!\")\n            return\n\n    with timer(\"Model training\"):\n       \n        \n        del_features = ['target', 'case_id','WEEK_NUM']\n        predictors = list(filter(lambda v: v not in del_features, df.columns))\n        cat_cols = list(df.select_dtypes(\"object\").columns)\n        model = kfold_lightgbm_sklearn(df, cat_cols)\n       \n        \n\n    \n    \n    #with timer(\"Feature importance assesment\"):\n        \n     #   get_features_importances(predictors, model)\n        \n        \n    \n        \n    with timer(\"Submission\"):\n\n        if  GENERATE_SUBMISSION_FILES:\n            \n            if generate_submission_file(df, model):\n\n\n                print(\"Submission file has been created.\")\n            \n    \n    print(\"NOTEBOOK HAS BEEN SUCCESSFULLY EXECUTED !!!\")\n    \n    return df, model\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.335325Z","iopub.execute_input":"2024-03-27T19:21:23.335843Z","iopub.status.idle":"2024-03-27T19:21:23.387825Z","shell.execute_reply.started":"2024-03-27T19:21:23.335802Z","shell.execute_reply":"2024-03-27T19:21:23.386145Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# **UTILITY FUNCTIONS**","metadata":{}},{"cell_type":"markdown","source":"### Pipeline","metadata":{}},{"cell_type":"code","source":"class Pipeline:\n    @staticmethod\n    \n    \n    # Sets datatypes accordingly\n    def set_table_dtypes(df):\n        for col in df.columns:\n            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Int64))\n            elif col in [\"date_decision\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Date))\n            elif col[-1] in (\"P\", \"A\"):\n                df = df.with_columns(pl.col(col).cast(pl.Float64))\n            elif col[-1] in (\"M\",):\n                df = df.with_columns(pl.col(col).cast(pl.String))\n            elif col[-1] in (\"D\",):\n                df = df.with_columns(pl.col(col).cast(pl.Date))            \n\n        return df\n    \n    \n    # Changes the values of all date columns. The result will not be a date but number of days since date_decision.\n    @staticmethod\n    def handle_dates(df):\n        for col in df.columns:\n            if col[-1] in (\"D\",):\n                \n                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n                df = df.with_columns(pl.col(col).dt.total_days())\n                \n        df = df.drop(\"date_decision\", \"MONTH\")\n\n        return df\n    \n    # It drops columns with a lot of NaN values.\n    @staticmethod\n    def filter_cols(df):\n        for col in df.columns:\n            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n                isnull = df[col].is_null().mean()\n\n                if isnull > 0.95:\n                    df = df.drop(col)\n\n        for col in df.columns:\n            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n                freq = df[col].n_unique()\n\n                if (freq == 1) | (freq > 200):\n                    df = df.drop(col)\n\n        return df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.389909Z","iopub.execute_input":"2024-03-27T19:21:23.390454Z","iopub.status.idle":"2024-03-27T19:21:23.411134Z","shell.execute_reply.started":"2024-03-27T19:21:23.390417Z","shell.execute_reply":"2024-03-27T19:21:23.409632Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_info(dataframe):\n    \"\"\"\n    View data types, shape, and calculate the percentage of NaN (missing) values in each column\n    of a Polars DataFrame simultaneously.\n    \n    Parameters:\n    dataframe (polars.DataFrame): The DataFrame to analyze.\n    \n    Returns:\n    None\n    \"\"\"\n    # Print DataFrame shape\n    print(\"DataFrame Shape:\", dataframe.shape)\n    print(\"-\" * 60)\n    \n    # Print column information\n    print(\"{:<50} {:<30} {:<20}\".format(\"Column Name\", \"Data Type\", \"NaN Percentage\"))\n    print(\"-\" * 60)\n    \n    # Total number of rows in the DataFrame\n    total_rows = len(dataframe)\n    \n    # Iterate over each column\n    for column in dataframe.columns:\n        # Get the data type of the column\n        dtype = str(dataframe[column].dtype)\n        \n        # Count the number of NaN values in the column\n        nan_count = dataframe[column].null_count()\n        \n        # Calculate the percentage of NaN values\n        nan_percentage = (nan_count / total_rows) * 100\n        \n        # Print the information\n        print(\"{:<50} {:<30} {:.2f}%\".format(column, dtype, nan_percentage))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.412500Z","iopub.execute_input":"2024-03-27T19:21:23.412964Z","iopub.status.idle":"2024-03-27T19:21:23.428300Z","shell.execute_reply.started":"2024-03-27T19:21:23.412920Z","shell.execute_reply":"2024-03-27T19:21:23.427109Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def to_pandas(df_data, cat_cols=None):\n    df_data = df_data.to_pandas()\n    \n    if cat_cols is None:\n        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n    \n    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n    \n    return df_data, cat_cols","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.430309Z","iopub.execute_input":"2024-03-27T19:21:23.431095Z","iopub.status.idle":"2024-03-27T19:21:23.442343Z","shell.execute_reply.started":"2024-03-27T19:21:23.431045Z","shell.execute_reply":"2024-03-27T19:21:23.441083Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.444303Z","iopub.execute_input":"2024-03-27T19:21:23.445322Z","iopub.status.idle":"2024-03-27T19:21:23.462224Z","shell.execute_reply.started":"2024-03-27T19:21:23.445276Z","shell.execute_reply":"2024-03-27T19:21:23.460692Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.464105Z","iopub.execute_input":"2024-03-27T19:21:23.464565Z","iopub.status.idle":"2024-03-27T19:21:23.477443Z","shell.execute_reply.started":"2024-03-27T19:21:23.464504Z","shell.execute_reply":"2024-03-27T19:21:23.476115Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n    \n\n    temp=base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]] \\\n        .sort_values(\"WEEK_NUM\") \\\n        .groupby(\"WEEK_NUM\").mean()\n   \n    week_nums_to_drop = temp[(temp[\"target\"] == 0) | (temp[\"target\"] == 1)].index.tolist()\n\n    base_filtered = base[~base[\"WEEK_NUM\"].isin(week_nums_to_drop)]\n\n    # Apply the aggregator\n    gini_in_time = base_filtered.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]] \\\n        .sort_values(\"WEEK_NUM\") \\\n        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]] \\\n        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n\n    \n\n    x = np.arange(len(gini_in_time))\n    y = gini_in_time\n    a, b = np.polyfit(x, y, 1)\n    y_hat = a * x + b\n    residuals = y - y_hat\n    res_std = np.std(residuals)\n    avg_gini = np.nanmean(gini_in_time)  # Use np.nanmean to handle NaN values\n    \n    if SHOW_REPORT:\n        # Display the plot of x on y\n        plt.figure(figsize=(8, 6))\n        plt.plot(x, y, 'o', label='Gini in Time')\n        plt.plot(x, y_hat, '-', label='Fitted line (slope={:.2f}, intercept={:.2f})'.format(a, b))\n        plt.xlabel('Week')\n        plt.ylabel('Gini in Time')\n        plt.title('Gini Stability Over Time')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n    \n    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.482517Z","iopub.execute_input":"2024-03-27T19:21:23.483588Z","iopub.status.idle":"2024-03-27T19:21:23.497513Z","shell.execute_reply.started":"2024-03-27T19:21:23.483519Z","shell.execute_reply":"2024-03-27T19:21:23.496293Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Report function","metadata":{}},{"cell_type":"code","source":"'''\ndef make_report(num_rows, predictors, model):\n    # 1. time\n    current_time = datetime.now()\n    # Print the current time\n    print(\"Current Time:\", current_time)\n    \n    # 2. specification\n    if not num_rows:\n        print(\"The notebook was run in full mode.\")\n    else:\n        print(\"The notebook was run in debug mode. Number of rows: \" + str(num_rows))\n    \n    # 3. features\n    feat_importances_df = model.get_features_importances_df(predictors)\n    feat_importances_df['gain'] = feat_importances_df['gain'].round(0)\n    print(feat_importances_df.shape)\n    \n    predictions = pd.Series(model.get_predictions())\n   \n    numerical_columns = data.select_dtypes(include=['int', 'float']).columns\n\n    # Compute correlations of each numerical column with 'PREDICTIONS'\n    correlations = {}\n    \n    # Compute correlations of each numerical column with 'feat'\n    for column in numerical_columns:\n        correlations[column] = predictions.corr(data[column])\n\n    # Create a new DataFrame with 'features' and 'correlation' columns\n    correlation_df = pd.DataFrame(list(correlations.items()), columns=['features', 'correlation'])\n\n    # Round the correlation numbers to three decimal places\n    correlation_df['correlation'] = correlation_df['correlation'].round(3)\n\n    # Merge feat_importances_df and correlation_df on 'feature'\n    combined_df = pd.merge(feat_importances_df, correlation_df, left_on=\"feature\", right_on='features', how='left')\n\n    # Handle categorical features with no correlation\n    combined_df['correlation'] = combined_df['correlation'].fillna(value=np.nan)\n    \n\n    # Compute and add valid percentage for each feature\n    valid_percentage = (data[0:-10].count() / len(data[0:-10]))\n    valid_percentage = valid_percentage.round(3)\n    combined_df['valid_percentage'] = combined_df['feature'].map(valid_percentage)\n\n    # Print the combined_df DataFrame\n    print(combined_df.to_string(index=False))\n    print()\n    roc_score=roc_auc_score(data['target'][0:-10],predictions)\n    print(\"ROC score: \",roc_score)\n\n    # Compute false positive rate, true positive rate, and thresholds for ROC curve\n    fpr, tpr, thresholds = roc_curve(data['target'][0:-10], predictions)\n\n    # Plot ROC curve\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_score)\n    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    plt.show()\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.499370Z","iopub.execute_input":"2024-03-27T19:21:23.499858Z","iopub.status.idle":"2024-03-27T19:21:23.517427Z","shell.execute_reply.started":"2024-03-27T19:21:23.499806Z","shell.execute_reply":"2024-03-27T19:21:23.515886Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'\\ndef make_report(num_rows, predictors, model):\\n    # 1. time\\n    current_time = datetime.now()\\n    # Print the current time\\n    print(\"Current Time:\", current_time)\\n    \\n    # 2. specification\\n    if not num_rows:\\n        print(\"The notebook was run in full mode.\")\\n    else:\\n        print(\"The notebook was run in debug mode. Number of rows: \" + str(num_rows))\\n    \\n    # 3. features\\n    feat_importances_df = model.get_features_importances_df(predictors)\\n    feat_importances_df[\\'gain\\'] = feat_importances_df[\\'gain\\'].round(0)\\n    print(feat_importances_df.shape)\\n    \\n    predictions = pd.Series(model.get_predictions())\\n   \\n    numerical_columns = data.select_dtypes(include=[\\'int\\', \\'float\\']).columns\\n\\n    # Compute correlations of each numerical column with \\'PREDICTIONS\\'\\n    correlations = {}\\n    \\n    # Compute correlations of each numerical column with \\'feat\\'\\n    for column in numerical_columns:\\n        correlations[column] = predictions.corr(data[column])\\n\\n    # Create a new DataFrame with \\'features\\' and \\'correlation\\' columns\\n    correlation_df = pd.DataFrame(list(correlations.items()), columns=[\\'features\\', \\'correlation\\'])\\n\\n    # Round the correlation numbers to three decimal places\\n    correlation_df[\\'correlation\\'] = correlation_df[\\'correlation\\'].round(3)\\n\\n    # Merge feat_importances_df and correlation_df on \\'feature\\'\\n    combined_df = pd.merge(feat_importances_df, correlation_df, left_on=\"feature\", right_on=\\'features\\', how=\\'left\\')\\n\\n    # Handle categorical features with no correlation\\n    combined_df[\\'correlation\\'] = combined_df[\\'correlation\\'].fillna(value=np.nan)\\n    \\n\\n    # Compute and add valid percentage for each feature\\n    valid_percentage = (data[0:-10].count() / len(data[0:-10]))\\n    valid_percentage = valid_percentage.round(3)\\n    combined_df[\\'valid_percentage\\'] = combined_df[\\'feature\\'].map(valid_percentage)\\n\\n    # Print the combined_df DataFrame\\n    print(combined_df.to_string(index=False))\\n    print()\\n    roc_score=roc_auc_score(data[\\'target\\'][0:-10],predictions)\\n    print(\"ROC score: \",roc_score)\\n\\n    # Compute false positive rate, true positive rate, and thresholds for ROC curve\\n    fpr, tpr, thresholds = roc_curve(data[\\'target\\'][0:-10], predictions)\\n\\n    # Plot ROC curve\\n    plt.figure(figsize=(8, 6))\\n    plt.plot(fpr, tpr, color=\\'blue\\', lw=2, label=\\'ROC curve (AUC = %0.2f)\\' % roc_score)\\n    plt.plot([0, 1], [0, 1], color=\\'gray\\', linestyle=\\'--\\')\\n    plt.xlim([0.0, 1.0])\\n    plt.ylim([0.0, 1.05])\\n    plt.xlabel(\\'False Positive Rate\\')\\n    plt.ylabel(\\'True Positive Rate\\')\\n    plt.title(\\'Receiver Operating Characteristic (ROC) Curve\\')\\n    plt.legend(loc=\"lower right\")\\n    plt.grid(True)\\n    plt.show()\\n'"},"metadata":{}}]},{"cell_type":"code","source":"def group(df_to_agg, prefix, aggregations, aggregate_by='case_id', datatype='polars'):\n    # Create a dictionary mapping aggregation functions to their string representations\n    \n    if datatype=='polars':\n        func_mapping = {\n        'min': pl.min,\n        'max': pl.max,\n        'mean': pl.mean,\n        'sum': pl.sum,\n        'count': pl.count,\n         'median': pl.median\n        }\n\n    # Perform the aggregation\n        agg_df = df_to_agg.group_by(aggregate_by).agg(**{\n            f\"{func}_{col}\": func_mapping[func](col) for col, funcs in aggregations.items() for func in funcs\n        })\n        '''\n        # Rename columns\n        for col, funcs in aggregations.items():\n            for func in funcs:\n                old_name = f\"{col}_{func}\"\n                new_name = f\"{prefix}{col}_{func.upper()}\"\n                agg_df = agg_df.select(pl.col(old_name).alias(new_name))\n        '''\n        return agg_df\n    \n    if datatype=='pandas':\n            # Create a dictionary mapping aggregation functions to their string representations\n        func_mapping = {\n            'min': 'min',\n            'max': 'max',\n            'mean': 'mean',\n            'sum': 'sum',\n            'count': 'count',\n            \n        }\n\n        # Perform the aggregation\n        agg_df = df_to_agg.groupby(aggregate_by).agg(**{\n            f\"{prefix}{col}_{func.upper()}\": (col, func_mapping[func]) for col, funcs in aggregations.items() for func in funcs\n        }).reset_index()\n        \n        return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.519670Z","iopub.execute_input":"2024-03-27T19:21:23.520442Z","iopub.status.idle":"2024-03-27T19:21:23.532162Z","shell.execute_reply.started":"2024-03-27T19:21:23.520385Z","shell.execute_reply":"2024-03-27T19:21:23.530866Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# **SELECTKBEST METHOD**","metadata":{}},{"cell_type":"code","source":"def preprocessingX(data):\n    \n        \n\n        def one_hot_encode(data):\n            \n            \n            original_columns = list(data.columns)\n            categories = [cat for cat in data.columns if data[cat].dtype == 'category']\n            df = pd.get_dummies(data, columns= categories, dummy_na= True) #one_hot_encode the categorical features\n            categorical_columns = [cat for cat in df.columns if cat not in original_columns]\n            return df, categorical_columns\n        \n        \n        df,categorical_columns=one_hot_encode(data)\n        del data;gc.collect()\n        \n        total_nan_count = df.isna().sum().sum()\n\n        print(\"Total count of NaN values in the DataFrame:\", total_nan_count)\n        for column in (set(df.columns)-{'target'}):\n            # Calculate the mean value of the column excluding NaNs\n            column_mean = df[column].mean()\n            \n            if not np.isfinite(column_mean):\n            # If mean value is infinite or NaN, replace it with the median\n                column_median = df[column].median()\n                df[column].fillna(column_median, inplace=True)\n            else:\n            # Replace NaN values in the column with the mean value\n                df[column].fillna(column_mean, inplace=True)\n\n        total_nan_count = df.isna().sum().sum()\n\n        print(\"Total count of NaN values in the DataFrame:\", total_nan_count)\n\n        return df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.534781Z","iopub.execute_input":"2024-03-27T19:21:23.535456Z","iopub.status.idle":"2024-03-27T19:21:23.548274Z","shell.execute_reply.started":"2024-03-27T19:21:23.535406Z","shell.execute_reply":"2024-03-27T19:21:23.547036Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def selectkbestX(data):\n    #########################################################################################\n    \n    #########################################################################################\n    def selectkbest_base(X_train, y_train):\n        \n        # Define SelectKBest with desired parameters\n        k = 500  # Number of top features to select\n        S = SelectKBest(score_func=f_classif, k=k)\n\n        # Fit SelectKBest on training data and transform features\n        X_train_k_best = S.fit_transform(X_train, y_train)\n\n        # Get scores assigned to each feature\n        feature_scores = S.scores_\n        \n        # Create a DataFrame to store feature names and their scores\n        feature_scores_df = pd.DataFrame({'Feature': X_train.columns, 'Score': feature_scores})\n\n        # Sort DataFrame by scores in descending order\n        #feature_scores_df_sorted = feature_scores_df.sort_values(by='Score', ascending=False)\n\n        # Print the table of top features and their scores\n      \n        # Return DataFrame with feature names and their scores\n        return feature_scores_df\n    #########################################################################################\n    \n    \n    df=preprocessingX(data)\n    del data;gc.collect()\n    \n    \n    \n    \n   \n    N_CHUNKS=5\n    df.drop(df[df['target'].isnull()].index, inplace=True)\n    \n   \n    del_features = ['target', 'case_id']\n    predictors = [col for col in df.columns if col not in del_features]\n    \n    feats_df = pd.DataFrame({'feature': predictors}, columns=['feature'])\n    \n    results=[]\n    \n    with tqdm(total=N_CHUNKS) as pbar:\n        for i in range(N_CHUNKS):\n\n            sub_df = df[df.index % N_CHUNKS == i]\n            df.drop(df.index[df.index % N_CHUNKS == i], inplace=True)\n            X_train=sub_df[predictors]\n            y_train=sub_df['target']\n\n\n            result_df=selectkbest_base(X_train, y_train)\n            \n            del sub_df\n            gc.collect()\n\n            results.append(result_df)\n            pbar.update(1)\n            \n    del df; gc.collect()\n    merged_df = results[0]\n\n# Merge the remaining dataframes horizontally on the 'Feature' column\n    for df_index in range(1, len(results)):\n        suffix = '_' + str(df_index)  # Add a suffix to distinguish overlapping column names\n        merged_df = pd.merge(merged_df, results[df_index], on='Feature', suffixes=('', suffix))\n\n    merged_df.rename(columns={'Score': 'Score_0'}, inplace=True)\n    merged_df['mean_score'] = 0\n    \n    for i in range(N_CHUNKS):\n        merged_df['mean_score']+=merged_df[\"Score_\"+str(i)]\n    \n    \n    final_df=merged_df[['Feature', 'mean_score']]\n    final_df = final_df.sort_values(by='mean_score', ascending=False)\n    pd.set_option('display.max_rows', None)  # Show all rows\n# Display the DataFrame\n    print(final_df)\n   \n\n    final_df.to_csv(\"/kaggle/working/SelectKBest.csv\")\n    \n    return merged_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.549781Z","iopub.execute_input":"2024-03-27T19:21:23.550235Z","iopub.status.idle":"2024-03-27T19:21:23.569917Z","shell.execute_reply.started":"2024-03-27T19:21:23.550192Z","shell.execute_reply":"2024-03-27T19:21:23.568554Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"#  **MODEL** <a id='model'></a>\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"code","source":"class VotingModel(BaseEstimator, RegressorMixin):\n    def __init__(self, estimators):\n        super().__init__()\n        self.estimators = estimators\n        \n        \n    def fit(self, X, y=None):\n        return self\n    \n    def predict(self, X):\n        y_preds = [estimator.predict(X) for estimator in self.estimators]\n        return np.mean(y_preds, axis=0)\n    \n    def predict_proba(self, X):\n        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n        # Use tqdm to create a progress bar during the prediction\n        with tqdm(total=len(self.estimators), desc=\"Predicting\", unit=\" models\") as pbar:\n            for i, estimator in enumerate(self.estimators):\n                y_preds[i] = estimator.predict_proba(X)\n                pbar.update(1)  # Update the progress bar\n        return np.mean(y_preds, axis=0)\n\n    \n    def get_splits(self, aggregation_method=np.mean):\n        \n        feature_importances_list=[]\n        for x in self.estimators:\n            feature_importances_list.append(x.feature_importance(importance_type='split'))\n            \n        # Aggregate feature importances across all models\n        if all(importances is not None for importances in feature_importances_list):\n            combined_importances = aggregation_method(feature_importances_list, axis=0)\n        else:\n            combined_importances = None   \n        return combined_importances\n    \n    \n    def get_gains(self, aggregation_method=np.mean):\n        \n        feature_importances_list=[]\n        for model in self.estimators:\n            feature_importances_list.append(x.feature_importance(importance_type='gain'))\n            \n        # Aggregate feature importances across all models\n        if all(importances is not None for importances in feature_importances_list):\n            combined_importances = aggregation_method(feature_importances_list, axis=0)\n        else:\n            combined_importances = None\n              \n        return combined_importances\n    \n    def get_features_importances_df(self, predictors):\n        \n        \n        importance_df = pd.DataFrame()\n        eval_results = dict()\n        for model in self.estimators:\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = predictors\n            fold_importance[\"gain\"] = model.feature_importance(importance_type='gain')\n            fold_importance[\"split\"] = model.feature_importance(importance_type='split')\n            importance_df = pd.concat([importance_df, fold_importance], axis=0)\n            importance_df= importance_df.groupby('feature').mean().reset_index()\n        return importance_df\n    \n    \n    def add_predictions(self, predictions):\n        self.predictions=predictions\n        \n    def get_predictions(self):\n        return self.predictions\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.571437Z","iopub.execute_input":"2024-03-27T19:21:23.572381Z","iopub.status.idle":"2024-03-27T19:21:23.590158Z","shell.execute_reply.started":"2024-03-27T19:21:23.572345Z","shell.execute_reply":"2024-03-27T19:21:23.588774Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def kfold_lightgbm_sklearn(data, categorical_feature = None):\n    \n    \n    \n   \n    #time.sleep(30)\n    start_time = time.time()\n    \n    \n    \n    numerical_columns = data.select_dtypes(include=['number']).columns\n\n    for column in numerical_columns:\n        min_value = data[column].min()\n        max_value = data[column].max()\n        print(f\"Column: {column}, Min Value: {min_value}, Max Value: {max_value}\")\n        \n    df=data.copy()\n    df.drop(df[df['target'].isnull()].index, inplace=True)\n    #test=data.copy()\n    #test.drop(test[test['target'].notnull()].index, inplace=True)\n    del data; gc.collect()\n    \n    print(\"shape before preprocessing\", df.shape)\n    df=preprocessingX(df)\n    print(\"shape after preprocessing\", df.shape)\n    #test=reduce_mem_usage(test)\n \n    \n    \n  \n\n \n    \n   \n    \n    df=reduce_mem_usage(df)\n   \n    print(\"Train/valid shape: {}, \".format(df.shape))\n    del_features = ['target', 'case_id', 'WEEK_NUM']\n    predictors = list(filter(lambda v: v not in del_features, df.columns))\n\n    if not STRATIFIED_KFOLD:\n        folds = KFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n    else:\n        folds = StratifiedKFold(n_splits= NUM_FOLDS, shuffle=True, random_state= RANDOM_SEED)\n    \n        # Hold oof predictions, test predictions, feature importance and training/valid auc\n    oof_preds = np.zeros(df.shape[0])\n    \n    importance_df = pd.DataFrame()\n    eval_results = dict()\n    \n    fitted_models = []\n    \n    \n    \n    \n    \n    \n    with tqdm(total=NUM_FOLDS) as pbar:\n        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[predictors], df['target'])):\n           \n          \n            train_x, train_y = df[predictors].iloc[train_idx], df['target'].iloc[train_idx]\n            valid_x, valid_y = df[predictors].iloc[valid_idx], df['target'].iloc[valid_idx]\n            \n            \n          \n        \n            #time.sleep(30)\n            params = {'random_state': RANDOM_SEED}\n            clf = RandomForestClassifier(**{**params, **RF_PARAMS})\n\n\n            \n            \n            clf.fit(train_x, train_y)\n\n\n            fitted_models.append(clf)\n\n            if EVALUATE_VALIDATION_SET:\n                oof_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n\n\n\n                # Feature importance by GAIN and SPLIT\n\n            #eval_results['train_{}'.format(n_fold+1)]  = clf.evals_result_['training']['auc']\n            #eval_results['valid_{}'.format(n_fold+1)] = clf.evals_result_['valid_1']['auc']\n\n            elapsed_time = time.time() - start_time\n            remaining_time = elapsed_time * (NUM_FOLDS - n_fold - 1) / (n_fold + 1)\n            print('Fold %2d AUC : %.6f. Elapsed time: %.2f seconds. Remaining time: %.2f seconds.'\n                  % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx]), elapsed_time, remaining_time))\n            del clf, train_x, train_y, valid_x, valid_y\n            gc.collect()\n            pbar.update(1)\n            \n    print('Full AUC score %.6f' % roc_auc_score(df['target'], oof_preds))\n    # Get the average feature importance between folds\n    \n    \n    \n    if len(df)>0:\n        base=get_base(DATA_DIRECTORY, len(df))\n        base, cat_cols = to_pandas(base)\n        base=base[base['target'].notnull()]\n        base['score']= oof_preds\n        gini_score = gini_stability(base)\n        print(\"Gini Score of the valid set:\", gini_score)\n    \n    \n    \n    \n    # Save feature importance, test predictions and oof predictions as csv\n    \n        \n        \n  \n        \n        \n    model = VotingModel(fitted_models)\n    if GENERATE_SUBMISSION_FILES:\n        \n\n\n            # Generate oof csv\n            oof = pd.DataFrame()\n            oof['case_id'] = df['case_id'].copy()\n            df['PREDICTIONS'] = oof_preds.copy()\n            df['target'] = df['target'].copy()\n            df.to_csv('oof{}.csv'.format(SUBMISSION_SUFIX), index=False)\n    model.add_predictions(oof_preds.copy())\n    del df; gc.collect()\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.591950Z","iopub.execute_input":"2024-03-27T19:21:23.592719Z","iopub.status.idle":"2024-03-27T19:21:23.616586Z","shell.execute_reply.started":"2024-03-27T19:21:23.592678Z","shell.execute_reply":"2024-03-27T19:21:23.615502Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# **SUBMISSION**","metadata":{}},{"cell_type":"code","source":"def generate_submission_file(data, model):\n    test=data.copy()\n    test.drop(test[test['target'].notnull()].index, inplace=True)\n    del data;gc.collect()\n\n    '''\n    length=len(test)\n    y_pred = pd.Series([0.5] * length,index=test['case_id'])\n    df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n    df_subm = df_subm.set_index(\"case_id\")\n    df_subm[\"score\"] = y_pred\n    df_subm.to_csv(\"submission.csv\")\n    '''\n    test=preprocessingX(test)\n    del_features = ['target', 'case_id','WEEK_NUM']\n    predictors = list(filter(lambda v: v not in del_features, test.columns))\n    y_pred = pd.Series(model.predict_proba(test[predictors])[:, 1], index=test['case_id']) \n\n    df_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\n    df_subm = df_subm.set_index(\"case_id\")\n    df_subm[\"score\"] = y_pred\n\n    df_subm.to_csv(\"submission.csv\")\n    \n    return True\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.618441Z","iopub.execute_input":"2024-03-27T19:21:23.618810Z","iopub.status.idle":"2024-03-27T19:21:23.628096Z","shell.execute_reply.started":"2024-03-27T19:21:23.618780Z","shell.execute_reply":"2024-03-27T19:21:23.626848Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# **EVALUATE FEATURES IMPORTANCES**","metadata":{}},{"cell_type":"code","source":"def get_features_importances(predictors, model):\n    importance_df = model.get_features_importances_df(predictors)\n    mean_importance = importance_df.groupby('feature').mean().reset_index()\n    mean_importance.to_csv('feature_importance{}.csv'.format(SUBMISSION_SUFIX), index=False)\n    mean_importance.sort_values(by= 'gain', ascending=False, inplace=True)\n    mean_importance.to_csv('feature_importance_gain{}.csv'.format(SUBMISSION_SUFIX), index=False)\n    mean_importance.sort_values(by= 'split', ascending=False, inplace=True)\n    mean_importance.to_csv('feature_importance_split{}.csv'.format(SUBMISSION_SUFIX), index=False)\n    return True","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.629923Z","iopub.execute_input":"2024-03-27T19:21:23.630333Z","iopub.status.idle":"2024-03-27T19:21:23.643034Z","shell.execute_reply.started":"2024-03-27T19:21:23.630299Z","shell.execute_reply":"2024-03-27T19:21:23.642029Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# **FEATURE ENGINEERING FUNCTION**","metadata":{}},{"cell_type":"code","source":"def feature_engineering(df):\n    \n    \n    \n    df=df.pipe(Pipeline.handle_dates) \n    #df=df.pipe(Pipeline.filter_cols)\n    \n    '''\n     data['CREDIT_INCOME_PERCENT'] = data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n                                    final credit amount on the previous application./Income of the client\n    \n    \n    credamount_590A/byoccupationinc_3656910L\n    '''\n    \n    \n    columns_to_add = [\n        (pl.col(\"days30_165L\")/ pl.col(\"days360_512L\")).alias(\"ratio_queries_30\"),\n        ((pl.col(\"days90_310L\") / pl.col(\"days360_512L\")).alias(\"ratio_queries_90\")),\n        ((pl.col(\"days120_123L\") / pl.col(\"days360_512L\")).alias(\"ratio_queries_120\")),\n        ((pl.col(\"days180_256L\") / pl.col(\"days360_512L\")).alias(\"ratio_queries_180\")),\n        \n        \n        ((pl.col(\"credamount_770A\") / pl.col(\"max_mainoccupationinc_437A\")).alias(\"CREDIT_INCOME_PERCENT\")),\n        ((pl.col(\"annuity_780A\") / pl.col(\"max_mainoccupationinc_437A\")).alias(\"ANNUITY_INCOME_PERCENT\")),\n        ((pl.col(\"credamount_770A\") / pl.col(\"annuity_780A\")).alias(\"CREDIT_ANNUITY_PERCENT\")),\n        \n        ((pl.col(\"annuity_780A\") / pl.col(\"credamount_770A\")).alias(\"CREDIT_TERM\")),\n        ((pl.col(\"max_mainoccupationinc_437A\") / pl.col(\"childnum_21L\")).alias(\"CHILDREN_CNT_INCOME_PERCENT\")),\n        \n        #data['ANNUITY_LENGTH_EMPLOYED_PERCENT'] = data['CREDIT_TERM']/ data['DAYS_EMPLOYED']\n        ((pl.col(\"CREDIT_TERM\") / pl.col(\"max_empl_employedfrom_271D\")).alias(\"ANNUITY_LENGTH_EMPLOYED_PERCENT\")),\n        \n        #data['PHONE_CHANGE_EMP_PERCENT'] = data['DAYS_LAST_PHONE_CHANGE']/data['DAYS_EMPLOYED']\n        \n        \n        \n        #((pl.col(\"credamount_590A\") / pl.col(\"byoccupationinc_3656910L\")).alias(\"credit_income_percent\")),\n        \n        \n        \n        #((pl.col(\"collater_typofvalofguarant_298M\") + pl.col(\"collater_typofvalofguarant_407M\")).alias(\"sum_collater\")),\n        #((pl.col(\"collater_typofvalofguarant_298M\") + pl.col(\"sum_collater\"))).alias(\"ratio_collater_active\")),\n        #((pl.col(\"collater_typofvalofguarant_407M\") + pl.col(\"sum_collater\"))).alias(\"ratio_collater_close\")),\n        #((pl.col(\"overdueamount_31A\") + pl.col(\"overdueamount_659A\")).alias(\"sum_overdue_amount\")),\n        #((pl.col(\"overdueamount_31A\") / pl.col(\"sum_overdue_amount\")).alias(\"ratio_overdue_amount_active\")),\n        #((pl.col(\"overdueamount_659A\") / pl.col(\"sum_overdue_amount\")).alias(\"ratio_overdue_amount_close\")),\n        #((pl.col(\"overdueamount_31A\") / pl.col(\"total_overdue_amount\")).alias(\"ratio_overdue_amount_active\")),\n        #((pl.col(\"overdueamount_659A\") / pl.col(\"total_overdue_amount\")).alias(\"ratio_overdue_amount_close\")),\n        #((pl.col(\"totalamount\")).alias(\"sum_totalcredit_contract\")),\n        #((pl.col(\"totalamount_503A\") / pl.col(\"sum_totalcredit_contract\")).alias(\"ratio_totalcredit_contract_active\")),\n        #((pl.col(\"totalamount_6A\") / pl.col(\"sum_totalcredit_contract\")).alias(\"ratio_totalcredit_contract_close\")),\n        #((pl.col(\"totaldebtoverduevalue_178A\") / pl.col(\"totaldebt_9A\")).alias(\"ratio_overdue_debt_active\")),\n        #((pl.col(\"totaldebtoverduevalue_718A\") / pl.col(\"totaldebt_9A\")).alias(\"ratio_overdue_debt_close\")),\n        #((pl.col(\"numberofinstls_229L\") + pl.col(\"numberofinstls_320L\")).alias(\"sum_instalments\")),\n        #((pl.col(\"numberofinstls_320L\") / pl.col(\"sum_instalments\")).alias(\"ratio_instalments_active\")),\n        #((pl.col(\"numberofinstls_229L\") / pl.col(\"sum_instalments\")).alias(\"ratio_instalments_close\"))\n    ]\n\n# Add the calculated columns to the DataFrame\n    #for column in columns_to_add:\n     #   df = df.with_columns([column])\n        \n        \n    '''\n    df = df.with_columns(\n    'ratio_queries_30',\n    df['days30_165L'] / df['days360_512L']\n)\n    df['ratio_queries_90'] = df['days90_310L'] / df['days360_512L']\n    df['ratio_queries_120'] = df['days120_123L'] / df['days360_512L']\n    df['ratio_queries_180'] = df['days180_256L'] / df['days360_512L']\n    df['sum_collater'] = df['collater_typofvalofguarant_298M'] +    df['collater_typofvalofguarant_407M']\n    df['ratio_collater_active'] = df['collater_typofvalofguarant_298M'] +    df['sum_collater']\n    df['ratio_collater_close'] = df['collater_typofvalofguarant_407M'] +    df['sum_collater']\n    df['sum_overdue_amount'] = df['overdueamount_31A'] +    df['overdueamount_659A']\n    df['ratio_overdue_amount_active'] = df['overdueamount_31A'] /    df['sum_overdue_amount']\n    df['ratio_overdue_amount_close'] = df['overdueamount_659A'] /    df['sum_overdue_amount']\n    df['ratio_overdue_amount_active'] = df['overdueamount_31A'] /    df['total_overdue_amount']\n    df['ratio_overdue_amount_close'] = df['overdueamount_659A'] /    df['total_overdue_amount']\n    df['sum_totalcredit_contract'] = df['totalamount']\n    df['ratio_totalcredit_contract_active'] = df['totalamount_503A'] /    df['sum_totalcredit_contract']\n    df['ratio_totalcredit_contract_close'] = df['totalamount_6A'] /    df['sum_totalcredit_contract']\n    df['ratio_overdue_debt_active'] = df['totaldebtoverduevalue_178A'] /    df['totaldebt_9A']\n    df['ratio_overdue_debt_close'] = df['totaldebtoverduevalue_718A'] /    df['totaldebt_9A']\n    df['sum_instalments'] = df['numberofinstls_229L'] +    df['numberofinstls_320L']\n    df['ratio_instalments_active'] = df['numberofinstls_320L'] /    df['sum_instalments']\n    df['ratio_instalments_close'] = df['numberofinstls_229L'] /    df['sum_instalments']\n    '''\n    df=df.pipe(Pipeline.filter_cols)\n    \n    columns_to_drop=[\n     \n   'min_pmts_year_1139T',              \n'mean_pmts_year_1139T',                            \n'max_pmts_year_1139T',                             \n'min_pmts_year_507T' ,                               \n'mean_pmts_year_507T',                              \n'max_pmts_year_507T',\n        \n        'min_overdueamountmaxdateyear_2T'  ,               \n'mean_overdueamountmaxdateyear_2T'   ,              \n'max_overdueamountmaxdateyear_2T'  ,              \n'min_overdueamountmaxdateyear_994T'  ,              \n'mean_overdueamountmaxdateyear_994T' ,             \n'max_overdueamountmaxdateyear_994T'\n]\n    columns_to_drop_existing = [col for col in columns_to_drop if col in df.columns]\n\n    df=df.drop(columns_to_drop_existing)\n    \n    \n    \n    features400=[\n            #0\n        'max_role_1084L', 'max_language1_981M', 'max_sex_738L','max_incometype_1044T','max_education_927M',\n        'max_type_25L','max_safeguarantyflag_411L','min_pmts_month_158T','min_pmts_month_706T','max_pmts_month_158T',\n        'max_pmts_month_706T','mean_pmts_month_706T','mean_pmts_month_158T','pctinstlsallpaidlate1d_3546856L','pctinstlsallpaidlate4d_3546849L',\n        'pctinstlsallpaidlate6d_3546844L','pctinstlsallpaidlat10d_839L','max_contaddr_smempladdr_334L','max_contaddr_matchlist_1032L','numinstlswithdpd10_728L',\n        'pctinstlsallpaidearl3d_427L','lastrejectreason_759M','days120_123L','days180_256L','days90_310L',\n        'lastrejectreasonclient_4145040M','lastcancelreason_561M','lastst_736L','numrejects9m_859L',\n        'avgmaxdpdlast9m_3716943P','numberofqueries_373L','days360_512L','days30_165L','mobilephncnt_593L',\n        'max_birth_259D','numcontrs3months_479L','dateofbirth_337D','numinstpaidearly3d_3546850L','sum_maxdpdtolerance_577P',\n        'max_maxdpdtolerance_577P','numinstlallpaidearly3d_817L','maxdpdtolerance_374P','numinstlsallpaid_934L','daysoverduetolerancedd_3976961L',\n        'max_employedfrom_700D','mean_maxdpdtolerance_577P','mean_employedfrom_700D','numinstpaidearly_338L','avgdpdtolclosure24_3658938P',\n        \n        'mean_pmtnum_8L','mean_tenor_203L','lastrejectdate_50D','numinstlswithoutdpd_562L','avgdbddpdlast24m_3658932P',\n        'max_pmtnum_8L','max_tenor_203L','numinstpaidearly3dest_4493216L','numinstmatpaidtearly2d_4499204L','min_employedfrom_700D',\n        'requesttype_4525192L','maxdpdfrom6mto36m_3546853P','maxdpdlast24m_143P','datelastinstal40dpd_247D','mindbddpdlast24m_3658935P',\n        'amtinstpaidbefduel24m_4187115A','avgdbdtollast24m_4525197P','maxdpdlast12m_727P','maxdbddpdtollast12m_3658940P',\n        'max_empl_employedfrom_271D','min_empl_employedfrom_271D','mean_empl_employedfrom_271D','min_maxdpdtolerance_577P','firstclxcampaign_1125D',\n        'max_status_219L','sum_pmtnum_8L','sum_tenor_203L','monthsannuity_845L','pmtnum_254L',\n        'max_education_1138M','maxdpdlast9m_1059P','sum_amount_4527230A','mindbdtollast24m_4525191P','min_subjectroles_name_541M',\n        'birthdate_574D','max_subjectroles_name_838M','max_subjectroles_name_541M','min_subjectroles_name_838M','ratio_queries_120',\n        'ratio_queries_90','mean_outstandingdebt_522A','cntpmts24_3658933L','ratio_queries_180','maxdbddpdtollast6m_4187119P',\n        'mean_currdebt_94A','max_familystate_726L','numinstregularpaidest_4493210L','numincomingpmts_3546848L','numinstpaid_4499208L',\n        \n         'numinstregularpaid_973L','disbursedcredamount_1113A','secondquarter_766L','pmtssum_45A','min_dtlastpmtallstes_3545839D',\n        'count_num_group1_tax_registry_a','max_inittransactioncode_279L','max_credtype_587L','max_conts_type_509L','min_isbidproduct_390L',\n        'max_rejectreasonclient_4145042M','max_rejectreason_755M','max_isbidproduct_390L','max_amount_4527230A','mean_pmts_dpd_303P',\n        'maxdpdlast6m_474P','mean_firstnonzeroinstldate_307D','max_relationshiptoclient_642T','sum_credamount_590A','credamount_770A',\n        'pmtscount_423L','numinstunpaidmaxest_4493212L','numinsttopaygrest_4493213L','avgdbddpdlast3m_4187120P',\n        'numinsttopaygr_769L','sum_credacc_actualbalance_314A','numinstunpaidmax_3546851L','max_empl_employedtotal_800L','price_1097A',\n        'ratio_queries_30','max_postype_4733339M','mean_creationdate_885D','maxdebt4_972A',\n        'mean_amount_4527230A','thirdquarter_1082L','sum_mainoccupationinc_437A','sum_pmtamount_36A','maxdpdinstldate_3546855D',\n        'min_purposeofcred_874M','max_description_351M','description_5085714M','min_dtlastpmt_581D',\n        'totaldebt_9A','max_contractst_964M','currdebt_22A','min_firstnonzeroinstldate_307D',\n        \n         'max_contractst_545M','max_purposeofcred_426M','max_pmts_dpd_303P',\n        'max_classificationofcontr_13M','max_financialinstitution_591M','max_classificationofcontr_400M','max_financialinstitution_382M','count_num_group1',\n        'eir_270L','interestrate_311L','min_purposeofcred_426M','maxdbddpdlast1m_3658939P',\n        'sum_revolvingaccount_394A','max_firstnonzeroinstldate_307D','min_dateactivated_425D','firstdatedue_489D','min_approvaldate_319D',\n        'min_refreshdate_3813885D','totalsettled_863A','count_persontype_1072L','max_credacc_cards_status_52L','min_creationdate_885D',\n        'max_pmtamount_36A','min_pmtnum_8L','min_tenor_203L','count_num_group1_tax_registry_c','max_credacc_status_367L',\n        'sumoutstandtotalest_4493215A','datelastunpaid_3546854D','sum_persontype_1072L','sumoutstandtotal_3546847A',\n        'numinstls_657L','mean_dtlastpmtallstes_3545839D','max_familystate_447L','mean_pmtamount_36A',\n        'max_purposeofcred_874M','maxdpdlast3m_392P','mean_credacc_actualbalance_314A','currdebtcredtyperange_828A',\n        'sum_persontype_792L','lastapplicationdate_877D','max_creationdate_885D','max_outstandingdebt_522A','max_credacc_actualbalance_314A',\n        \n        'max_currdebt_94A','max_pmts_dpd_1073P','mean_credamount_590A','sum_personindex_1023L','min_credacc_actualbalance_314A',\n        'sum_outstandingdebt_522A','min_amount_4527230A','mean_persontype_792L','mean_credacc_credlmt_575A','lastactivateddate_801D',\n        'sum_currdebt_94A','count_personindex_1023L','count_relationshiptoclient_642T','max_dateactivated_425D','max_housetype_905L',\n        'min_currdebt_94A','max_relationshiptoclient_415T','min_lastupdate_388D','min_processingdate_168D',\n        'min_dateofrealrepmt_138D','mean_lastupdate_388D','max_persontype_1072L','max_persontype_792L','min_pmtamount_36A',\n        'lastapprcommoditycat_1041M','pmtaverage_4527227A','annuity_780A','mean_dateofrealrepmt_138D',\n        'sum_annuity_853A','mean_pmts_dpd_1073P','min_credacc_credlmt_575A','lastapprdate_640D','mean_credacc_minhisbal_90A',\n        'min_dateofcredend_353D','mean_dtlastpmt_581D','max_credacc_minhisbal_90A','avgoutstandbalancel6m_4187114A','max_approvaldate_319D',\n        'maxannuity_159A','min_credacc_minhisbal_90A','sum_amount_4917619A','cntincpaycont9m_3716944L','min_dateofcredstart_181D',\n        'mean_refreshdate_3813885D','max_remitter_829L','pmtaverage_3A','avglnamtstart24m_4525187A','education_1103M',\n       'mean_dpdmax_139P','mean_numberofoverdueinstlmax_1039L','min_recorddate_4527225D','min_annuity_853A',\n        'max_dpdmax_139P','sum_dpdmax_139P','lastdelinqdate_224D','mean_persontype_1072L',\n        'count_num_group1_cb_a_2','count_num_group2_cb_a_2','twobodfilling_608L','sum_numberofoverdueinstlmax_1039L','homephncnt_628L',\n        'count_num_group1_tax_registry_b','datefirstoffer_1144D','max_numberofoverdueinstlmax_1039L','min_numberofoverdueinstlmax_1039L',\n        'mean_downpmt_134A','max_empls_economicalst_849M','min_revolvingaccount_394A','responsedate_4527233D',\n        'sum_isbidproduct_390L','max_mainoccupationinc_437A','count_familystate_447L','min_dateofcredstart_739D','max_amount_4917619A',\n        'mean_dateofcredend_353D','min_dpdmax_139P','mean_revolvingaccount_394A','maininc_215A','lastrejectcredamount_222A',\n        'max_processingdate_168D','min_totaldebtoverduevalue_178A','inittransactioncode_186L','max_deductiondate_4917603D',\n        'min_deductiondate_4917603D','mean_processingdate_168D','contractssum_5085716L','mean_dateofcredstart_181D','applicationscnt_867L',\n        'mean_amount_4917619A','max_revolvingaccount_394A','mean_isbidproduct_390L','mean_dateofcredstart_739D','min_pmts_dpd_1073P',\n        \n        'sum_credacc_credlmt_575A','min_pmts_dpd_303P','lastapprcredamount_781A','max_empl_industry_691L',\n        'min_amount_4917619A','mean_annuity_853A',\n       'max_overdueamountmaxdatemonth_365T','max_downpmt_134A','disbursementtype_67L',\n        'min_overdueamountmaxdatemonth_284T','sum_numberofcontrsvalue_358L','count_num_group1_person2','sum_byoccupationinc_3656910L','mean_deductiondate_4917603D',\n        'sellerplacescnt_216L','mean_overdueamountmaxdatemonth_365T','max_overdueamountmaxdatemonth_284T','mean_approvaldate_319D','credtype_322L',\n        'max_numberofcontrsvalue_358L','mean_numberofcontrsvalue_358L','min_downpmt_134A','min_credacc_maxhisbal_375A','mean_isdebitcard_527L',\n        'min_mainoccupationinc_384A','bankacctype_710L','mean_pmts_overdue_1152A','min_numberofcontrsvalue_358L','min_mainoccupationinc_437A',\n        'min_residualamount_856A','mean_byoccupationinc_3656910L','downpmt_116A','isbidproduct_1095L','clientscnt12m_3712952L',\n        'mean_credacc_maxhisbal_375A','max_nominalrate_281L','mean_dateactivated_425D','sum_downpmt_134A','mean_totaldebtoverduevalue_178A',\n        \n         'mean_numberofinstls_320L','max_numberofinstls_320L','max_isdebitcard_527L','mean_nominalrate_281L','dtlastpmtallstes_4499206D',\n        'max_lastupdate_388D','responsedate_4917613D','sum_credacc_minhisbal_90A','max_byoccupationinc_3656910L',\n        'min_credacc_transactions_402L','min_instlamount_768A','inittransactionamount_650A','max_totaldebtoverduevalue_178A','min_isdebitcard_527L',\n        'clientscnt6m_3712949L','mean_credacc_transactions_402L','max_credacc_maxhisbal_375A','min_numberofinstls_320L','mean_totalamount_996A',\n        'validfrom_1069D','count_num_group1_cb_a_1','mean_residualamount_856A','max_debtoverdue_47A',\n        'max_dateofrealrepmt_138D','mean_totalamount_6A','min_pmts_overdue_1152A',\"max_cancelreason_3545846M\",\n    ]\n    \n    features125=[\n        \n        'max_role_1084L', 'max_language1_981M', 'max_sex_738L','max_incometype_1044T','max_education_927M',\n        'max_type_25L','max_safeguarantyflag_411L','min_pmts_month_158T','min_pmts_month_706T','max_pmts_month_158T',\n        'max_pmts_month_706T','mean_pmts_month_706T','mean_pmts_month_158T','pctinstlsallpaidlate1d_3546856L','pctinstlsallpaidlate4d_3546849L',\n        'pctinstlsallpaidlate6d_3546844L','pctinstlsallpaidlat10d_839L','max_contaddr_smempladdr_334L','max_contaddr_matchlist_1032L','numinstlswithdpd10_728L',\n        'pctinstlsallpaidearl3d_427L','lastrejectreason_759M','days120_123L','days180_256L','days90_310L',\n        'lastrejectreasonclient_4145040M','lastcancelreason_561M','lastst_736L','numrejects9m_859L',\n        'avgmaxdpdlast9m_3716943P','numberofqueries_373L','days360_512L','days30_165L','mobilephncnt_593L',\n        'max_birth_259D','numcontrs3months_479L','dateofbirth_337D','numinstpaidearly3d_3546850L','sum_maxdpdtolerance_577P',\n        'max_maxdpdtolerance_577P','numinstlallpaidearly3d_817L','maxdpdtolerance_374P','numinstlsallpaid_934L','daysoverduetolerancedd_3976961L',\n        'max_employedfrom_700D','mean_maxdpdtolerance_577P','mean_employedfrom_700D','numinstpaidearly_338L','avgdpdtolclosure24_3658938P',\n        \n        'mean_pmtnum_8L','mean_tenor_203L','lastrejectdate_50D','numinstlswithoutdpd_562L','avgdbddpdlast24m_3658932P',\n        'max_pmtnum_8L','max_tenor_203L','numinstpaidearly3dest_4493216L','numinstmatpaidtearly2d_4499204L','min_employedfrom_700D',\n        'requesttype_4525192L','maxdpdfrom6mto36m_3546853P','maxdpdlast24m_143P','datelastinstal40dpd_247D','mindbddpdlast24m_3658935P',\n        'amtinstpaidbefduel24m_4187115A','avgdbdtollast24m_4525197P','maxdpdlast12m_727P','maxdbddpdtollast12m_3658940P',\n        'max_empl_employedfrom_271D','min_empl_employedfrom_271D','mean_empl_employedfrom_271D','min_maxdpdtolerance_577P','firstclxcampaign_1125D',\n        'max_status_219L','sum_pmtnum_8L','sum_tenor_203L','monthsannuity_845L','pmtnum_254L',\n        'max_education_1138M','maxdpdlast9m_1059P','sum_amount_4527230A','mindbdtollast24m_4525191P','min_subjectroles_name_541M',\n        'birthdate_574D','max_subjectroles_name_838M','max_subjectroles_name_541M','min_subjectroles_name_838M','ratio_queries_120',\n        'ratio_queries_90','mean_outstandingdebt_522A','cntpmts24_3658933L','ratio_queries_180','maxdbddpdtollast6m_4187119P',\n        'mean_currdebt_94A','max_familystate_726L','numinstregularpaidest_4493210L','numincomingpmts_3546848L','numinstpaid_4499208L',\n         'numinstregularpaid_973L','disbursedcredamount_1113A','secondquarter_766L','pmtssum_45A','min_dtlastpmtallstes_3545839D',\n        'count_num_group1_tax_registry_a','max_inittransactioncode_279L','max_credtype_587L','max_conts_type_509L','min_isbidproduct_390L',\n        'max_rejectreasonclient_4145042M','max_rejectreason_755M','max_isbidproduct_390L','max_amount_4527230A','mean_pmts_dpd_303P',\n        'maxdpdlast6m_474P','mean_firstnonzeroinstldate_307D','max_relationshiptoclient_642T','sum_credamount_590A','credamount_770A',\n        'pmtscount_423L','max_empl_industry_691L','numinstunpaidmaxest_4493212L','numinsttopaygrest_4493213L','avgdbddpdlast3m_4187120P',\n        \n    ]\n    \n    features200=[\n         'max_role_1084L', 'max_language1_981M', 'max_sex_738L','max_incometype_1044T','max_education_927M',\n        'max_type_25L','max_safeguarantyflag_411L','min_pmts_month_158T','min_pmts_month_706T','max_pmts_month_158T',\n        'max_pmts_month_706T','mean_pmts_month_706T','mean_pmts_month_158T','pctinstlsallpaidlate1d_3546856L','pctinstlsallpaidlate4d_3546849L',\n        'pctinstlsallpaidlate6d_3546844L','pctinstlsallpaidlat10d_839L','max_contaddr_smempladdr_334L','max_contaddr_matchlist_1032L','numinstlswithdpd10_728L',\n        'pctinstlsallpaidearl3d_427L','lastrejectreason_759M','days120_123L','days180_256L','days90_310L',\n        'lastrejectreasonclient_4145040M','lastcancelreason_561M','lastst_736L','numrejects9m_859L',\n        'avgmaxdpdlast9m_3716943P','numberofqueries_373L','days360_512L','days30_165L','mobilephncnt_593L',\n        'max_birth_259D','numcontrs3months_479L','dateofbirth_337D','numinstpaidearly3d_3546850L','sum_maxdpdtolerance_577P',\n        'max_maxdpdtolerance_577P','numinstlallpaidearly3d_817L','maxdpdtolerance_374P','numinstlsallpaid_934L','daysoverduetolerancedd_3976961L',\n        'max_employedfrom_700D','mean_maxdpdtolerance_577P','mean_employedfrom_700D','numinstpaidearly_338L','avgdpdtolclosure24_3658938P',\n        \n        'mean_pmtnum_8L','mean_tenor_203L','lastrejectdate_50D','numinstlswithoutdpd_562L','avgdbddpdlast24m_3658932P',\n        'max_pmtnum_8L','max_tenor_203L','numinstpaidearly3dest_4493216L','numinstmatpaidtearly2d_4499204L','min_employedfrom_700D',\n        'requesttype_4525192L','maxdpdfrom6mto36m_3546853P','maxdpdlast24m_143P','datelastinstal40dpd_247D','mindbddpdlast24m_3658935P',\n        'amtinstpaidbefduel24m_4187115A','avgdbdtollast24m_4525197P','maxdpdlast12m_727P','maxdbddpdtollast12m_3658940P',\n        'max_empl_employedfrom_271D','min_empl_employedfrom_271D','mean_empl_employedfrom_271D','min_maxdpdtolerance_577P','firstclxcampaign_1125D',\n        'max_status_219L','sum_pmtnum_8L','sum_tenor_203L','monthsannuity_845L','pmtnum_254L',\n        'max_education_1138M','maxdpdlast9m_1059P','sum_amount_4527230A','mindbdtollast24m_4525191P','min_subjectroles_name_541M',\n        'birthdate_574D','max_subjectroles_name_838M','max_subjectroles_name_541M','min_subjectroles_name_838M','ratio_queries_120',\n        'ratio_queries_90','mean_outstandingdebt_522A','cntpmts24_3658933L','ratio_queries_180','maxdbddpdtollast6m_4187119P',\n        'mean_currdebt_94A','max_familystate_726L','numinstregularpaidest_4493210L','numincomingpmts_3546848L','numinstpaid_4499208L',\n        \n         'numinstregularpaid_973L','disbursedcredamount_1113A','secondquarter_766L','pmtssum_45A','min_dtlastpmtallstes_3545839D',\n        'count_num_group1_tax_registry_a','max_inittransactioncode_279L','max_credtype_587L','max_conts_type_509L','min_isbidproduct_390L',\n        'max_rejectreasonclient_4145042M','max_rejectreason_755M','max_isbidproduct_390L','max_amount_4527230A','mean_pmts_dpd_303P',\n        'maxdpdlast6m_474P','mean_firstnonzeroinstldate_307D','max_relationshiptoclient_642T','sum_credamount_590A','credamount_770A',\n        'pmtscount_423L','numinstunpaidmaxest_4493212L','numinsttopaygrest_4493213L','avgdbddpdlast3m_4187120P',\n        'numinsttopaygr_769L','sum_credacc_actualbalance_314A','numinstunpaidmax_3546851L','max_empl_employedtotal_800L','price_1097A',\n        'ratio_queries_30','max_postype_4733339M','mean_creationdate_885D','maxdebt4_972A',\n        'mean_amount_4527230A','thirdquarter_1082L','sum_mainoccupationinc_437A','sum_pmtamount_36A','maxdpdinstldate_3546855D',\n        'min_purposeofcred_874M','max_description_351M','description_5085714M','min_dtlastpmt_581D',\n        'totaldebt_9A','max_contractst_964M','currdebt_22A','min_firstnonzeroinstldate_307D',\n        \n         'max_contractst_545M','max_purposeofcred_426M','max_pmts_dpd_303P',\n        'max_classificationofcontr_13M','max_financialinstitution_591M','max_classificationofcontr_400M','max_financialinstitution_382M','count_num_group1',\n        'eir_270L','interestrate_311L','min_purposeofcred_426M','maxdbddpdlast1m_3658939P',\n        'sum_revolvingaccount_394A','max_firstnonzeroinstldate_307D','min_dateactivated_425D','firstdatedue_489D','min_approvaldate_319D',\n        'min_refreshdate_3813885D','totalsettled_863A','count_persontype_1072L','max_credacc_cards_status_52L','min_creationdate_885D',\n        'max_pmtamount_36A','min_pmtnum_8L','min_tenor_203L','count_num_group1_tax_registry_c','max_credacc_status_367L',\n        'sumoutstandtotalest_4493215A','datelastunpaid_3546854D','sum_persontype_1072L','sumoutstandtotal_3546847A',\n        'numinstls_657L','mean_dtlastpmtallstes_3545839D','max_familystate_447L','mean_pmtamount_36A',\n        'max_purposeofcred_874M','maxdpdlast3m_392P','mean_credacc_actualbalance_314A','currdebtcredtyperange_828A',\n        'sum_persontype_792L','lastapplicationdate_877D','max_creationdate_885D','max_outstandingdebt_522A','max_credacc_actualbalance_314A',\n        \n        'max_currdebt_94A','max_pmts_dpd_1073P','mean_credamount_590A','sum_personindex_1023L','min_credacc_actualbalance_314A',\n        'sum_outstandingdebt_522A','min_amount_4527230A','mean_persontype_792L','mean_credacc_credlmt_575A','lastactivateddate_801D',\n        'sum_currdebt_94A','count_personindex_1023L','count_relationshiptoclient_642T','max_dateactivated_425D','max_housetype_905L',\n        'min_currdebt_94A','max_relationshiptoclient_415T','min_lastupdate_388D','min_processingdate_168D',\n        'min_dateofrealrepmt_138D','mean_lastupdate_388D','max_persontype_1072L','max_persontype_792L','min_pmtamount_36A',\n        'lastapprcommoditycat_1041M','pmtaverage_4527227A','annuity_780A','mean_dateofrealrepmt_138D'\n    ]\n    seen = set()\n    duplicates = []\n    for item in features400:\n        if item in seen:\n            duplicates.append(item)\n        else:\n            seen.add(item)\n    print(\"duplicates:\")\n    print(duplicates)\n    print()\n    \n    print(\"Length of features400: \", len(features400))\n    print(\"Length of features200: \", len(features200))\n    print(\"Length of features125: \", len(features125))\n    missing_columns = [col for col in features400 if col not in df.columns]\n\n    # Print missing columns, if any\n    if missing_columns:\n        print(\"The following columns are missing in the DataFrame:\")\n        for col in missing_columns:\n            print(col)\n    else:\n        print(\"All columns from features400 are present in the DataFrame.\")\n    \n    # Columns to preserve\n    preserved_columns = ['target', 'case_id', 'WEEK_NUM']\n\n    # Identify columns to drop excluding the preserved columns\n    columns_to_drop = [col for col in df.columns if col not in preserved_columns + features125]\n\n    # Drop columns that are not in features_selected and not preserved\n    \n    df=df.drop(columns=columns_to_drop)\n    \n    \n    if BALANCE_COLUMNS:\n\n        # the test set might be different, so lets drop the columns that have many nan values in test set\n        train = df.filter(df['target'].is_not_null())\n        test = df.filter(df['target'].is_null())\n\n        valid_percentage_train = []\n        valid_percentage_test=[]\n        for col in df.columns:\n            valid_percentage_train.append(train[col].count())\n            valid_percentage_test.append(test[col].count())\n\n        valid_percentage_train = pd.Series(valid_percentage_train)\n        valid_percentage_test= pd.Series(valid_percentage_test)\n\n        print(train.count())\n        print(test.count())\n        print(\"length of train\",len(valid_percentage_train))\n        print(\"length of test\",len(valid_percentage_test))\n        print(\"df columns\",len(df.columns))\n\n        info_df = pd.DataFrame({'column': df.columns, 'valid_train': valid_percentage_train, 'valid_test': valid_percentage_test})\n        irrelevant_columns = info_df[info_df['valid_test'] < 0.5 * info_df['valid_train']]['column'].to_list()\n        columns_to_drop = [col for col in df.columns if (col not in preserved_columns) and (col in irrelevant_columns) ]\n        df = df.drop(columns=columns_to_drop)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.645343Z","iopub.execute_input":"2024-03-27T19:21:23.645848Z","iopub.status.idle":"2024-03-27T19:21:23.715827Z","shell.execute_reply.started":"2024-03-27T19:21:23.645804Z","shell.execute_reply":"2024-03-27T19:21:23.714178Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"'''\ndf = get_base(DATA_DIRECTORY)\ndf_applprev1 = get_applprev1(DATA_DIRECTORY)\ndf_applprev1 = df_applprev1.filter(pl.col('case_id').is_in(df['case_id'].unique()))\ndf = df.join(df_applprev1, on='case_id', how='left', suffix='_applprev1')\nprint(\"Previous applications depth 1 test dataframe shape:\", df_applprev1.shape)\nprint(\"DATAFRAME shape:\", df.shape)\ndel df_applprev1\ngc.collect()\n\n\ndf=feature_engineering(df)\nprint(df['credit_income_percent'])\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.717585Z","iopub.execute_input":"2024-03-27T19:21:23.718695Z","iopub.status.idle":"2024-03-27T19:21:23.727446Z","shell.execute_reply.started":"2024-03-27T19:21:23.718649Z","shell.execute_reply":"2024-03-27T19:21:23.726353Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'\\ndf = get_base(DATA_DIRECTORY)\\ndf_applprev1 = get_applprev1(DATA_DIRECTORY)\\ndf_applprev1 = df_applprev1.filter(pl.col(\\'case_id\\').is_in(df[\\'case_id\\'].unique()))\\ndf = df.join(df_applprev1, on=\\'case_id\\', how=\\'left\\', suffix=\\'_applprev1\\')\\nprint(\"Previous applications depth 1 test dataframe shape:\", df_applprev1.shape)\\nprint(\"DATAFRAME shape:\", df.shape)\\ndel df_applprev1\\ngc.collect()\\n\\n\\ndf=feature_engineering(df)\\nprint(df[\\'credit_income_percent\\'])\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"# **GET FUNCTIONS**","metadata":{}},{"cell_type":"markdown","source":"### get_base()","metadata":{}},{"cell_type":"code","source":"def get_base(path, num_rows = None):\n    # Read the Parquet file using scan() method\n    train={}\n    test={}\n    \n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_base.parquet'))\n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_base.parquet')).limit(num_rows) \n        \n    test = pl.read_parquet(os.path.join(path, 'test/test_base.parquet'))    \n    length=len(test)\n    nan_series=pl.Series([None] * length)\n    test = test.select(pl.col(\"*\"), nan_series.alias(\"target\"))\n    df=pl.concat([train, test])\n    del test;del train;gc.collect()\n    \n    \n    df = df.with_columns(pl.col('date_decision').cast(pl.Date))\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.729042Z","iopub.execute_input":"2024-03-27T19:21:23.729737Z","iopub.status.idle":"2024-03-27T19:21:23.741778Z","shell.execute_reply.started":"2024-03-27T19:21:23.729704Z","shell.execute_reply":"2024-03-27T19:21:23.740587Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### get_static()","metadata":{}},{"cell_type":"code","source":"def get_static(path, num_rows = None):\n# Read the Parquet file using scan() method\n    chunks = []\n    for path in glob(DATA_DIRECTORY+str('train/train_static_0_*.parquet')):\n        chunks.append(pl.read_parquet(path,low_memory=True).pipe(Pipeline.set_table_dtypes) )\n    train = (pl.concat(chunks, how=\"vertical_relaxed\")).pipe(Pipeline.filter_cols)\n    \n    if num_rows!= None:\n        df1 = train.slice(0,num_rows)\n        df2 = train.slice(num_rows,len(train))\n        \n        train=df1\n        del df2\n        gc.collect()\n    chunks = []\n    for path in glob(DATA_DIRECTORY+str('test/test_static_0_*.parquet')):\n        chunks.append(pl.read_parquet(path,low_memory=True).pipe(Pipeline.set_table_dtypes) )\n    test = pl.concat(chunks, how=\"vertical_relaxed\")\n    \n    \n    columns_to_keep = train.columns\n\n# Find columns in 'test' that are not in 'train'\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n\n# Drop columns from 'test' that are not in 'train'\n    test = test.drop(columns_to_remove)\n    df=pl.concat([train, test])\n    del test;del train;gc.collect()\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.743354Z","iopub.execute_input":"2024-03-27T19:21:23.743784Z","iopub.status.idle":"2024-03-27T19:21:23.755786Z","shell.execute_reply.started":"2024-03-27T19:21:23.743751Z","shell.execute_reply":"2024-03-27T19:21:23.754292Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### get_static_cb()","metadata":{}},{"cell_type":"code","source":"def get_static_cb(path, num_rows = None):\n    \n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_static_cb_0.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_static_cb_0.parquet'),low_memory=True).limit(num_rows).pipe(Pipeline.set_table_dtypes) \n       \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_static_cb_0.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del test;del train;gc.collect()\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.757892Z","iopub.execute_input":"2024-03-27T19:21:23.758458Z","iopub.status.idle":"2024-03-27T19:21:23.770025Z","shell.execute_reply.started":"2024-03-27T19:21:23.758412Z","shell.execute_reply":"2024-03-27T19:21:23.768737Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### get_applprev1(DATA_DIRECTORY, num_rows=num_rows)","metadata":{}},{"cell_type":"code","source":"def get_applprev1(path, num_rows = None):\n    \n    \n    chunks = []\n    for path in glob(DATA_DIRECTORY+str('train/train_applprev_1_*.parquet')):\n        chunks.append(pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes))\n    train = pl.concat(chunks, how=\"vertical_relaxed\")#.pipe(Pipeline.filter_cols)\n    \n    \n    if num_rows!= None:\n        df1 = train.slice(0,num_rows)\n        df2 = train.slice(num_rows,len(train))\n\n        train=df1\n        del df2   \n        gc.collect()\n    chunks = []\n    for path in glob(DATA_DIRECTORY+str('test/test_applprev_1_*.parquet')):\n        chunks.append(pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes))\n    test = pl.concat(chunks, how=\"vertical_relaxed\")\n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n    df=pl.concat([train, test])\n    del test;del train;gc.collect()\n    agg_df = group(df, '', APPLPREV1_AGG)\n    del df;gc.collect()\n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.772004Z","iopub.execute_input":"2024-03-27T19:21:23.772465Z","iopub.status.idle":"2024-03-27T19:21:23.784769Z","shell.execute_reply.started":"2024-03-27T19:21:23.772421Z","shell.execute_reply":"2024-03-27T19:21:23.783328Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### get_applprev2(DATA_DIRECTORY, num_rows=num_rows)","metadata":{}},{"cell_type":"code","source":"def get_applprev2(path, num_rows = None):\n    train={}\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_applprev_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n     \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_applprev_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n       \n    \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_applprev_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', APPLPREV2_AGG)\n    del df ;gc.collect()\n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.786891Z","iopub.execute_input":"2024-03-27T19:21:23.787347Z","iopub.status.idle":"2024-03-27T19:21:23.799942Z","shell.execute_reply.started":"2024-03-27T19:21:23.787304Z","shell.execute_reply":"2024-03-27T19:21:23.798647Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### get_person1","metadata":{}},{"cell_type":"code","source":"def get_person1(path, num_rows = None):\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_person_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_person_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n      \n    \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_person_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', PERSON1_AGG)\n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.801390Z","iopub.execute_input":"2024-03-27T19:21:23.803815Z","iopub.status.idle":"2024-03-27T19:21:23.814861Z","shell.execute_reply.started":"2024-03-27T19:21:23.803775Z","shell.execute_reply":"2024-03-27T19:21:23.813469Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### get_person2","metadata":{}},{"cell_type":"code","source":"def get_person2(path, num_rows = None):\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_person_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_person_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes)\n        \n    test = pl.read_parquet(os.path.join(path, 'test/test_person_2.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', PERSON2_AGG)\n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.816591Z","iopub.execute_input":"2024-03-27T19:21:23.817026Z","iopub.status.idle":"2024-03-27T19:21:23.828891Z","shell.execute_reply.started":"2024-03-27T19:21:23.816991Z","shell.execute_reply":"2024-03-27T19:21:23.827466Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### other","metadata":{}},{"cell_type":"code","source":"def get_other(path, num_rows = None):\n     # Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_other_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_other_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n         \n    test = pl.read_parquet(os.path.join(path, 'test/test_other_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', OTHER_AGG)\n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.835890Z","iopub.execute_input":"2024-03-27T19:21:23.836282Z","iopub.status.idle":"2024-03-27T19:21:23.845730Z","shell.execute_reply.started":"2024-03-27T19:21:23.836251Z","shell.execute_reply":"2024-03-27T19:21:23.844635Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## get_debitcard","metadata":{}},{"cell_type":"code","source":"def get_debitcard(path, num_rows = None):\n    # Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_debitcard_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n     \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_debitcard_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n      \n        \n    test = pl.read_parquet(os.path.join(path, 'test/test_debitcard_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', DEBITCARD_AGG)\n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.847423Z","iopub.execute_input":"2024-03-27T19:21:23.847794Z","iopub.status.idle":"2024-03-27T19:21:23.864220Z","shell.execute_reply.started":"2024-03-27T19:21:23.847752Z","shell.execute_reply":"2024-03-27T19:21:23.863068Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### get_tax_registry_a","metadata":{}},{"cell_type":"code","source":"def get_tax_registry_a(path, num_rows = None):\n    \n    # Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_a_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_a_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n  \n    \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_tax_registry_a_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', TAX_REGISTRY_A_AGG)    \n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.866228Z","iopub.execute_input":"2024-03-27T19:21:23.866726Z","iopub.status.idle":"2024-03-27T19:21:23.878373Z","shell.execute_reply.started":"2024-03-27T19:21:23.866683Z","shell.execute_reply":"2024-03-27T19:21:23.877255Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### get_tax_registry_b","metadata":{}},{"cell_type":"code","source":"def get_tax_registry_b(path, num_rows = None):\n    # Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_b_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes)\n        \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_b_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_tax_registry_b_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', TAX_REGISTRY_B_AGG) \n    del df;gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.880214Z","iopub.execute_input":"2024-03-27T19:21:23.880582Z","iopub.status.idle":"2024-03-27T19:21:23.890971Z","shell.execute_reply.started":"2024-03-27T19:21:23.880550Z","shell.execute_reply":"2024-03-27T19:21:23.889849Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### get_tax_registry_c","metadata":{}},{"cell_type":"code","source":"def get_tax_registry_c(path, num_rows = None):\n     # Read the Parquet file using scan() method\n# Read the Parquet file using scan() method\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_c_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_tax_registry_c_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n        \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_tax_registry_c_1.parquet'),low_memory=True).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test;gc.collect()\n    agg_df = group(df, '', TAX_REGISTRY_C_AGG)    \n    del df; gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.892903Z","iopub.execute_input":"2024-03-27T19:21:23.893402Z","iopub.status.idle":"2024-03-27T19:21:23.905240Z","shell.execute_reply.started":"2024-03-27T19:21:23.893359Z","shell.execute_reply":"2024-03-27T19:21:23.903772Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### get_credit_bureau_a_1","metadata":{}},{"cell_type":"code","source":"def get_credit_bureau_a_1(path, num_rows = None):\n    \n    \n    \n    agg_chunks=[]\n    \n    for path in glob(DATA_DIRECTORY + 'train/train_credit_bureau_a_1_*.parquet'):\n        file_df=pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes)\n        agg_file_df = group(file_df, '', CREDIT_BUREAU_A_1_AGG, datatype='polars')\n        agg_chunks.append(agg_file_df)\n        del file_df; gc.collect()\n    \n    \n    train_agg_df=agg_chunks[0]\n    for agg_chunk in agg_chunks[1:]:\n        train_agg_df.vstack(agg_chunk)\n    train_agg_df.rechunk()\n        \n        \n    \n    \n    \n    agg_chunks=[]\n    \n    for path in glob(DATA_DIRECTORY + 'test/test_credit_bureau_a_1_*.parquet'):\n        file_df=pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes)\n        agg_file_df = group(file_df, '', CREDIT_BUREAU_A_1_AGG, datatype='polars')\n        agg_chunks.append(agg_file_df)\n        del file_df; gc.collect()\n        \n        \n    test_agg_df=agg_chunks[0]\n    for agg_chunk in agg_chunks[1:]:\n        test_agg_df.vstack(agg_chunk)\n    test_agg_df.rechunk()\n    \n    \n    \n\n    \n    agg_df=train_agg_df\n    agg_df.extend(test_agg_df)\n    \n\n    \n    \n    print(\"agg df \", agg_df.shape)\n   \n    unique_count = agg_df['case_id'].n_unique()\n\n    print(\"Number of unique values in 'case_id' column:\", unique_count)\n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.907140Z","iopub.execute_input":"2024-03-27T19:21:23.907639Z","iopub.status.idle":"2024-03-27T19:21:23.922045Z","shell.execute_reply.started":"2024-03-27T19:21:23.907595Z","shell.execute_reply":"2024-03-27T19:21:23.920417Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### get_credit_bureau_b_1","metadata":{}},{"cell_type":"code","source":"def get_credit_bureau_b_1(path, num_rows = None):\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_1.parquet')).pipe(Pipeline.set_table_dtypes) \n        \n        \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_1.parquet')).pipe(Pipeline.set_table_dtypes) \n   \n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_credit_bureau_b_1.parquet')).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n\n    df=pl.concat([train, test])\n    del train; del test ; gc.collect()\n    agg_df = group(df, '', CREDIT_BUREAU_B_1_AGG) \n    \n    \n    del df; gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.923981Z","iopub.execute_input":"2024-03-27T19:21:23.924883Z","iopub.status.idle":"2024-03-27T19:21:23.935623Z","shell.execute_reply.started":"2024-03-27T19:21:23.924838Z","shell.execute_reply":"2024-03-27T19:21:23.934466Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### get_credit_bureau_a_2","metadata":{}},{"cell_type":"code","source":"def get_credit_bureau_a_2(path, num_rows = None):\n    \n    \n    \n    agg_chunks=[]\n    \n    for path in glob(DATA_DIRECTORY + 'train/train_credit_bureau_a_2_*.parquet'):\n        file_df=pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes)\n        agg_file_df = group(file_df, '', CREDIT_BUREAU_A_2_AGG, datatype='polars')\n        agg_chunks.append(agg_file_df)\n        del file_df;gc.collect()\n    \n    train_agg_df=agg_chunks[0]\n    for agg_chunk in agg_chunks[1:]:\n        train_agg_df.vstack(agg_chunk)\n    train_agg_df.rechunk()\n    \n    \n    agg_chunks=[]\n    \n    for path in glob(DATA_DIRECTORY + 'test/test_credit_bureau_a_2_*.parquet'):\n        file_df=pl.read_parquet(path, low_memory=True).pipe(Pipeline.set_table_dtypes)\n        agg_file_df = group(file_df, '', CREDIT_BUREAU_A_2_AGG, datatype='polars')\n        agg_chunks.append(agg_file_df)\n        del file_df;gc.collect()\n    \n    test_agg_df=agg_chunks[0]\n    for agg_chunk in agg_chunks[1:]:\n        test_agg_df.vstack(agg_chunk)\n    test_agg_df.rechunk()\n    \n    agg_df=train_agg_df\n    agg_df.extend(test_agg_df)\n    \n    print(\"agg df \", agg_df.shape)\n   \n    unique_count = agg_df['case_id'].n_unique()\n\n    print(\"Number of unique values in 'case_id' column:\", unique_count)\n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.937008Z","iopub.execute_input":"2024-03-27T19:21:23.937604Z","iopub.status.idle":"2024-03-27T19:21:23.951263Z","shell.execute_reply.started":"2024-03-27T19:21:23.937521Z","shell.execute_reply":"2024-03-27T19:21:23.949820Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### get_credit_bureau_b_2","metadata":{}},{"cell_type":"code","source":"def get_credit_bureau_b_2(path, num_rows = None):\n    if num_rows == None:\n        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_2.parquet')).pipe(Pipeline.set_table_dtypes) \n   \n    else:\n        train = pl.read_parquet(os.path.join(path, 'train/train_credit_bureau_b_2.parquet')).pipe(Pipeline.set_table_dtypes) \n\n    \n    test = pl.read_parquet(os.path.join(path, 'test/test_credit_bureau_b_2.parquet')).pipe(Pipeline.set_table_dtypes) \n    \n    #train = train.pipe(Pipeline.filter_cols)\n   \n    columns_to_keep = train.columns\n    columns_to_remove = [column for column in test.columns if column not in columns_to_keep]\n    test = test.drop(columns_to_remove)\n    \n    df=pl.concat([train, test])\n    del train;del test; gc.collect()\n    agg_df = group(df, '', CREDIT_BUREAU_B_2_AGG) \n    \n    del df; gc.collect()\n    \n    return agg_df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.952963Z","iopub.execute_input":"2024-03-27T19:21:23.953307Z","iopub.status.idle":"2024-03-27T19:21:23.966066Z","shell.execute_reply.started":"2024-03-27T19:21:23.953279Z","shell.execute_reply":"2024-03-27T19:21:23.964565Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# **EXECUTION** <a id='execution'></a>\n\n[CONFIGURATION](#configuration) \n\n[MAIN FUNCTION](#main_function)\n\n[MODEL](#model)\n\n[EXECUTION](#execution)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\nif __name__ == \"__main__\":\n    pd.set_option('display.max_rows', 60)\n    pd.set_option('display.max_columns', 100)\n    with timer(\"Pipeline total time\"):\n        main(debug= True)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T19:21:23.967915Z","iopub.execute_input":"2024-03-27T19:21:23.968464Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Notebook started:\nbase dataframe shape: (1526669, 5)\nbase - done in 1s\nstatic dataframe shape: (1526669, 156)\nDATAFRAME shape: (1526669, 160)\nstatic - done in 14s\nstatic cb dataframe shape: (1500486, 31)\nDATAFRAME shape: (1526669, 190)\nstatic_cb - done in 4s\nPrevious applications depth 1 test dataframe shape: (1221524, 115)\nDATAFRAME shape: (1526669, 304)\nPrevious applications depth 1 test - done in 35s\nPrevious applications depth 2 test dataframe shape: (1221523, 5)\nDATAFRAME shape: (1526669, 308)\nPrevious applications depth 2 test - done in 5s\nPerson depth 1 test dataframe shape: (1526665, 47)\nDATAFRAME shape: (1526669, 354)\nPerson depth 1 test - done in 11s\nPerson depth 2 test dataframe shape: (1435108, 4)\nDATAFRAME shape: (1526669, 357)\nPerson depth 2 test - done in 2s\nOther test dataframe shape: (51111, 12)\nDATAFRAME shape: (1526669, 368)\nOther test - done in 1s\nDebit card test dataframe shape: (111772, 5)\nDATAFRAME shape: (1526669, 372)\nDebit card test - done in 1s\nTax registry a test dataframe shape: (457934, 10)\nDATAFRAME shape: (1526669, 381)\nTax registry a test - done in 3s\nTax registry b test dataframe shape: (150734, 10)\nDATAFRAME shape: (1526669, 390)\nTax registry b test - done in 1s\nTax registry c test dataframe shape: (482265, 10)\nDATAFRAME shape: (1526669, 399)\nTax registry c test - done in 3s\nagg df  (176609, 134)\nNumber of unique values in 'case_id' column: 176609\nCredit bureau a 1 test dataframe shape: (176609, 134)\nDATAFRAME shape: (1526669, 532)\nCredit bureau a 1 test - done in 87s\nCredit bureau b 1 test dataframe shape: (36500, 2)\nDATAFRAME shape: (1526669, 533)\nCredit bureau b 1 test - done in 1s\nagg df  (150427, 33)\nNumber of unique values in 'case_id' column: 150427\nCredit bureau a 2 test dataframe shape: (150427, 33)\nDATAFRAME shape: (1526669, 565)\nCredit bureau a 2 test - done in 71s\nCredit bureau b 2 test dataframe shape: (36447, 12)\nDATAFRAME shape: (1526669, 576)\nCredit bureau b 2 test - done in 1s\nduplicates:\n[]\n\nLength of features400:  347\nLength of features200:  216\nLength of features125:  123\nThe following columns are missing in the DataFrame:\nratio_queries_120\nratio_queries_90\nratio_queries_180\nratio_queries_30\nDataFrame Shape: (1526669, 123)\n------------------------------------------------------------\nColumn Name                                        Data Type                      NaN Percentage      \n------------------------------------------------------------\ncase_id                                            Int64                          0.00%\nWEEK_NUM                                           Int64                          0.00%\ntarget                                             Int64                          0.00%\namtinstpaidbefduel24m_4187115A                     Float64                        36.75%\navgdbddpdlast24m_3658932P                          Float64                        40.17%\navgdbddpdlast3m_4187120P                           Float64                        62.11%\navgdbdtollast24m_4525197P                          Float64                        63.72%\navgdpdtolclosure24_3658938P                        Float64                        30.60%\navgmaxdpdlast9m_3716943P                           Float64                        49.59%\ncntpmts24_3658933L                                 Float64                        30.18%\ncredamount_770A                                    Float64                        0.00%\ndatelastinstal40dpd_247D                           Int64                          91.23%\ndaysoverduetolerancedd_3976961L                    Float64                        29.65%\ndisbursedcredamount_1113A                          Float64                        0.00%\nfirstclxcampaign_1125D                             Int64                          56.28%\nlastcancelreason_561M                              String                         0.00%\nlastrejectdate_50D                                 Int64                          50.37%\nlastrejectreason_759M                              String                         0.00%\nlastrejectreasonclient_4145040M                    String                         0.00%\nlastst_736L                                        String                         19.99%\nmaxdbddpdtollast12m_3658940P                       Float64                        46.21%\nmaxdbddpdtollast6m_4187119P                        Float64                        57.40%\nmaxdpdfrom6mto36m_3546853P                         Float64                        22.49%\nmaxdpdlast12m_727P                                 Float64                        20.04%\nmaxdpdlast24m_143P                                 Float64                        20.04%\nmaxdpdlast6m_474P                                  Float64                        20.04%\nmaxdpdlast9m_1059P                                 Float64                        20.04%\nmaxdpdtolerance_374P                               Float64                        20.04%\nmindbddpdlast24m_3658935P                          Float64                        40.17%\nmindbdtollast24m_4525191P                          Float64                        63.72%\nmobilephncnt_593L                                  Float64                        0.00%\nmonthsannuity_845L                                 Float64                        29.65%\nnumcontrs3months_479L                              Float64                        0.00%\nnumincomingpmts_3546848L                           Float64                        29.81%\nnuminstlallpaidearly3d_817L                        Float64                        29.19%\nnuminstlsallpaid_934L                              Float64                        29.19%\nnuminstlswithdpd10_728L                            Float64                        29.90%\nnuminstlswithoutdpd_562L                           Float64                        29.90%\nnuminstmatpaidtearly2d_4499204L                    Float64                        55.49%\nnuminstpaid_4499208L                               Float64                        55.49%\nnuminstpaidearly3d_3546850L                        Float64                        29.28%\nnuminstpaidearly3dest_4493216L                     Float64                        55.06%\nnuminstpaidearly_338L                              Float64                        29.65%\nnuminstregularpaid_973L                            Float64                        29.84%\nnuminstregularpaidest_4493210L                     Float64                        55.06%\nnuminsttopaygrest_4493213L                         Float64                        55.06%\nnuminstunpaidmaxest_4493212L                       Float64                        55.06%\nnumrejects9m_859L                                  Float64                        0.00%\npctinstlsallpaidearl3d_427L                        Float64                        30.05%\npctinstlsallpaidlat10d_839L                        Float64                        30.22%\npctinstlsallpaidlate1d_3546856L                    Float64                        30.05%\npctinstlsallpaidlate4d_3546849L                    Float64                        30.12%\npctinstlsallpaidlate6d_3546844L                    Float64                        30.14%\npmtnum_254L                                        Float64                        2.94%\nbirthdate_574D                                     Int64                          60.18%\ndateofbirth_337D                                   Int64                          9.23%\ndays120_123L                                       Float64                        9.23%\ndays180_256L                                       Float64                        9.23%\ndays30_165L                                        Float64                        9.23%\ndays360_512L                                       Float64                        9.23%\ndays90_310L                                        Float64                        9.23%\nnumberofqueries_373L                               Float64                        9.23%\npmtscount_423L                                     Float64                        62.49%\npmtssum_45A                                        Float64                        62.49%\nrequesttype_4525192L                               String                         55.90%\nsecondquarter_766L                                 Float64                        9.23%\nsum_credamount_590A                                Float64                        19.99%\nmax_credtype_587L                                  String                         20.14%\nmean_currdebt_94A                                  Float64                        27.45%\nmin_dtlastpmtallstes_3545839D                      Int64                          35.96%\nmax_education_1138M                                String                         19.99%\nmin_employedfrom_700D                              Int64                          36.63%\nmax_employedfrom_700D                              Int64                          36.63%\nmean_employedfrom_700D                             Int64                          36.63%\nmax_familystate_726L                               String                         23.81%\nmean_firstnonzeroinstldate_307D                    Int64                          21.94%\nmax_inittransactioncode_279L                       String                         20.14%\nmin_isbidproduct_390L                              Boolean                        19.99%\nmax_isbidproduct_390L                              Boolean                        19.99%\nmin_maxdpdtolerance_577P                           Float64                        29.54%\nmax_maxdpdtolerance_577P                           Float64                        29.54%\nmean_maxdpdtolerance_577P                          Float64                        29.54%\nsum_maxdpdtolerance_577P                           Float64                        19.99%\nmean_outstandingdebt_522A                          Float64                        27.54%\nmax_pmtnum_8L                                      Float64                        21.06%\nmean_pmtnum_8L                                     Float64                        21.06%\nsum_pmtnum_8L                                      Float64                        19.99%\nmax_rejectreason_755M                              String                         19.99%\nmax_rejectreasonclient_4145042M                    String                         19.99%\nmax_status_219L                                    String                         19.99%\nmax_tenor_203L                                     Float64                        21.06%\nmean_tenor_203L                                    Float64                        21.06%\nsum_tenor_203L                                     Float64                        19.99%\nmax_conts_type_509L                                String                         20.04%\nmax_birth_259D                                     Int64                          0.00%\nmax_contaddr_matchlist_1032L                       Boolean                        0.03%\nmax_contaddr_smempladdr_334L                       Boolean                        0.03%\nmax_education_927M                                 String                         0.00%\nmax_empl_employedfrom_271D                         Int64                          62.88%\nmean_empl_employedfrom_271D                        Int64                          62.88%\nmin_empl_employedfrom_271D                         Int64                          62.88%\nmax_empl_industry_691L                             String                         65.79%\nmax_incometype_1044T                               String                         0.00%\nmax_language1_981M                                 String                         0.00%\nmax_relationshiptoclient_642T                      String                         61.29%\nmax_role_1084L                                     String                         0.00%\nmax_safeguarantyflag_411L                          Boolean                        0.00%\nmax_sex_738L                                       String                         0.00%\nmax_type_25L                                       String                         0.00%\ncount_num_group1_tax_registry_a                    UInt32                         70.00%\nmax_amount_4527230A                                Float64                        70.00%\nsum_amount_4527230A                                Float64                        70.00%\nmean_pmts_dpd_303P                                 Float64                        90.99%\nmin_pmts_month_158T                                Float64                        91.07%\nmean_pmts_month_158T                               Float64                        91.07%\nmax_pmts_month_158T                                Float64                        91.07%\nmin_pmts_month_706T                                Float64                        90.98%\nmean_pmts_month_706T                               Float64                        90.98%\nmax_pmts_month_706T                                Float64                        90.98%\nmin_subjectroles_name_541M                         String                         90.15%\nmax_subjectroles_name_541M                         String                         90.15%\nmin_subjectroles_name_838M                         String                         90.15%\nmax_subjectroles_name_838M                         String                         90.15%\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2190594624.py:314: DeprecationWarning: named `columns` param is deprecated; use positional `*args` instead.\n  df=df.drop(columns=columns_to_drop)\n","output_type":"stream"},{"name":"stdout","text":"Memory usage after optimization is: 342.16 MB\nDecreased by 69.6%\nDATAFRAME shape: (1526669, 123)\nFeature engineering / preprocessing - done in 26s\nColumn: case_id, Min Value: 0, Max Value: 2703454\nColumn: WEEK_NUM, Min Value: 0, Max Value: 100\nColumn: target, Min Value: 0.0, Max Value: 1.0\nColumn: amtinstpaidbefduel24m_4187115A, Min Value: 0.0, Max Value: 1408010.25\nColumn: avgdbddpdlast24m_3658932P, Min Value: -1220.0, Max Value: 4752.0\nColumn: avgdbddpdlast3m_4187120P, Min Value: -908.0, Max Value: 4752.0\nColumn: avgdbdtollast24m_4525197P, Min Value: -1220.0, Max Value: 4752.0\nColumn: avgdpdtolclosure24_3658938P, Min Value: 0.0, Max Value: 4752.0\nColumn: avgmaxdpdlast9m_3716943P, Min Value: 0.0, Max Value: 240.0\nColumn: cntpmts24_3658933L, Min Value: 0.0, Max Value: 25.0\nColumn: credamount_770A, Min Value: 2000.0, Max Value: 950000.0\nColumn: datelastinstal40dpd_247D, Min Value: -5228.0, Max Value: -26.0\nColumn: daysoverduetolerancedd_3976961L, Min Value: 0.0, Max Value: 5336.0\nColumn: disbursedcredamount_1113A, Min Value: 0.0, Max Value: 950000.0\nColumn: firstclxcampaign_1125D, Min Value: -2011.0, Max Value: 14.0\nColumn: lastrejectdate_50D, Min Value: -5336.0, Max Value: 14.0\nColumn: maxdbddpdtollast12m_3658940P, Min Value: -1199.0, Max Value: 4804.0\nColumn: maxdbddpdtollast6m_4187119P, Min Value: -1225.0, Max Value: 4804.0\nColumn: maxdpdfrom6mto36m_3546853P, Min Value: 0.0, Max Value: 4464.0\nColumn: maxdpdlast12m_727P, Min Value: 0.0, Max Value: 4628.0\nColumn: maxdpdlast24m_143P, Min Value: 0.0, Max Value: 4628.0\nColumn: maxdpdlast6m_474P, Min Value: 0.0, Max Value: 4628.0\nColumn: maxdpdlast9m_1059P, Min Value: 0.0, Max Value: 4628.0\nColumn: maxdpdtolerance_374P, Min Value: 0.0, Max Value: 4628.0\nColumn: mindbddpdlast24m_3658935P, Min Value: -1284.0, Max Value: 4708.0\nColumn: mindbdtollast24m_4525191P, Min Value: -1284.0, Max Value: 4708.0\nColumn: mobilephncnt_593L, Min Value: 0.0, Max Value: 23.0\nColumn: monthsannuity_845L, Min Value: 0.0, Max Value: 167.0\nColumn: numcontrs3months_479L, Min Value: 0.0, Max Value: 58.0\nColumn: numincomingpmts_3546848L, Min Value: 0.0, Max Value: 843.0\nColumn: numinstlallpaidearly3d_817L, Min Value: 0.0, Max Value: 377.0\nColumn: numinstlsallpaid_934L, Min Value: 0.0, Max Value: 385.0\nColumn: numinstlswithdpd10_728L, Min Value: 0.0, Max Value: 330.0\nColumn: numinstlswithoutdpd_562L, Min Value: 0.0, Max Value: 861.0\nColumn: numinstmatpaidtearly2d_4499204L, Min Value: 0.0, Max Value: 347.0\nColumn: numinstpaid_4499208L, Min Value: 0.0, Max Value: 393.0\nColumn: numinstpaidearly3d_3546850L, Min Value: 0.0, Max Value: 373.0\nColumn: numinstpaidearly3dest_4493216L, Min Value: 0.0, Max Value: 322.0\nColumn: numinstpaidearly_338L, Min Value: 0.0, Max Value: 373.0\nColumn: numinstregularpaid_973L, Min Value: 0.0, Max Value: 393.0\nColumn: numinstregularpaidest_4493210L, Min Value: 0.0, Max Value: 393.0\nColumn: numinsttopaygrest_4493213L, Min Value: 0.0, Max Value: 152.0\nColumn: numinstunpaidmaxest_4493212L, Min Value: 0.0, Max Value: 72.0\nColumn: numrejects9m_859L, Min Value: 0.0, Max Value: 153.0\nColumn: pctinstlsallpaidearl3d_427L, Min Value: 0.0, Max Value: 23.0\nColumn: pctinstlsallpaidlat10d_839L, Min Value: 0.0, Max Value: 1.111328125\nColumn: pctinstlsallpaidlate1d_3546856L, Min Value: 0.0, Max Value: 1.0\nColumn: pctinstlsallpaidlate4d_3546849L, Min Value: 0.0, Max Value: 2.0\nColumn: pctinstlsallpaidlate6d_3546844L, Min Value: 0.0, Max Value: 1.0\nColumn: pmtnum_254L, Min Value: 3.0, Max Value: 60.0\nColumn: birthdate_574D, Min Value: -27776.0, Max Value: -7656.0\nColumn: dateofbirth_337D, Min Value: -44064.0, Max Value: -58.0\nColumn: days120_123L, Min Value: 0.0, Max Value: 109.0\nColumn: days180_256L, Min Value: 0.0, Max Value: 110.0\nColumn: days30_165L, Min Value: 0.0, Max Value: 22.0\nColumn: days360_512L, Min Value: 0.0, Max Value: 115.0\nColumn: days90_310L, Min Value: 0.0, Max Value: 41.0\nColumn: numberofqueries_373L, Min Value: 0.0, Max Value: 115.0\nColumn: pmtscount_423L, Min Value: 0.0, Max Value: 121.0\nColumn: pmtssum_45A, Min Value: 0.0, Max Value: 476843.40625\nColumn: secondquarter_766L, Min Value: 0.0, Max Value: 109.0\nColumn: sum_credamount_590A, Min Value: 0.0, Max Value: 7800000.0\nColumn: mean_currdebt_94A, Min Value: 0.0, Max Value: 339996.375\nColumn: min_dtlastpmtallstes_3545839D, Min Value: -4240.0, Max Value: 14.0\nColumn: min_employedfrom_700D, Min Value: -21104.0, Max Value: 12.0\nColumn: max_employedfrom_700D, Min Value: -21104.0, Max Value: 12.0\nColumn: mean_employedfrom_700D, Min Value: -21104.0, Max Value: 12.0\nColumn: mean_firstnonzeroinstldate_307D, Min Value: -5324.0, Max Value: 47.0\nColumn: min_maxdpdtolerance_577P, Min Value: 0.0, Max Value: 4360.0\nColumn: max_maxdpdtolerance_577P, Min Value: 0.0, Max Value: 4360.0\nColumn: mean_maxdpdtolerance_577P, Min Value: 0.0, Max Value: 4360.0\nColumn: sum_maxdpdtolerance_577P, Min Value: 0.0, Max Value: 9912.0\nColumn: mean_outstandingdebt_522A, Min Value: 0.0, Max Value: 614749.8125\nColumn: max_pmtnum_8L, Min Value: 3.0, Max Value: 63.0\nColumn: mean_pmtnum_8L, Min Value: 3.0, Max Value: 60.0\nColumn: sum_pmtnum_8L, Min Value: 0.0, Max Value: 1200.0\nColumn: max_tenor_203L, Min Value: 3.0, Max Value: 63.0\nColumn: mean_tenor_203L, Min Value: 3.0, Max Value: 60.0\nColumn: sum_tenor_203L, Min Value: 0.0, Max Value: 1200.0\nColumn: max_birth_259D, Min Value: -27776.0, Max Value: -7656.0\nColumn: max_empl_employedfrom_271D, Min Value: -20608.0, Max Value: 13.0\nColumn: mean_empl_employedfrom_271D, Min Value: -20608.0, Max Value: 13.0\nColumn: min_empl_employedfrom_271D, Min Value: -20608.0, Max Value: 13.0\nColumn: count_num_group1_tax_registry_a, Min Value: 1.0, Max Value: 99.0\nColumn: max_amount_4527230A, Min Value: 0.0, Max Value: 87115.6015625\nColumn: sum_amount_4527230A, Min Value: 0.0, Max Value: 560494.375\nColumn: mean_pmts_dpd_303P, Min Value: -2.396484375, Max Value: 4976.0\nColumn: min_pmts_month_158T, Min Value: 1.0, Max Value: 2.0\nColumn: mean_pmts_month_158T, Min Value: 2.0, Max Value: 6.5\nColumn: max_pmts_month_158T, Min Value: 2.0, Max Value: 12.0\nColumn: min_pmts_month_706T, Min Value: 1.0, Max Value: 2.0\nColumn: mean_pmts_month_706T, Min Value: 2.0, Max Value: 6.5\nColumn: max_pmts_month_706T, Min Value: 2.0, Max Value: 12.0\nshape before preprocessing (1526659, 123)\nTotal count of NaN values in the DataFrame: 51790787\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n  return dtype.type(n)\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n  the_mean = the_sum / count if count > 0 else np.nan\n","output_type":"stream"},{"name":"stdout","text":"Total count of NaN values in the DataFrame: 0\nshape after preprocessing (1526659, 388)\nMemory usage after optimization is: 727.97 MB\nDecreased by 0.0%\nTrain/valid shape: (1526659, 388), \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18ede8366ffa489db8808f6970e42ac0"}},"metadata":{}},{"name":"stdout","text":"Fold  1 AUC : 0.656784. Elapsed time: 200.13 seconds. Remaining time: 1801.16 seconds.\nFold  2 AUC : 0.661523. Elapsed time: 386.77 seconds. Remaining time: 1547.10 seconds.\n","output_type":"stream"}]}]}